---
layout: single
title: "[OS] Memory Management"
categories: ['OS']
tag: ['운영체제', 'OS']
toc: true
toc_sticky: true
---

# Chapter 9: Memory Management

- Background 
- Logical versus Physical Address Space 
- Swapping  
- Contiguous Memory Allocation 
- **Paging** (시험)
- **Segmentation** (시험)
- Segmentation with Paging 
- Structure of the Page Table 
- Example: The Intel 32 and 64-bit Architectures 
- Example: ARM Architecture



<br>

## Objectives

- To provide a detailed description of various ways of organizing memory  hardware 
- To discuss various memory-management techniques, including paging  and segmentation 
- To provide a detailed description of the Intel Pentium, which supports both pure segmentation and segmentation with paging



<br>

## Structure - Top Level

- components are interleaved

![image-20221127005647009](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221127005647009.png)

<br>

![image-20221002232502033](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232502033.png)



<br>

## Structure -The CPU

![image-20221002232615247](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232615247.png)



<br>

## Structure - The Control Unit

![image-20221002232722331](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232722331.png)

<br>

## Von Neumann architecture

- Instructions and data are stored in a single read-write memory 
- Contents of memory are **addressable by location** without regard to the type of data contained there 
- Execution occurs **in sequential** fashion unless explicitly modified 
  - explicitly modified - loop, selection




<br>

## What is a program?

- A sequence of steps (instructions) 
- For each step, an arithmetic or logical operation is done 
- For each operation, a different set of control signals is needed

- instruction cycle의 무한 반복

<br>

## Instruction Cycle

- Two steps: 
  - Fetch 
  - Execute

![image-20221002232821824](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232821824.png)



- atomic program
  - 외부에서 interrupt를 걸어도 그 즉시 멈추지 않음
  - 나중에 처리



<br>

## Instruction Cycle (with Interrupts) - State Diagram

![image-20221002232849213](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232849213.png)



<br>

## Background

- Program must be brought (from disk) into memory and placed within a  process for it to be run 

  

- Main memory and registers are only storage CPU can access directly 

- Memory unit only sees a stream of addresses + read requests, or address + data and write requests 

  

- Register access in one CPU clock (or less) 

- Main memory can take many cycles, causing a **stall** 

- **Cache** sits between main memory and CPU registers 

  

- Protection of memory required to ensure correct operation 
  - Multi-programming에서의 security 
  - 여러 프로세스들간에 다른 프로세스의 메모리 영역 침범이 이루어지지 않도록 관리



- Memory resource 관리 
  - As a result of CPU scheduling -> improved cpu utilization, response 
  - CPU scheduling과 같이 메모리를 resource 차원에서 관리해야함.  (분배 문제) 
- A program resides on a disk as a **binary executable file** -> a.out
  - Program must be brought into memory and placed within a process  for it to be executed. 
  - Input queue – collection of processes on the disk that are waiting to be brought into memory for execution. 
    - Select one of the processes in input queue, load that process  into memory (by longterm scheduler)
    - Sequence of memory addresses are generated by the running  program (Instruction execution cycles, addressing modes) 
    - If process terminate, its memory space is made available



<br>

## Base and Limit Registers

- A pair of base and limit registers define the logical address  space

![image-20221002233047756](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233047756.png)

base register - limit register가 가리키는 범주에 벗어난 것은 illegal process로 간주

실행되는 프로세스마다 바뀜 (by OS)

<br>

## Hardware Address Protection with Base and Limit Registers

- CPU must check every memory access generated in user mode to  be sure it is between base and limit for that user

![image-20221002233125230](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233125230.png)

- the instructions to loading the base and limit registers are privileged



<br>

## Address Binding

- Programs on disk, ready to be brought into memory to execute form an **input queue** 
  - Without support, must be loaded into address 0000 
- Inconvenient to have first user process physical address always at 0000  
  - How can it not be? 
  - Most systems allow a user process to reside in any part of the physical memory 
  - **First address** of user process **does not need to be 0** 



- Further, addresses represented in different ways at different stages of a program’s life



<br>

## Background

- User programs go through several steps before being executed. 
  - Source code addresses usually symbolic address 
  - Compiled code addresses **bind** to `relocatable addresses `
    - A compiler binds symbolic address to relocatable address 
    - i.e. "14 bytes from beginning of this module"
  - Linker or loader will bind relocatable addresses to absolute addresses 
    - i.e. 74014  - 최종 주소
  - Each binding maps one address space to another

![image-20221002233255372](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233255372.png)

- Program
  - symbolic address
- 1.c, 2.c 
- 1.o, 2.o(by link module)
  - relocatable address
- a.out(by linker)
  - absolute address
- mm에 탑재(by loader)

<br>

## Address Binding

![image-20221127011733238](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221127011733238.png)



- 빈칸으로 되어있는 것은 채우지 못하는 경우
  - BLE NEXT가 BLE ___로 되어 있는 이유는 NEXT에 대한 부분의 주소를 아직 모르기 때문에 비워놔야 하는 것이다.

<br>

## Address Binding

- Internal address(위 예제의 빈칸)는 pass1,2를 통하여 reconcile됨. 
  - 소스 코드를 두 번 읽으면 가능

- Reconcile : give actual address 
- But, How about addresses which cannot be reconciled at  assembly? 
  - References to external modules 
  - References to absolute address



<br>

## Address Binding(안중요)

![image-20221002233459847](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233459847.png)

- What is done at each step ? 
  - Assembler 
    - Translate assembly language instruction into machine code 
      - Format instruction words 
      - Reconciles labels/variables location 
      - Usually addresses are generated in relocatable form 
        - » Assumes first words of program at address zero

​	

<br>

## Address Binding(안중요)

- Linker 
  - Takes various relocatable, assembled modules & combines  them into 1 module 
    - Reconcile external reference 
    - Generates load module 
    - What is in load module 
      - Machine instruction / data 
      - Information about size of various parts (code, table  data) 
      - Relocation information 
        - » Addresses which need to be reconciled when  module is placed in a particular location in  memory 



<br>

## Address Binding(안중요)

- Loader 
  - Accepts load module, places it into memory 
  - Reconciling addresses where necessary



<br>

## Binding of Instructions and Data to Memory(중요)

Address binding of instructions and data to memory addresses can happen at three different stages.

absolute address가 언제 결정되냐에 따라 다르다! (binding)

- **Compile time**:  
  - If it is known at compile time where the process will reside in memory, absolute code can be generated; 
    - 컴파일 할 때 이 프로그램이 MM에 탑재될 위치의 시작 주소를 알고있을 때 가능
  - link module을 만들지 않고 바로 load module을 만듦)
  - must recompile code if starting location changes. 
- **Load time**:  
  - Must generate **relocatable code** if memory location is not known at compile time. 
  - If the starting address changes, we need to reload the user code  
- **Execution time**:  (중요)
  - **Binding delayed** until run time if the process can be moved during its execution from one memory segment to another.  
  - binding이 컴파일을 할 때도 absolute address가 결정되지 않고 loading 할 때도 결정이 안 되고 오직 해당 instruction이 실행될 때만 결정되는 것이다.
  - Need hardware support for address maps (e.g., base and limit  registers). 



<br>

## Multistep Processing of a User Program

![image-20221002233809961](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233809961.png)

object module - link module

load module(a.out을 만들어냄)

<br>

## Logical vs. Physical Address Space

- The concept of a **logical address space** that is bound to a separate physical address space is central to proper memory management. 
  - Logical address – generated by the **CPU**; also referred to as virtual  address. 
  - Physical address – address seen by the memory unit. 
  - MMU : 두 주소 간의 변환을 해주는 역할
- Logical and physical addresses are the same in compile-time and loadtime address-binding schemes; logical (virtual) and physical addresses  differ in execution-time address-binding scheme. 
  - **Logical address space** is the set of all logical addresses generated  by a program 
  - **Physical address space** is the set of all physical addresses  generated by a program



<br>

## Physical &amp; Logical storage

- Sharing of memory 
  - Where is a process information placed? 
  - How is it later accessed? 
  - How is security insured? 
  - Want the addressing to be transparent to user 
- Physical storage 
  - Actual storage in hardware memory of machine, usually start at  zero 
- Logical storage  
  - Memory as perceived by process 
    - Can be larger or smaller than physical storage 
    - Size usually limited by architecture (<>virtual address)  
  - Usually relocatable address 
- Processes only see logical storage 
  - Logical address must be translated to physical address





<br>

## Memory-Management Unit (MMU)

- Hardware device that at run time maps virtual to physical address 

![image-20221002234124953](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234124953.png)

- Many methods possible, covered in the rest of this chapter 
- To start, consider simple scheme where the value in the relocation register is  added to every address generated by a user process at the time it is sent to  memory 
  - Base register now called relocation register 
  - MS-DOS on Intel 80x86 used 4 relocation registers 
- The user program deals with logical addresses; it never sees the real physical  addresses 
  - Execution-time binding occurs when reference is made to location in memory 
  - Logical address bound to physical addresses



<br>

## Dynamic relocation using a relocation register

![image-20221002234148212](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234148212.png)



<br>

## Dynamic Loading

- Entire program and data of a process must be in physical memory for the process  to execute 
  - The size of process is limited to the size of physical memory 
- To obtain better memory space utilization, dynamic loading can be used 
  - Routine is not loaded until it is called 
  - Better memory-space utilization; unused routine is never loaded. 
  - All routines are kept on disk in a relocatable load format 
  - When an unloaded routine is needed, relocatable loader is called to load the  desired routine into memory, then control is passed to newly loaded code 
  - Useful when large amounts of code are needed to handle infrequently  occurring cases. 
  - No special support from the operating system is required except providing  library routines to implement DL 
    - implemented through program design. 
    - OS can help by providing libraries to implement dynamic loading



<br>

## Dynamic Linking

- Static linking – system libraries and program code combined by the loader into the  binary program image 
  - shared libraries 
- Dynamic linking 
  - Rather than loading being postponed until execution time, Linking is postponed until execution time. 
- Usually used with system libraries such as language library 
  - W/O this facility, all programs on a system need to have a copy of their language  library, wastes both disk and memory 
- Small piece of code, stub, is included in the image for each library routine reference 
  - Stub is used to locate the appropriate memory-resident library routine. 
  - Stub replaces itself with the address of the routine, and executes the routine 
- Operating system checks if routine is in processes’ memory address 
  - If not in address space, add to address space 
- Consider applicability to patching system libraries 
  - Versioning may be needed 
- Need OS support because of address space problem between different processes



<br>

## Swapping

-  A process can be swapped temporarily out of memory to a backing store, and  then brought back into memory for continued execution 
  - Total physical memory space of processes can exceed physical memory 
  - Need execution time binding 
- **Backing store** – fast disk large enough to accommodate copies of all memory  images for all users; must provide direct access to these memory images 
- **Roll out, roll in** – swapping variant used for priority-based scheduling  algorithms; lower-priority process is swapped out so higher-priority process can  be loaded and executed 
- Major part of swap time is transfer time; total transfer time is directly proportional  to the amount of memory swapped 
- System maintains a **ready queue** of ready-to-run processes which have  memory images on disk



<br>

## Swapping

- Does the swapped out process need to swap back in to same physical  addresses? 
- Depends on address binding method 
  - Plus consider pending I/O to / from process memory space 
- Modified versions of swapping are found on many systems (i.e., UNIX,  Linux, and Windows) 
  - Swapping normally disabled 
  - Started if more than threshold amount of memory allocated 
  - Disabled again once memory demand reduced below threshold



<br>

## Schematic View of Swapping

![image-20221002234528490](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234528490.png)



<br>

## Context Switch Time including Swapping

- If next processes to be put on CPU is not in memory, need to swap out a process and  swap in target process 
- Context switch time can then be very high 
- 100MB process swapping to hard disk with transfer rate of 50MB/sec 
  - Plus disk latency of 8 ms 
  - Swap out time of 2008 ms 
  - Plus swap in of same sized process 
  - Total context switch swapping component time of 4016ms (> 4 seconds) 
- Can reduce if reduce size of memory swapped – by knowing how much memory really  being used 
  - System calls to inform OS of memory use via request memory and release  memory 
  - request_memory() and release_memory()



<br>

## Context Switch Time including Swapping

- Other constraints as well on swapping 
  - Pending I/O – can’t swap out as I/O would occur to wrong process 
  - Or always transfer I/O to kernel space, then to I/O device 
    - Known as double buffering, adds overhead 
- Standard swapping not used in modern operating systems 
  - But modified version common 
    - Swap only when free memory extremely low



<br>

## Swapping on Mobile Systems

- Not typically supported 
  - Flash memory based 
    - Small amount of space 
    - Limited number of write cycles 
    - Poor throughput between flash memory and CPU on mobile platform 
- Instead use other methods to free memory if low 
  - iOS asks apps to voluntarily relinquish allocated memory 
    - Read-only data thrown out and reloaded from flash if needed 
    - Failure to free can result in termination 
  - Android terminates apps if low free memory, but first writes application  state to flash for fast restart 
  - Both OSes support paging as discussed below



<br>

## Memory management

- How memory is allocated to different jobs to hold their (entire or parts of)  load module 
  - Various levels of memory 
    - Cache, main memory, secondary storage 
    - Access slower storage (secondary storage) as infrequently as  possible 
    - When need to access? 
      - Fetch instruction 
      - Fetch data/store data 
  - Use of main memory 
    - Utilize to fullest 
    - Must be shared



<br>

## Placement of modules in memory

- Main memory must support both OS and user processes 
  - Kernel remains in main memory 
  - Memory have security (between kernel and user, between users) 
- Limited resource, must allocate efficiently 
- Determine different placement strategies for user processes 
- Compare strategies based on 
  - Internal fragmentation 
    - Pieces of memory which are associated with a process but which the  process cannot using 
      - This space cannot be allocated  
  - External fragmentation 
    - Pieces of free too small to be allocated and are therefore wasted 
- Degree of multi-programming 
  - Measure of number of jobs which can be in system based on the allocation of  some portion of memory for the job’s use



<br>

## Contiguous Allocation

- Main memory usually into two partitions: 
  - Resident operating system, usually held in low memory with interrupt vector. 
  - User processes then held in high memory. 
  - Each process contained in single contiguous section of memory 
- Relocation registers used to protect user processes from each other, and  from changing operating-system code and data 
  - Base register contains value of smallest physical address 
  - Limit register contains range of logical addresses – each logical  address must be less than the limit register  
  - MMU maps logical address dynamically 
  - Can then allow actions such as kernel code being transient and  kernel changing size



<br>

## Hardware Support for Relocation and Limit Registers

![image-20221002235106545](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235106545.png)



<br>

## Single-partition allocation

- Single job in memory (All or nothing) 
  - Place the entire job in the user portion main memory 
- Where is job placed? 
  - User job can be at address directly next to kernel space 
  - Kernel-user or user-kernel depending on interrupt h/w 
  - Relocation-register scheme used to protect user processes from each other,  and from changing operating-system code and data. 
  - Relocation register contains value of smallest physical address; limit register  contains range of logical addresses – each logical address must be less than  the limit register.  
- Adv.: Compile time address binding 
- Dis, : need recompiling when kernel size changes 
  - Kernel routine 중 자주 수행되지 않는 program을 불러들일때 
    - Place user job at opposite end of memory and allow to grow toward  kernel space 
    - Translation of logical to physical (execution time biding) 
      - Security 
      - Simple addressing

<br>

## Multiple fixed parition

- MM is divided into a number of fixed size partition 
- When a process arrives, it is placed into one of the partition which are  larger than job itself     -> process is assigned entire partition 
- Prob.  
  - internal fragmentation 
  - Degree of multiprogramming bounded by # of partitions 
- Advantages 
  - Address change easy, because simple addressing 
  - Easy security 
  - Easy bookeeping : no free memory management

- What if a job does not fit the partition/memory ? (larger than)



<br>

## Overlays

- Keep in memory only those instructions and data that are needed at any  given time. 
  - Breaks program into pieces (Fig. 8.2) 
  - When other instructions are needed, they are loaded into space that  are occupied by instructions that are no longer needed 
- Needed when process is larger than amount of memory allocated to it. 
- Implemented by user, no special support needed from operating system,  programming design of overlay structure is complex



<br>

## Multiple - Variable sized partition allocation

- Multiple-partition allocation 
  - Degree of multiprogramming limited by number of partitions 
  - Variable-partition sizes for efficiency (sized to a given process’ needs) 
  - Hole – block of available memory; holes of various size are scattered  throughout memory. 
  - When a process arrives, it is allocated memory from a hole large enough to  accommodate it. 
  - Process exiting frees its partition, adjacent free partitions combined 
  - Operating system maintains information about: a) allocated partitions b) free partitions (hole) 
  - Non internal, external Fragmentation

![image-20221002235500482](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235500482.png)



<br>

## Dynamic Storage-Allocation Problem

How to satisfy a request of size n from a list of free holes.

- First-fit: Allocate the first hole that is big enough. 
  - Maintain free space information as a linked list sorted by  address (start, size)to allocate search list, assign first partition  whose size is larger than job 
  - On fly compaction 
    - Ability to combine adjacent free space 
    - Easy to maintain list in order 
  - Long search time 
  - External fragmentation 
    - Decreases size of large block 
    - Potentially increase search time



- Best-fit: Allocate the smallest hole that is big enough; must search entire  list, unless ordered by size. Produces the smallest leftover hole. 
  - Maintain free space as large of chunks as possible 
    - Maintain list is sorted in increasing size order 
  - Elements may have to be moved in the list when they change in size 
  - Remainder is going to be smaller 
- Worst-fit: Allocate the largest hole; must also search entire list.  Produces the largest leftover hole. 
  - Maintain list in decreasing size order 
  - Try to avoid generating small pieces of free space 
  - Decrease the amount of large free space



-  First-fit and best-fit better than worst-fit in terms of speed and  storage utilization 
- First fit analysis reveals that given N blocks allocated, 0.5 N blocks lost to fragmentation 
  - 1/3 may be unusable -> 50-percent rule



<br>

## Fragmentation

- External fragmentation – total memory space exists to satisfy a request,  but it is not contiguous. 
- Internal fragmentation – allocated memory may be slightly larger than  requested memory; this size difference is memory internal to a partition,  but not being used. 
- Reduce external fragmentation by compaction 
  - Shuffle memory contents to place all free memory together in one  large block. 
  - Compaction is possible only if relocation is dynamic, and is done at  execution time. 
  - I/O problem 
    - Latch job in memory while it is involved in I/O. 
    - Do I/O only into OS buffers. 
  - Now consider that backing store has same fragmentation problems



<br>

## Segmentation

- Memory-management scheme that supports user view of memory  

- A program is a collection of segments 

  - A segment is a logical unit such as: 

  main program 

  procedure 

  function 

  method 

  object 

  local variables, global variables 

  common block 

  stack

  symbol tablearray



<br>

## User's View of a Program

![image-20221002235912372](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235912372.png)



<br>

## Logical View of Segmentation

![image-20221002235931229](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235931229.png)



<br>

## Segmentation Architecture

- Logical address consists of a two tuple: 

  <segment-number, offset>,

- Segment table – maps two-dimensional physical addresses; each table entry  has: 

- base – contains the starting physical address where the segments reside in  memory 

- limit – specifies the length of the segment 

- Segment-table base register (STBR) points to the segment table’s location in  memory 

- Segment-table length register (STLR) indicates number of segments used by a  program; 

  segment number s is legal if s < STLR



<br>

## Segmentation Architecture (Cont.)

- Protection 
  - With each entry in segment table associate: 
    - validation bit = 0 -> illegal segment 
    - read/write/execute privileges 
- Protection bits associated with segments; code sharing occurs at  segment level 
- Since segments vary in length, memory allocation is a dynamic  storage-allocation problem 
- A segmentation example is shown in the following diagram

- Relocation. 
  - dynamic 
  - by segment table  
- Sharing. 
  - shared segments 
  - same segment number : self reference 
- Allocation. 
  - first fit/best fit 
  - external fragmentation



<br>

## Segmentation Hardware

![image-20221003000143452](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000143452.png)



<br>

## Example of Segmentation

![image-20221003000157093](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000157093.png)



<br>

## Sharing of segments

![image-20221003000211184](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000211184.png)





<br>

## Paging

- Another solution to external fragmentation 
  - Physical address space of a process can be noncontiguous; process is  allocated physical memory whenever the latter is available. 
  - Avoids external fragmentation 
  - Avoids problem of varying sized memory chunks 
- Divide physical memory into fixed-sized blocks called frames (size is power of 2,  between 512 bytes and 8192 bytes). 
- Divide logical memory into blocks of same size called pages. 
- Keep track of all free frames. 
- To run a program of size n pages, need to find n free frames and load program. 
- Set up a page table to translate logical to physical addresses.  
- Backing store likewise split into pages 
- Still have Internal fragmentation, External?



<br>

## Address Translation Scheme

- Address generated by CPU is divided into: 

  - Page number (p) – used as an index into a page table which  contains base address of each page in physical memory 
  - Page offset (d) – combined with base address to define the  physical memory address that is sent to the memory unit
  - ![image-20221003000318696](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000318696.png)

  - For given logical address space 2<sup>m</sup> and page size 2<sup>n</sup>



<br>

## Address Translation Scheme

- Address generated by CPU is divided into: 
  - Page number (p) – used as an index into a page table which  contains base address of each page in physical memory. 
  - Page offset (d) – combined with base address to define the physical  memory address that is sent to the memory unit. 
  - Given page size P under logical address A 
    - p = A div P 
    - d = A mod P 
    - Ex) page size = 10 , logical address = 31 
      - P = 31 div 10 = 3 
      - D = 31 mod 10 = 1



<br>

## Paging Hardware

![image-20221003000440077](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000440077.png)





<br>

## Paging Model of Logical and Physical Memory

![image-20221003000459434](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000459434.png)

<br>

## Paging Example

![image-20221003000512397](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000512397.png)



<br>

## Paging (Cont.)

- Calculating internal fragmentation 
  - Page size = 2,048 bytes 
  - Process size = 72,766 bytes 
  - 35 pages + 1,086 bytes 
  - Internal fragmentation of 2,048 - 1,086 = 962 bytes 
  - Worst case fragmentation = 1 frame – 1 byte 
  - On average fragmentation = 1 / 2 frame size 
  - So small frame sizes desirable? 
  - But each page table entry takes memory to track 
  - Page sizes growing over time 
    - Solaris supports two page sizes – 8 KB and 4 MB 
- Process view and physical memory now very different 
- By implementation process can only access its own memory



<br>

## Free Frames

![image-20221003000622312](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000622312.png)



<br>

## Implementation of Page Table

- Pages can be mapped into non-contiguous frames 
- Page table is kept in main memory. 
- Page-table base register (PTBR) points to the page table 
- Page-table length register (PTLR) indicates size of the page table 
  - Rarely does a process use all its address range 
- In this scheme every data/instruction access requires two memory  accesses. One for the page table and one for the data/instruction. 
- The two memory access problem can be solved by the use of a special fastlookup hardware cache called associative memory or translation lookaside buffers (TLBs)

- Some TLBs store address-space identifiers (ASIDs) in each TLB entry  
  - uniquely identifies each process to provide address-space protection for  that process 
  - Otherwise need to flush at every context switch 
- TLBs typically small (64 to 1,024 entries) 
- On a TLB miss, value is loaded into the TLB for faster access next time 
  - Replacement policies must be considered 
  - Some entries can be wired down for permanent fast access



<br>

## Associative Register

- Associative registers – parallel search

![image-20221003000741601](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000741601.png)

- Address translation (p, d) 
  - If p is in associative register, get frame # out.  
  - Otherwise get frame # from page table in memory



<br>

## Paging Hardware With TLB

![image-20221003000804647](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000804647.png)



<br>

## Effective Access Time

- Associative Lookup =  time unit 

  - Can be < 10% of memory access time 

- Hit ratio = α

  - Hit ratio – percentage of times that a page number is found in the associative  registers; ratio related to number of associative registers 

- Consider α = 80%, ε = 20ns for TLB search, 100ns for memory access Assume  memory cycle time is 1 microsecond

-  Effective Access Time (EAT) 

  EAT = (1 + ε) α + (2 + ε)(1 – α) 

  = 2 + ε – α

- Consider α = 80%, ε = 20ns for TLB search, 100ns for memory access 

  - EAT = 0.80 x 120 + 0.20 x 220 = 140ns 

- Consider slower memory but better hit ratio -> α = 98%, ε = 20ns for TLB search,  140ns for memory access 

  - EAT = 0.98 x 160 + 0.02 x 300 = 162.8ns



<br>

## Memory Protection

- Memory protection implemented by associating protection bit with each  frame to indicate if read-only or read-write access is allowed 
  - Read only, read-write, execution only bits 
- Valid-invalid bit attached to each entry in the page table: 
  - "valid" indicates that the associated page is in the process’ logical  address space, and is thus a legal page 
  - "invalid" indicates that the page is not in the process’ logical address  space 
  - Or use PTLR 
- Page-table length register (PRLR) indicates size of the page table. 
  - Rarely does a process use all its address range 
- Any violations result in a trap to the kernel



<br>

## Valid (v) or Invalid(i) Bit In A Page Table

![image-20221003001217135](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001217135.png)



<br>

## Shared Pages

- Shared code 
  - One copy of read-only (reentrant) code shared among processes  (i.e., text editors, compilers, window systems) 
  - Similar to multiple threads sharing the same process space 
  - Also useful for interprocess communication if sharing of read-write  pages is allowed 
- Private code and data
  - Each process keeps a separate copy of the code and data 
  - The pages for the private code and data can appear anywhere in  the logical address space



<br>

## Shared Page Examples

![image-20221003001303441](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001303441.png)



<br>

## Structure of the Page Table

- Memory structures for paging can get huge using straight-forward  methods 
  - Consider a 32-bit logical address space as on modern  computers 
  - Page size of 4 KB (212) 
  - Page table would have 1 million entries (232 / 212) 
  - If each entry is 4 bytes -> 4 MB of physical address space /  memory for page table alone 
    - That amount of memory used to cost a lot 
    - Don’t want to allocate that contiguously in main memory 
- Hierarchical Paging 
- Hashed Page Tables 
- Inverted Page Tables



<br>

## Structure of the Page Table

- Memory structures for paging can get huge using straight-forward methods 
- Most modern computer systems support a large logical address space (2<sup>32</sup>, 2<sub>64</sub>) 
  - Consider a 32-bit logical address space , Page size of 4 KB (2<sup>12</sup>) 
  - Page table would have 1 million (2*20) entries - 2<sup>32</sup> / 2<sup>12</sup>) 
  - Page table itself is becomes excessively large 
  - page table consists of (1 million) entries 
  - If each entry consists of 4 bytes, each process may need up to 4Mb of physical  address space for the page table alone 
  - Don’t want to allocate that contiguously in main memory 
- Hierarchical Paging 
- Hashed Page Tables
- Inverted Page Tables



<br>

## Hierarchical Page Tables

- Break up the logical address space into multiple page tables 
- A simple technique is a two-level page table 
- We then page the page table



<br>

## Two-Level Page-Table Scheme

![image-20221003001608667](C:\Users\c_dragon\AppData\Roaming\Typora\typora-user-images\image-20221003001608667.png)



<br>

## Two-Level Paging Example

- A logical address (on 32-bit machine with 4K page size) is divided into: 
  - a page number consisting of 20 bits 
  - a page offset consisting of 12 bits. 
- Since the page table is paged, the page number is further divided into: 
  - a 10-bit page number.  
  - a 10-bit page offset. 
- Thus, a logical address is as follows: 

![image-20221003001715427](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001715427.png)

- where pi is an index into the outer page table, and p2 is the displacement within the  page of the outer page table. 
- Known as forward-mapped page table





<br>

## Address-Translation Scheme

![image-20221003001727500](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001727500.png)



<br>

## Multilevel Paging(64-bit Logical Address Space)

- If page size is 4 KB (212) 

  - Then page table has 252 entries 

  - If we use 2-level paging scheme, inner page tables could be 1 page long  (2**10 4 byte entries) 

  - Address would look like 

    ![image-20221003001824871](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001824871.png)

  - Outer page table has 242 entries or 244 bytes 

  - One solution is to add a 2nd outer page table (Three level paging scheme) 

  - But in the following example the 2nd outer page table is still 234 bytes in size 

    - And possibly 4 memory access to get to one physical memory location



<br>

## Three-level Paging Scheme

![image-20221003001837935](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001837935.png)



<br>

## Four level paging scheme

- Since each level is stored as a separate table in memory, covering a  logical address to a physical one may take four memory accesses.  (p1,p2,p3,p4,d) 

- Even though time needed for one memory access is quintupled, caching  permits performance to remain reasonable. 

- Cache hit rate of 98 percent yields: 

  effective access time = 0.98 x 120 + 0.02 x 520 

  = 128 nanoseconds. 

which is only a 28 percent slowdown in memory access time.



<br>

## Hashed Page Tables

- A Common approach in case of address spaces > 32 bits. 
- The virtual page number is hashed into a page table.  
  - This page table contains a chain of elements hashing to the same location. 
- Each element contains (1) the virtual page number (2) the value of the mapped  page frame (3) a pointer to the next element 
- Virtual page numbers are compared in this chain searching for a match.  
  - If a match is found, the corresponding physical frame is extracted. 
- Variation for 64-bit addresses is clustered page tables 
  - Similar to hashed but each entry refers to several pages (such as 16) rather  than 1 
  - Especially useful for sparse address spaces (where memory references are  non-contiguous and scattered)

<br>

## Hashed Page Table

![image-20221003002014031](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002014031.png)



<br>

## Inverted Page Table

- Each process has a page table associated with it 
  - Each page table may consists of millions of entries 
- Rather than each process having a page table and keeping track of all possible  logical pages, track all physical pages 
  - One entry for each real page (frame) of memory. 
  - Entry consists of the virtual address of the page stored in that real memory  location, with information about the process that owns that page. 
- Decreases memory needed to store each page table, but increases time needed to  search the table when a page reference occurs.- whole table might be searched 
- Use hash table to limit the search to one — or at most a few — page-table entries. 
  - TLB can accelerate access (Associated memory register)
- But how to implement shared memory? 
  - One mapping of a virtual address to the shared physical address



<br>

## Inverted Page Table Architecture

- each virtual address consists of <process-id, page-number, offset>

![image-20221003002127392](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002127392.png)



<br>

## Segmentation with Paging - MULTICS

- The MULTICS system solved problems of external fragmentation  and lengthy search times by paging the segments. 
- Solution differs from pure segmentation in that the segment-table  entry contains not the base address of the segment, but rather the  base address of a page table for this segment.



<br>

## MULTICS Address Translation Scheme

![image-20221003002203270](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002203270.png)





<br>

## Segmentation with Paging - Intel 386

- Intel 386 uses segmentation with paging for memory management with a  two-level paging scheme.

![image-20221003002226872](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002226872.png)





<br>

## Example: The Intel 32 and 64-bit Architectures

- Dominant industry chips
- Pentium CPUs are 32-bit and called IA-32 architecture (x-86) 
- Current Intel CPUs are 64-bit and called IA-64 architecture 
- Many variations in the chips, cover the main ideas here



<br>

## Example: The Intel IA-32 Architecture

- Supports both segmentation and segmentation with paging 
  - Each segment can be 4 GB (4*10<sup>9</sup> Bytes)  
  - Up to 16 K segments per process 
  - Logical address space of a process is divided into two partitions 
    - First partition of up to 8 K segments are private to process (kept in local  descriptor table (LDT)) 
    - Second partition of up to 8K segments shared among all processes (kept  in global descriptor table (GDT)) 
    - Each entry in LDT & GDT consists of an 8-byte segment descriptor with  detailed information about a particular segment including base location  and limit of a segment



<br>

## Example: The Intel IA-32 Architecture (Cont.)

- CPU generates logical address 

  - Logical address is a pair of (selector, offset) 

  - Selector(16 bits) given to segmentation unit 

    - Which produces linear addresses  

    - s designates the segment number,  

    - g indicates whether the segment is in GDT or LDT 

    - p deals with protection 

    - offset (32 bits) specifying the location of the byte within the segment  

      ![image-20221003002437823](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002437823.png)

  - Linear address given to paging unit 

    - Which generates physical address in main memory 
    - Paging units form equivalent of MMU 
    - Pages sizes can be 4 KB or 4 MB 
      - For 4KB pages, two-level paging



<br>

## Logical to Physical Address Translation in IA-32

![image-20221003002502914](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002502914.png)



<br>

## Intel IA-32 Segmentation

![image-20221003002513358](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002513358.png)



<br>

## Intel IA-32 Paging Architecture

![image-20221003002529262](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002529262.png)





<br>

## Intel IA-32 Page Address Extensions

- 32-bit address limits led Intel to create page address extension (PAE), allowing  32-bit apps access to more than 4GB of memory space 
  - Paging went to a 3-level scheme 
  - Top two bits refer to a page directory pointer table 
  - Page-directory and page-table entries moved from 32 bits to 64-bits in size 
    - Base address of page tables and page frames to extend from 20 to 24 bits  
  - Net effect of PAE is increasing address space (from 32 bits) to 36 bits – 64GB of physical memory (24 + 12 bit offset)

![image-20221003002607170](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002607170.png)





<br>

## Intel x86-64

- Current generation Intel x86 architecture 
- 64 bits is ginormous (> 16 exabytes 16*10<sup>18</sup> : 2<sup>64</sup> bytes) 
- In practice only implement 48 bit addressing for virtual addressing 
  - Page sizes of 4 KB, 2 MB, 1 GB 
  - Four levels of paging hierarchy 
- Can also use PAE, so virtual addresses are 48 bits and physical  addresses are 52 bits

![image-20221003002651857](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002651857.png)





<br>

## Example: ARM Architecture

- Dominant mobile platform chip  (Apple iOS and Google Android  devices for example) 
- Modern, energy efficient, 32-bit  CPU 
- 4 KB and 16 KB pages 
- 1 MB and 16 MB pages (termed  sections)  One-level paging for sections, twolevel for smaller pages 
- Two levels of TLBs 
  - Outer level has two micro  TLBs (one data, one  instruction) 
  - Inner is single main TLB 
  - First inner is checked, on  miss outers are checked,  and on miss page table  walk performed by CPU

![image-20221003002726169](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002726169.png)



<br>

## ARMv8 4-level hierarchical paging

![image-20221003002742974](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002742974.png)



<br>

## Linear Address in Linux

- Linux uses only 6 segments (kernel code, kernel data, user code, user  data, task-state segment (TSS), default LDT segment) 

- Linux only uses two of four possible modes – kernel and user 

- Uses a three-level paging strategy that works well for 32-bit and 64-bit  systems 

- Linear address broken into four parts: 

  ![image-20221003002815700](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002815700.png)

- But the Pentium only supports 2-level paging?!



<br>

## Three-level Paging in Linux

![image-20221003002833465](https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002833465.png)



<br>

## Comparing Memory-Management Startegies

- Hardware support 
- Performance 
- Fragmentation 
- Relocation 
- Swapping  
- Sharing  
- Protection 
- -> Refer to summary section in text boo