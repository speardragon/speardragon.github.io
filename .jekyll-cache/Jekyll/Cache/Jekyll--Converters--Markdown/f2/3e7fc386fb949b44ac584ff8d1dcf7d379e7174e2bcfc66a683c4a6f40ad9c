I"ÒJ<h2 id="universal-design-principles---ncsu">Universal Design Principles - NCSU</h2>

<ul>
  <li>To guide a wide range of design disciplines including 
environments, products, and communications
    <ol>
      <li>Equitable use</li>
      <li>Flexibility in use</li>
      <li>Simple and intuitive to use</li>
      <li>Perceptible information</li>
      <li>Tolerance for error</li>
      <li>Low physical effort</li>
      <li>Size and space for approach and use</li>
    </ol>
  </li>
</ul>

<p><br /></p>

<h2 id="1-equitable-use">1. Equitable Use</h2>

<ul>
  <li>The design is useful and marketable to people with diverse abilities</li>
</ul>

<p>Guidelines:
1a. Provide the same means of use for all users: identical whenever possible; equivalent when not.</p>

<p>1b. Avoid segregating or stigmatizing any users.</p>

<p>1c. Provisions for privacy, security, and safety should be equally available to all users.</p>

<p>1d. Make the design appealing to all users.</p>

<p><br /></p>

<h2 id="2-flexibility-in-use">2. Flexibility in Use</h2>

<ul>
  <li>The design accommodates a wide range of individual preferences and abilities.</li>
</ul>

<p>Guidelines:
2a. Provide choice in methods of use.
2b. Accommodate right- or left-handed access and use.
2c. Facilitate the user‚Äôs accuracy and precision.
2d. Provide adaptability to the user‚Äôs pace.</p>

<p><br /></p>

<h2 id="3-simple-and-intuitive-use">3. Simple and Intuitive Use</h2>

<ul>
  <li>Use of the design is easy to understand, regardless of the user‚Äôs experience, knowledge, language skills, or current concentration level.</li>
</ul>

<p>Guidelines:
3a. Eliminate unnecessary complexity.
3b. Be consistent with user expectations and intuition.
3c. Accommodate a wide range of literacy and language skills.
3d. Arrange information consistent with its importance.
3e. Provide effective prompting and feedback during and after task completion.</p>

<p><br /></p>

<h2 id="4-perceptible-information">4. Perceptible Information</h2>

<ul>
  <li>The design communicates necessary information effectively to the user, regardless of ambient conditions or the user‚Äôs sensory abilities.</li>
</ul>

<p>Guidelines:
4a. Use different modes (pictorial, verbal, tactile) for redundant presentation of essential information.
4b. Provide adequate contrast between essential information and its surroundings.
4c. Maximize ‚Äúlegibility‚Äù of essential information.
4d. Differentiate elements in ways that can be described (i.e., make it easy to give instructions or directions).
4e. Provide compatibility with a variety of techniques or devices used by people with sensory limitations.</p>

<p><br /></p>

<h2 id="5-tolerance-for-error">5. Tolerance for Error</h2>

<ul>
  <li>The design minimizes hazards and the adverse consequences of accidental or unintended actions.</li>
</ul>

<p>Guidelines:
5a. Arrange elements to minimize hazards and errors: most used elements, most accessible; hazardous elements eliminated, isolated, or shielded.
5b. Provide warnings of hazards and errors.
5c. Provide fail safe features.
5d. Discourage unconscious action in tasks that require vigilance.</p>

<p><br /></p>

<h2 id="6-low-physical-effort">6. Low Physical Effort</h2>

<ul>
  <li>The design can be used efficiently and comfortably and with a minimum of fatigue.</li>
</ul>

<p>Guidelines:
6a. Allow user to maintain a neutral body position.
6b. Use reasonable operating forces.
6c. Minimize repetitive actions.
6d. Minimize sustained physical effort.</p>

<p><br /></p>

<h2 id="7-size-and-space-for-approach-and-use">7. Size and Space for Approach and Use</h2>

<ul>
  <li>Appropriate size and space is provided for approach, reach, manipulation, and use regardless of user‚Äôs body size, posture, or mobility</li>
</ul>

<p>Guidelines:
7a. Provide a clear line of sight to important elements for any seated or standing user.
7b. Make reach to all components comfortable for any seated or standing user.
7c. Accommodate variations in hand and grip size.
7d. Provide adequate space for the use of assistive devices or personal assistance.</p>

<p><br /></p>

<h2 id="ud-principles-coverage">UD Principle‚Äôs Coverage</h2>

<ul>
  <li>Principles of Universal Design address only universally usable design, while the practice of design involves more than consideration for usability.</li>
  <li>Designers must also incorporate other considerations such as economic, engineering, cultural, gender, and environmental concerns in their design processes.</li>
  <li>These Principles offer designers guidance to better integrate features that meet the needs of as many 
users as possible.</li>
</ul>

<p><br /></p>

<h2 id="multi-sensory-systems-beyond-ud-in-hci">Multi-Sensory Systems: Beyond UD in HCI</h2>

<ul>
  <li>More than one sensory channel in interaction
    <ul>
      <li>e.g. sounds, text, hypertext, animation, video, gestures, vision</li>
    </ul>
  </li>
  <li>Used in a range of applications:
    <ul>
      <li>Particularly good for users with special needs, and virtual reality</li>
    </ul>
  </li>
  <li>Will cover
    <ul>
      <li>General terminology</li>
      <li>Speech</li>
      <li>Non-speech sounds</li>
      <li>Handwriting</li>
    </ul>
  </li>
  <li>Considering applications as well as principles</li>
</ul>

<p><br /></p>

<h2 id="usable-senses">Usable Senses</h2>

<ul>
  <li>The 5 senses (sight, sound, touch, taste and smell) are used by us every day
    <ul>
      <li>Each is important on its own</li>
      <li>Together, they provide a fuller interaction with the natural world</li>
    </ul>
  </li>
  <li>Computers rarely offer such a rich interaction</li>
  <li>Can we use all the available senses?
    <ul>
      <li>Ideally ‚Äì yes</li>
      <li>Practically ‚Äì no</li>
    </ul>
  </li>
  <li>We can use ‚Ä¢ sight ‚Ä¢ sound ‚Ä¢ touch (sometimes)</li>
  <li>We cannot (yet) use ‚Ä¢ taste ‚Ä¢ smell</li>
</ul>

<p><br /></p>

<h2 id="multi-modal-vs-multi-media">Multi-modal vs. Multi-media</h2>

<ul>
  <li>Multi-modal systems</li>
  <li>Use more than one sense (or mode) of interaction</li>
  <li>e.g. visual and aural senses: a text processor may speak the words as well as echoing them to the screen</li>
  <li>Multi-media systems</li>
  <li>Use a number of different media to communicate information</li>
  <li>e.g. a computer-based teaching systemmay use video, animation, text and still imagesdifferent media all using the visual mode of interactionmay also use sounds, both speech and non-speechtwo more media, now using a different mode</li>
</ul>

<p><br /></p>

<h2 id="speech">Speech</h2>

<ul>
  <li>Human beings have a great and natural mastery of speech</li>
  <li>Makes it difficult to appreciate the complexities
but
it‚Äôs an easy medium for communication</li>
</ul>

<p><br /></p>

<h2 id="structure-of-speech">Structure of Speech</h2>

<ul>
  <li>Phonemes
    <ul>
      <li>40 of them</li>
      <li>Basic atomic units</li>
      <li>Sound slightly different depending on the context they are in, these larger units are ‚Ä¶</li>
    </ul>
  </li>
  <li>Allophones
    <ul>
      <li>All the sounds in the language</li>
      <li>Between 120 and 130 of them</li>
      <li>These are formed into ‚Ä¶</li>
    </ul>
  </li>
  <li>Morphemes
    <ul>
      <li>Smallest unit of language that has meaning.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-speech-terminology">Other Speech terminology</h2>

<ul>
  <li>Prosody
    <ul>
      <li>Alteration in tone and quality</li>
      <li>Variations in emphasis, stress, pauses and pitch</li>
      <li>Impart more meaning to sentences.</li>
    </ul>
  </li>
  <li>Co-articulation
    <ul>
      <li>The effect of context on the sound</li>
      <li>Transforms the phonemes into allophones</li>
    </ul>
  </li>
  <li>Syntax ‚Äì structure of sentences</li>
  <li>Semantics ‚Äì meaning of sentences</li>
</ul>

<p><br /></p>

<h2 id="speech-recognition-problems">Speech Recognition Problems</h2>

<ul>
  <li>
    <p>Different people speak differently:</p>

    <ul>
      <li>Accent, intonation, stress, idiom, volume, etc.</li>
    </ul>
  </li>
  <li>
    <p>The syntax of semantically similar sentences may vary.</p>
  </li>
  <li>
    <p>Background noises can interfere.</p>
  </li>
  <li>
    <p>People often ‚Äúummm‚Ä¶..‚Äù and ‚Äúerrr‚Ä¶..‚Äù</p>
  </li>
  <li>
    <p>Words not enough - semantics needed as well</p>

    <ul>
      <li>
        <p>Requires intelligence to understand a sentence</p>
      </li>
      <li>
        <p>Context of the utterance often has to be known</p>
      </li>
      <li>
        <p>Also information about the subject and speake</p>

        <p>e.g. even if ‚ÄúErrr‚Ä¶. I, um, don‚Äôt like this‚Äù is recognised, it is a fairly useless piece of information on it‚Äôs own</p>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="the-phonetic-typewriter">The Phonetic Typewriter</h2>

<ul>
  <li>Developed for Finnish (a phonetic language, written as it is said)</li>
  <li>Trained on one speaker, will generalise to others.</li>
  <li>A neural network is trained to cluster together similar sounds, which are then labelled with the corresponding character.</li>
  <li>When recognising speech, the sounds uttered are allocated to the closest corresponding output, and the character for that output is printed.
    <ul>
      <li>Requires large dictionary of minor variations to correct general mechanism</li>
      <li>Noticeably poorer performance on speakers it has not been trained on</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="the-phonetic-typewriter-examples">The Phonetic Typewriter Examples</h2>

<p><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20221010162320582.png" alt="image-20221010162320582" /></p>

<p><br /></p>

<h2 id="speech-recognition-useful">Speech Recognition: Useful?</h2>

<ul>
  <li>Single user or limited vocabulary systems 
e.g. computer dictation</li>
  <li>Open use, limited vocabulary systems can work 
satisfactorily
e.g. some voice activated telephone systems</li>
  <li>general user, wide vocabulary systems ‚Ä¶
‚Ä¶ still a problem</li>
  <li>Great potential, however
    <ul>
      <li>When users hands are already occupied
e.g. driving, manufacturing</li>
      <li>For users with physical disabilities</li>
      <li>Lightweight, mobile devices</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="speech-synthesis">Speech Synthesis</h2>

<ul>
  <li>The generation of speech</li>
  <li>Useful
    <ul>
      <li>Natural and familiar way of receiving information</li>
    </ul>
  </li>
  <li>Problems
    <ul>
      <li>Similar to recognition: prosody particularly</li>
    </ul>
  </li>
  <li>Additional problems
    <ul>
      <li>Intrusive - needs headphones, or creates noise in the workplace</li>
      <li>Transient - harder to review and browse</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="speech-synthesis-useful">Speech Synthesis: Useful?</h2>

<ul>
  <li>Successful in certain constrained applications
when the user:
    <ul>
      <li>Is particularly motivated to overcome problems</li>
      <li>Has few alternatives</li>
    </ul>
  </li>
  <li>Examples:
    <ul>
      <li>Screen readers
        <ul>
          <li>Read the textual display to the user utilised by visually impaired people</li>
        </ul>
      </li>
      <li>Warning signals
        <ul>
          <li>Spoken information sometimes presented to pilots whose visual and haptic skills are already fully occupied</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="non-speech-sounds">Non-Speech Sounds</h2>

<ul>
  <li>Examples: boings, bangs, squeaks, clicks etc.</li>
  <li>Commonly used for warnings and alarms</li>
  <li>Evidence to show they are useful
    <ul>
      <li>Fewer typing mistakes with key clicks</li>
      <li>Video games harder without sound</li>
    </ul>
  </li>
  <li>Language/culture independent, unlike speech</li>
</ul>

<p><br /></p>

<h2 id="non-speech-sounds-useful">Non-Speech Sounds: Useful?</h2>

<ul>
  <li>Dual mode displays:
    <ul>
      <li>Information presented along two different sensory channels</li>
      <li>Redundant presentation of information</li>
      <li>Resolution of ambiguity in one mode through information in another</li>
    </ul>
  </li>
  <li>Sound good for
    <ul>
      <li>Transient information</li>
      <li>Background status information</li>
      <li>e.g. 
Sound can be used as a redundant mode in the computer operating systems; almost any user action (file selection, window active, disk insert, search error, copy complete, etc.) can have a different sound associated with it</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="auditory-icons">Auditory Icons</h2>

<ul>
  <li>Use natural sounds to represent different types of object or action</li>
  <li>Natural sounds have associated semantics which can be mapped onto similar meanings in the interaction
    <ul>
      <li>e.g. throwing something away ~ the sound of smashing glass</li>
    </ul>
  </li>
  <li>Problem: not all things have associated meanings</li>
  <li>Additional information can also be presented:
    <ul>
      <li>Muffled sounds if object is obscured or action is in the background</li>
      <li>Use of stereo allows positional information to be added</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="sonicfinder-for-the-macintosh-1989">SonicFinder for the Macintosh (1989)</h2>

<ul>
  <li>Items and actions on the desktop have associated 
sounds</li>
  <li>Folders have a papery noise</li>
  <li>Moving files ‚Äì dragging sound</li>
  <li>Copying ‚Äì a problem ‚Ä¶ sound of a liquid being poured into a receptaclerising pitch indicates the progress of the copy</li>
  <li>Big files have louder sound than smaller ones</li>
</ul>

<p>https://vimeo.com/158610127</p>

<p><br /></p>

<h2 id="earcons">Earcons</h2>

<ul>
  <li>Synthetic sounds used to convey information</li>
  <li>Structured combinations of notes (motives) represent actions and objects</li>
  <li>Motives combined to provide rich information
    <ul>
      <li>Compound earcons</li>
      <li>Multiple motives combined to make one more complicated earcon</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221010162752944.png" alt="image-20221010162752944" /></p>

<p><br /></p>

<h2 id="earcons-ctd">Earcons (ctd)</h2>

<ul>
  <li>Family earcons
    <ul>
      <li>Similar types of earcons represent similar classes of action or similar objects: the family of ‚Äúerrors‚Äù would contain syntax and operating system errors</li>
    </ul>
  </li>
  <li>Earcons easily grouped and refined due to compositional and hierarchical nature</li>
  <li>Harder to associate with the interface task since there is no natural mapping</li>
</ul>

<p><br /></p>

<h2 id="touch">Touch</h2>

<ul>
  <li>Haptic interaction
    <ul>
      <li>Cutaneous perception
        <ul>
          <li>Tactile sensation; vibrations on the skin</li>
        </ul>
      </li>
      <li>Kinesthetics
        <ul>
          <li>Movement and position; force feedback</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Information on shape, texture, resistance, temperature, comparative spatial factors</li>
  <li>Example technologies
    <ul>
      <li>Electronic braille displays</li>
      <li>Force feedback devices
        <ul>
          <li>Phantom OMNI</li>
          <li>VR haptic globes</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="handwriting-recognition">Handwriting Recognition</h2>

<ul>
  <li>Handwriting is another communication mechanism 
which we are used to in day-to-day life</li>
  <li>Technology
    <ul>
      <li>Handwriting consists of complex strokes and spaces</li>
      <li>Captured by digitising tablet
        <ul>
          <li>Strokes transformed to sequence of dots</li>
        </ul>
      </li>
      <li>Large tablets available
        <ul>
          <li>Suitable for digitising maps and technical drawings</li>
        </ul>
      </li>
      <li>Smaller devices, some incorporating thin screens to display the information
        <ul>
          <li>Smartphones</li>
          <li>Tablet PCs</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="handwriting-recognition-ctd">Handwriting Recognition (ctd)</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221010163159210.png" alt="image-20221010163159210" /></p>

<ul>
  <li>Problems
    <ul>
      <li>Personal differences in letter formation</li>
      <li>Co-articulation effects</li>
    </ul>
  </li>
  <li>Breakthroughs:
    <ul>
      <li>Stroke not just bitmap</li>
      <li>Special ‚Äòalphabet‚Äô ‚Äì Graffiti on PalmOS</li>
    </ul>
  </li>
  <li>Current state:
    <ul>
      <li>Usable ‚Äì even without training</li>
      <li>But many prefer keyboards!</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="gesture">Gesture</h2>

<p><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20221010163311456.png" alt="image-20221010163311456" /></p>

<ul>
  <li>Applications
    <ul>
      <li>Gestural input - e.g. ‚Äúput that there‚Äù</li>
      <li>Sign language</li>
    </ul>
  </li>
  <li>Technology
    <ul>
      <li>Data glove</li>
      <li>Position sensing devices e.g MIT Media Room</li>
    </ul>
  </li>
  <li>Benefits
    <ul>
      <li>Natural form of interaction - pointing</li>
      <li>Enhance sign language communication between signing and non-signing users</li>
    </ul>
  </li>
  <li>Problems
    <ul>
      <li>User dependent, variable and issues of coarticulation</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="users-with-disabilities">Users with disabilities</h2>

<ul>
  <li>Visual impairment
    <ul>
      <li>Screen readers, SonicFinder</li>
    </ul>
  </li>
  <li>Hearing impairment
    <ul>
      <li>Text communication, gesture, captions</li>
    </ul>
  </li>
  <li>Physical impairment
    <ul>
      <li>Speech I/O, eyegaze, gesture, predictive systems (e.g. Reactive keyboard)</li>
    </ul>
  </li>
  <li>Speech impairment
    <ul>
      <li>Speech synthesis, text communication</li>
    </ul>
  </li>
  <li>Dyslexia
    <ul>
      <li>Speech input, output</li>
    </ul>
  </li>
  <li>Autism
    <ul>
      <li>Communication, education</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="-plus-">‚Ä¶ plus ‚Ä¶</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221010163509301.png" alt="image-20221010163509301" /></p>

<ul>
  <li>Age groups
    <ul>
      <li>Older people e.g. disability aids, memory aids, communication toolsto prevent social isolation</li>
      <li>Children e.g. appropriate input/outputdevices, involvement in design process</li>
    </ul>
  </li>
  <li>Cultural differences
    <ul>
      <li>Influence of nationality, generation, gender, race, sexuality, class, religion, political persuasion etc. on interpretation of interface features</li>
      <li>e.g. interpretation and acceptability of language, cultural 
symbols, gesture and colour</li>
    </ul>
  </li>
</ul>

:ET