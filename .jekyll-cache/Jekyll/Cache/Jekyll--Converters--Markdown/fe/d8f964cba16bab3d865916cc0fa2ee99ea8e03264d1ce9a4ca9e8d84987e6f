I"è><p><br /></p>

<p>[toc]</p>

<h1 id="chapter-10-virtual-memory">Chapter 10: Virtual Memory</h1>

<ul>
  <li>Background</li>
  <li>Demand Paging</li>
  <li>Performance of Demand Paging</li>
  <li>Copy-on-Write</li>
  <li>Page Replacement</li>
  <li>Allocation of Frames</li>
  <li>Thrashing</li>
  <li>Memory-Mapped Files</li>
  <li>Allocating Kernel Memory</li>
  <li>Other Considerations</li>
  <li>Demand Segmentation</li>
  <li>Operating-System Examples</li>
</ul>

<p><br /></p>

<h2 id="objectives">Objectives</h2>

<ul>
  <li>To describe the benefits of a virtual memory system</li>
  <li>To explain the concepts of demand paging, page-replacement algorithms, and allocation of page frames</li>
  <li>To discuss the principle of the working-set model</li>
  <li>To examine the relationship between shared memory and memorymapped files</li>
  <li>
    <p>To explore how kernel memory is managed</p>
  </li>
  <li>ì „ì²´ì ì¸ íë¦„ì€ virtual memoryë¥¼ ê´€ë¦¬í•˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ì¸ demand pagingì— ëŒ€í•´ì„œ ê³µë¶€ë¥¼ í•˜ê³  ì´ ê¸°ë²•ì— ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì¸ page replacement schemesì— ê´€í•´ ê³µë¶€ë¥¼ í•œë‹¤.</li>
  <li>ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ëŸ¬í•œ ê°€ìƒ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ë°œìƒí•  ë¬¸ì œì  ì¤‘ í•˜ë‚˜ì¸ Thrasingì— ëŒ€í•´ì„œ ê³µë¶€í•´ ë³´ë„ë¡ í•œë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="background">Background</h2>

<ul>
  <li>In Ch 9, MM strategies have same goal
    <ul>
      <li>To keep many processes in memory simultaneously to allow MP</li>
      <li>Requires that an entire process to be in memory before process can execute</li>
    </ul>
  </li>
  <li>Code needs to be in memory to execute, but entire program rarely used
    <ul>
      <li><strong>ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ê²ƒë“¤ë„ íƒ‘ì¬ë˜ëŠ” ë¬¸ì œ</strong></li>
      <li>Error code, unusual routines, large data structures</li>
      <li>Entire program code not needed at same time</li>
    </ul>
  </li>
  <li>Consider ability to execute <mark>partially-loaded </mark>program
    <ul>
      <li>Program no longer constrained by limits of physical memory
        <ul>
          <li>Program and programs could be larger than physical memory</li>
        </ul>
      </li>
      <li>Each program takes less memory while running -&gt; more programs run at the same time
        <ul>
          <li>Increased CPU <strong>utilization</strong> and <strong>throughput</strong> with no increase in response time or turnaround time</li>
        </ul>
      </li>
      <li>Less I/O needed to load or swap programs into memory
        <ul>
          <li>each user program runs faster</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Ch9ì—ì„œ ë°°ì› ë˜ Memory ManagementëŠ” í•˜ë‚˜ì˜ í”„ë¡œê·¸ë¨ ì „ì²´ë¥¼ ì‹¤ì œ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ëŠ” ë°©ì‹ì„ ì‚¬ìš©í–ˆëŠ”ë° virtual memoryë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¹ì¥ ì‹¤í–‰ì— ì‚¬ìš©ë˜ëŠ”, ì¦‰ í•„ìš”í•œ ë¶€ë¶„ë§Œ ë”± physical memoryì— ì˜¬ë ¤ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤.</li>
  <li>ì´ê²ƒì„ í†µí•´ ìƒê¸°ëŠ” ì¥ì ì€?
    <ol>
      <li>í”„ë¡œê·¸ë¨ì€ ë” ì´ìƒ physical memoryì˜ ì‹¤ì œ ë‚¨ì€ ê³µê°„ì´ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ì— ëŒ€í•´ì„œ program ì‹œì‘ ì „ì— ê³ ë¯¼í•  í•„ìš”ê°€ ì—†ë‹¤.</li>
      <li>í”„ë¡œê·¸ë¨ì´ ì „ì²´ê°€ ë‹¤ ì˜¬ë¼ê°€ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ë” ë§ì€ í”„ë¡œê·¸ë¨ì€ ë™ì‹œì— ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.</li>
      <li>í•œ ë²ˆì— ì˜¬ë¦¬ëŠ” ì†ŒìŠ¤ì˜ ì–‘ì´ ì ê¸° ë•Œë¬¸ì— HDDì™€ Main Memoryê°„ì— I/O ì‘ì—… ì†ë„ê°€ ë¹¨ë¼ì§„ë‹¤.</li>
    </ol>
  </li>
</ul>

<p><br /></p>

<h2 id="background-1">Background</h2>

<ul>
  <li><strong>Virtual memory</strong>
    <ul>
      <li>A technique that allows the execution of processes that are <strong>not completely</strong> in memory
        <ul>
          <li>ëª¨ë“  ê²ƒì„ ë‹¤ íƒ‘ì¬ ì‹œí‚¤ì§€ ì•Šê³ ë„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë„ë¡</li>
        </ul>
      </li>
      <li>separation of user logical memory from physical memory.</li>
      <li>Only part of the program needs to be in memory for execution
        <ul>
          <li>Need to allow pages to be swapped in and out. â€“ Logical address space can therefore be much larger than physical address space  (ê±°ì˜ ë¬´í•œëŒ€ì²˜ëŸ¼ ë³´ì„)
            <ul>
              <li>each process has appearance of infinite memory (virtual address space) available to it</li>
              <li>Can deal with jobs with high memory requirement which system may not want to fulfill (in terms of multiprogramming)</li>
              <li>Overlay, dynamic loading (restriction)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Allows address spaces to be shared by several processes</li>
      <li>Allows for more efficient process creation</li>
      <li>More programs running concurrently</li>
      <li>Less I/O needed to load or swap processes</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="background-cont">Background (Cont.)</h2>

<ul>
  <li><strong>Virtual address space</strong> â€“ logical view of how process is stored in memory
    <ul>
      <li>Usually start at address 0, <strong>contiguous</strong> addresses until end of space</li>
      <li>Meanwhile, <strong>physical memory</strong> organized in <strong>non-contiguous</strong> page frames</li>
      <li><strong>MMU</strong> must map logical to physical (translation)</li>
    </ul>
  </li>
  <li>Virtual memory can be implemented via:
    <ul>
      <li>Demand paging</li>
      <li>Demand segmentation</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123231958407.png" alt="image-20221123231958407" /></p>

<p><br /></p>

<h2 id="virtual-memory-that-is-larger-than-physical-memory">Virtual Memory That is Larger Than Physical Memory</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232013232.png" alt="image-20221123232013232" /></p>

<p><br /></p>

<h2 id="what-should-be-done-by-os">What should be done by OS</h2>

<ul>
  <li>To perform the idea, OS must maintain the following perspectives
    <ul>
      <li>Which portion of a process will be in memory -&gt; locality(ì§‘ì¤‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” page ì§‘í•©)
        <ul>
          <li>In general, process is broken into pages</li>
        </ul>
      </li>
      <li>When is a portion of job brought into memory
        <ul>
          <li><strong>On demand</strong></li>
        </ul>
      </li>
      <li>Maintain information regarding which portion of job are in memory</li>
      <li>Where they are located</li>
      <li>When they are taken out of memory</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="virtual-address-space">Virtual-address Space</h2>

<ul>
  <li>Usually design logical address space for stack to start at Max logical address and grow â€œdownâ€ while heap grows â€œupâ€
    <ul>
      <li>Maximizes address space use</li>
      <li>Unused address space between the two is <strong>hole</strong>
        <ul>
          <li>No physical memory needed until heap or stack grows to a given new page</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Enables <strong>sparse address spaces</strong>(ì¤‘ê°„ì´ ë¹„ì–´ìˆìœ¼ë‹ˆê¹Œ) with holes left for growth, dynamically linked libraries, etc</li>
  <li>System libraries shared via mapping into virtual address space</li>
  <li>Shared memory by mapping pages read-write into virtual address space</li>
  <li>Pages can be shared during fork(), speeding process creation
    <ul>
      <li>codeëŠ” ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ì™€ ê³µìœ í•˜ëŠ” ë¶€ë¶„(read-onlyë¼ì„œ)</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232146128.png" alt="image-20221123232146128" /></p>

<p><br /></p>

<h2 id="shared-library-using-virtual-memory">Shared Library Using Virtual Memory</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232200391.png" alt="image-20221123232200391" /></p>

<p><br /></p>

<h2 id="demand-paging">Demand Paging</h2>

<ul>
  <li>
    <p>demand pagingì˜ basic conceptì€ virtual memoryê°€ ì¶”êµ¬í•˜ëŠ” ë°©ì‹ì„ êµ¬í˜„í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ ì˜¤ë¡œì§€ ì‚¬ìš© ì¤‘ì¸ ë¶€ë¶„ë§Œ memoryì— ì˜¬ë¦¬ëŠ” ë°©ë²•ì´ë‹¤.</p>
  </li>
  <li>Could bring entire process into memory at load time</li>
  <li>Or bring a page into memory o<strong>nly when it is needed</strong>
    <ul>
      <li>Less I/O needed, no unnecessary I/O</li>
      <li>Less memory needed</li>
      <li>Faster response</li>
      <li>More users</li>
    </ul>
  </li>
  <li>Similar to <strong>paging system</strong> with <strong>swapping</strong> (diagram on below)
    <ul>
      <li>ì•ì—ì„œ ë°°ì› ë˜ swappingì€ process ì „ì²´ê°€ swap in, swap out ë˜ëŠ” ê²ƒì´ì—ˆë‹¤ë©´ paging systemì—ì„œëŠ” pageë‹¨ìœ„ë¡œ swap in, swap outëœë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„œ hardwareì˜ supportê°€ í•„ìš”í•œë° ê·¸ ì´ìœ ëŠ” valid-invalid Bitë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì´ë‹¤.</p>
  </li>
  <li>Page is needed =&gt; reference to it
    <ul>
      <li>invalid reference =&gt; abort</li>
      <li>valid reference
        <ul>
          <li>not-in-memory =&gt; bring to memory
            <ul>
              <li>validí•œ pageì§€ë§Œ memoryì—ëŠ” íƒ‘ì¬ë˜ì§€ ì•ŠìŒ!</li>
            </ul>
          </li>
          <li>in-memory =&gt; OK (just referencing)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Lazy swapper</strong>(on demandë¡œ pagingë˜ê¸° ë•Œë¬¸) - never swaps a page into memory unless page will be needed
    <ul>
      <li>í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ ì ˆëŒ€ memory ì•ˆ ê°€ì ¸ì˜¬ ê±°ì„ ã…¡ã…¡
        <ul>
          <li>on-demand means -&gt; reference ë˜ì–´ì§ˆ ë•Œ</li>
        </ul>
      </li>
      <li>Swapper that deals with pages is a pager</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232418351.png" alt="image-20221123232418351" /></p>

<ul>
  <li>When is a portion of process (page) brought into memory ?
    <ul>
      <li>Demand paging (<strong>on-demand</strong>)
        <ul>
          <li>Page is only brought into memory when needed
            <ul>
              <li>lazy swapper:</li>
              <li>Swapper that deals with pages is a pager
                <ul>
                  <li>Â» view a process as a sequence of pages rather than one large contiguous address space</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Paging system with swapping ?</li>
        </ul>
      </li>
      <li>Pre-fetching (Taking Guess)
        <ul>
          <li>ì¶”ì¸¡í•˜ê³  ë¯¸ë¦¬ fetch(í•˜ë“œì›¨ì–´ì—ì„œ ì½ì–´ì˜¤ëŠ” ì‹œê°„ì„ ì¤„ì„)</li>
          <li>Bring page into memory before it is needed</li>
          <li>Because I/O is slow, if guess is wrong then it costs high
            <ul>
              <li>ë§Œì•½ í‹€ë¦¬ë©´ ê·¸ ëŒ€ê°€ê°€â€¦í¬í â€¦</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="basic-concepts">Basic Concepts</h2>

<ul>
  <li>If pages needed are already <strong>memory resident</strong>
    <ul>
      <li>No difference from non demand-paging</li>
    </ul>
  </li>
  <li>If page needed and not memory resident
    <ul>
      <li>Need to detect and load the page into memory from storage
        <ul>
          <li>Without changing program behavior</li>
          <li>Without programmer needing to change code</li>
        </ul>
      </li>
      <li>virtual memoryëŠ” application program logic ê³¼ ìƒê´€ì—†ì´ OSì— ì˜í•´ì„œë§Œ ì œê³µë˜ëŠ” ê¸°ëŠ¥</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="valid-invalid-bit">Valid-Invalid Bit</h2>

<ul>
  <li>With each page table entry a validâ€“invalid bit is associated 
(<strong>v</strong> =&gt; in-memory â€“ <strong>memory resident</strong>, 
  <strong>i</strong> =&gt; not-in-memory)</li>
  <li>Initially validâ€“invalid bit is set to i on all entries</li>
  <li>Example of a page table snapshot:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232634353.png" alt="image-20221123232634353" /></p>

<ul>
  <li>During address translation, if validâ€“invalid bit in page table entry is I
    <ul>
      <li>page fault
        <ul>
          <li>ì²˜ë¦¬ -&gt; ië¥¼ vë¡œ ë°”ê¿”ì£¼ëŠ” ì¼ ë™ì‘</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="page-table-when-some-pages-are-not-in-main-memory">Page Table When Some Pages Are Not in Main Memory</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232719163.png" alt="image-20221123232719163" /></p>

<p><br /></p>

<h2 id="page-fault">Page Fault</h2>

<ul>
  <li>Occurs when an attempt is made to access a location which is not in memory
    <ul>
      <li>ì§€ê¸ˆ ì‹¤í–‰ ì‹œì¼œì•¼ í•  pageê°€ physical memoryì— ì˜¬ë¼ì™€ ìˆì§€ ì•ŠëŠ” ê²ƒì„ ë§í•œë‹¤.</li>
    </ul>
  </li>
  <li>If there is a reference to a page, first reference will trap to OS
    <ul>
      <li>CPUëŠ” OSì—ê²Œ ì´ë¥¼ ì•Œë¦¬ê³ (by trap) OSëŠ” ì ì‹œ ë™ì•ˆ CPU ì‘ì—…ì„ ë©ˆì¶˜ë‹¤.</li>
      <li>page fault</li>
    </ul>
  </li>
  <li>Cold faults
    <ul>
      <li>Faults which occur in a processâ€™s <strong>initial execution</strong> when its first page are brought into memory</li>
      <li>ì ˆëŒ€ í”¼í•  ë°©ë²• ì—†ìŒ(ì–˜ ë§ê³  ì¼ë°˜ì ì¸ page faultë¥¼ ì¤„ì´ë ¤ê³  ë…¸ë ¥í•´ì•¼ í•¨.)</li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <p>OS looks at another table to decide:</p>

    <ol>
      <li>
        <p>Invalid reference(ë’¤ìª½ì— ë¶™ì–´ìˆëŠ” í…Œì´ë¸”) =&gt; abort.</p>
      </li>
      <li>
        <p>Just not in memory.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Get empty frame. (í™•ë³´)</p>
  </li>
  <li>
    <p>Swap page into frame via scheduled disk operation (disk I/O ìš”êµ¬)</p>
  </li>
  <li>
    <p>Reset tables, to indicate page now in memory Set validation bit = <strong>v</strong></p>
  </li>
  <li>
    <p>Restart instruction that caused the page fault</p>
  </li>
</ol>

<ul>
  <li>page faultë¥¼ ì¼ìœ¼ì¼°ë˜ ëª…ë ¹ì–´ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì‘ì—…ì„ ì¬ê°œ</li>
</ul>

<p><br /></p>

<h2 id="steps-in-handling-a-page-fault---ì‹œí—˜">Steps in Handling a Page Fault - ì‹œí—˜</h2>

<p>ìœ„ì˜ 1~5 stepì„ ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒ(mapping í•  ì¤„ ì•Œì•„ì•¼ í•¨.)</p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123232911116.png" alt="image-20221123232911116" /></p>

<p><br /></p>

<h2 id="aspects-of-demand-paging">Aspects of Demand Paging</h2>

<ul>
  <li>Extreme case â€“ start process with no pages in memory
    <ul>
      <li>OS sets instruction pointer to first instruction of process, non-memory-resident -&gt; page fault</li>
      <li>And for every other process pages on first access</li>
      <li><strong>Pure demand paging</strong> (ì•„ë¬´ê²ƒë„ íƒ‘ì¬ë˜ì§€ ì•Šì€)</li>
      <li>ì„±ëŠ¥ ì €í•´ ìš”ì†Œê°€ ìˆìŒ</li>
    </ul>
  </li>
  <li>Actually, a given instruction could access multiple pages -&gt; multiple page faults
    <ul>
      <li>Consider fetch and decode of instruction which adds 2 numbers (addì™€ ê°™ì€ instructionì„ ìƒê°í•´ ë³´ë©´ ì•Œê² ì§€ë§Œ í•œ instruction ë‹¹ pageê°€ 3ê°œëŠ” ìˆì–´ì•¼ í•¨)
        <ul>
          <li>ì´ëŠ” 3ê°œì˜ page faultë¥¼ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬í•´ì•¼ì§€ í•˜ë‚˜ì˜ instructionì´ ì‹¤í–‰ë¨.</li>
        </ul>
      </li>
      <li>Pain decreased because of <strong>locality of reference</strong></li>
    </ul>
  </li>
  <li>Hardware support needed for demand paging (same as hardware for paging/swapping)
    <ul>
      <li>Page table with valid / invalid bit</li>
      <li>Secondary memory (swap device with swap space)</li>
      <li>Instruction restart</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="instruction-restart">Instruction Restart</h2>

<ul>
  <li>
    <p>Consider an instruction that could access <strong>several different locations</strong> (add ê°™ì€ instruction)</p>

    <ul>
      <li>
        <p>block move</p>

        <ul>
          <li>
            <p>Either block straddles a page boundary</p>

            <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123233034654.png" alt="image-20221123233034654" /></p>
          </li>
        </ul>
      </li>
      <li>
        <p>auto increment/decrement location</p>
      </li>
      <li>
        <p>Restart the whole operation?</p>

        <ul>
          <li>What if source and destination overlap?</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="performance-of-demand-paging-when-page-fault-occurs">Performance of Demand Paging (When page fault occurs)</h2>

<p>normal page fault</p>

<p>cold faults</p>

<ul>
  <li>Stages in Demand Paging (worse case)</li>
</ul>

<ol>
  <li>Trap to the operating system (interrupt)</li>
  <li>Save the user registers and process state (context switch) - handlerê°€ê¸° ì „ì— ì´ì „ ìƒíƒœë¥¼ save</li>
  <li>Determine that the interrupt was a page fault (interrupt ì¢…ë¥˜ê°€ ë¨¸ì„?)</li>
  <li>Check that the page reference was legal and determine the location of the page on the disk (legalí•¨?)</li>
  <li>Issue a read from the disk to a free frame: (ì½ì–´ì„œ copyí•˜ë¼ê³  diskì—ê²Œ ìš”êµ¬)
    <ol>
      <li>Wait in a queue for this device until the read request is serviced</li>
      <li>Wait for the device seek and/or latency time (HDDë¼ì„œ í•„ìš”í•œ ë¶€ë¶„)</li>
      <li>Begin the transfer of the page to a free frame</li>
    </ol>
  </li>
  <li>While waiting, allocate the CPU to other process</li>
  <li>Receive an interrupt from the disk I/O subsystem (<strong>I/O completed</strong>)</li>
  <li>Save the registers and process state for the other process (context switch)</li>
  <li>Determine that the interrupt was from the disk</li>
  <li>Correct the page table and other tables to show page is now in memory (v -&gt; i)</li>
  <li>Wait for the CPU to be allocated to this process again
    <ul>
      <li>Job becomes <strong>ready</strong>, wait CPU to restart instruction</li>
    </ul>
  </li>
  <li><strong>Restore</strong> the user registers, process state, and new page table, (context switch) and then <strong>resume</strong> the interrupted instruction</li>
</ol>

<p><br /></p>

<h2 id="performance-of-demand-paging-cont">Performance of Demand Paging (Cont.)</h2>

<ul>
  <li>Three major activities
    <ul>
      <li>Service the <strong>interrupt</strong> - careful coding means just several hundred instructions needed</li>
      <li><strong>Read</strong> the page - lots of time (HDDí•œí…Œì„œ ì½ì–´ì•¼ ë¼ì„œ ì˜¤ë˜ ê±¸ë¦¼)</li>
      <li><strong>Restart</strong> the process â€“ again just a small amount of time</li>
    </ul>
  </li>
  <li>Page Fault Rate 0 â‰¤ p â‰¤ 1.0
    <ul>
      <li>if p = 0 no page faults (demand pagingì„ í•˜ì§€ ì•ŠëŠ”ë‹¤)</li>
      <li>if p = 1, every reference is a fault (ë§¤ reference ë§ˆë‹¤ page faultê°€ ì¼ì–´ë‚¨.)
        <ul>
          <li><mark>ì´ ë•Œ, referenceëŠ” íŠ¹ì • addressì— ëŒ€í•œ referenceë¥¼ ë§í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ pageì— ëŒ€í•œ referenceì„.</mark></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Effective Access Time (EAT)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123233316821.png" alt="image-20221123233316821" /></p>

<p>swap outì´ ì™œ ìˆì§€? -&gt; swap in ì„ í•˜ê¸° ìœ„í•´ì„œ free frameì„ ì°¾ì•„ë³´ì•˜ëŠ”ë° free frameì´ ì—†ìœ¼ë©´ ê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ page ì¤‘ ì¼ë¶€ë¥¼ swap out í•´ì•¼í•´ì„œ ìƒê¸°ëŠ” ê³¼ì •</p>

<p><br /></p>

<h2 id="demand-paging-example">Demand Paging Example</h2>

<ul>
  <li>Memory access time = 100 nanoseconds</li>
  <li>Average page fault service time = 25 milliseconds
    <ul>
      <li>EAT = (1 â€“ p) x 100 + p (25,000,000) 
 	= 100 + 24,999,900 X p</li>
      <li><strong>effective access time is directly proportional to page fault rate</strong></li>
    </ul>
  </li>
  <li>If one access out of 1000 causes a page fault, the effective access time is 25 micro seconds</li>
  <li>
    <p>Computer would be slow down by a factor of 250 because of demand paging</p>
  </li>
  <li>cold faultsê°€ ì•„ë‹Œ ì¼ë°˜ page faultë¥¼ ì¤„ì´ëŠ” ë°©ë²• ? -&gt; TLB cache! (cacheì˜ hit ratioë¥¼ ì¦ê°€ì‹œí‚´ìœ¼ë¡œì¨!)</li>
</ul>

<p><br /></p>

<ul>
  <li>Memory access time = 200 nanoseconds (demand pagingì„ ì•ˆí•œ ê²½ìš°)</li>
  <li>Average page-fault service time = 8 milliseconds</li>
  <li>EAT = (1 â€“ p) x 200 + p (8 milliseconds) 
        = (1 â€“ p) x 200 + p x 8,000,000 
        = 200 + p x 7,999,800</li>
  <li>If one access out of 1,000 causes a page fault, then
    <ul>
      <li>EAT = 8.2 microseconds.</li>
      <li>This is a slowdown by a factor of 40!! (demand pagingì„ ì•ˆí•  ë•Œë³´ë‹¤ 40ë°°ë§Œí¼ ëŠë ¤ì§)</li>
    </ul>
  </li>
  <li>If want performance degradation &lt; 10 percent
    <ul>
      <li>220 &gt; 200 + 7,999,800 x p 
 20 &gt; 7,999,800 x p</li>
      <li>p &lt; .0000025</li>
      <li>&lt; one page fault in every 400,000 memory accesses</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="demand-paging-example-1">Demand Paging Example</h2>

<ul>
  <li>
    <p>Memory access time = 1 microsecond</p>
  </li>
  <li>
    <p>50% of the time the page that is being replaced has been modified and therefore needs to be swapped out.</p>
  </li>
  <li>
    <p>Swap Page Time = 10 msec = 10,000 msec</p>

    <p>â€‹	EAT = (1 â€“ p) x 1 + p (15000)</p>

    <p>â€‹			1 + 15000P (in msec)</p>
  </li>
</ul>

<p><br /></p>

<h2 id="demand-paging-optimizations---handling-of-swap-space">Demand Paging Optimizations - Handling of Swap Space</h2>

<p>demand paging ì„±ëŠ¥ì„ ì˜¬ë¦¬ëŠ” ë°©ë²•</p>

<ul>
  <li>I/O to <strong>Swap space is faster than file system I/O</strong> even if on the same device
    <ul>
      <li>Swap space is allocated in larger chunks, less management needed than file system
        <ul>
          <li>(fileì„ ì°¾ì•„ê°€ê¸° ìœ„í•´ì„œëŠ”) File lookups and indirect allocation methods are not used</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>For better paging performance,
    <ul>
      <li>First option: Copy entire process image to swap space at process load time
        <ul>
          <li>Then performing demand paging (page in and out) <strong>from the swap space</strong></li>
          <li>Disadvantage: copying of the file image at program start-up(ë¶€ë‹´ë¨.)</li>
        </ul>
      </li>
      <li>Second option: demand paging from the file system initially, but to write the pages to swap space as they are replaced
        <ul>
          <li>file systemì—ì„œ demand pagingì„ ë°”ë¡œ í•˜ê¸´ í•˜ëŠ”ë° memory íƒ‘ì¬ë˜ì—ˆë˜ pageê°€ replace(swap-out) ë  ë•Œ, swap spaceë¡œ swap-outí•œë‹¤.
            <ul>
              <li>ì¦‰ ìµœì´ˆì˜ pageê°€ read ë  ë•Œë§Œ file systemìœ¼ë¡œë¶€í„°!</li>
            </ul>
          </li>
          <li>Ensure that only needed pages are read from the file system but that all subsequent paging is done from swap space</li>
          <li>Used in Linux, Windows</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Demand page in from program binary executable files on disk, but <strong>discard</strong> rather than paging out when freeing frame
    <ul>
      <li>ìˆ˜ì •ë˜ì§€ ì•Šì€ ë¶€ë¶„ì˜ swap-outì€ ê·¸ëƒ¥ ë²„ë¦¼.</li>
      <li>Because they are not modified, ìƒê´€ì—†ìŒ</li>
      <li>can reduce the size of swap space</li>
      <li>Still need to write to swap space
        <ul>
          <li>Swap space is used for the pages not associated with a file (like stack and heap) â€“ <strong>anonymous memory</strong></li>
          <li><strong>Pages modified in memory but not yet written back to the file system</strong></li>
          <li>Used in Linux, BSD Unix</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Mobile systems
    <ul>
      <li>Typically donâ€™t support swapping</li>
      <li>Instead, demand page from file system and reclaim read-only pages (such as code) from applications if memory becomes constrained</li>
      <li>Such data can be demand-paged from the file systems if it is later needed</li>
      <li>Under iOS, anonymous memory pages are never reclaimed from an application unless the application is terminated or explicitly releases the memory</li>
      <li>Compressed memory (alternative to swapping) is used in mobile systems</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="copy-on-write">Copy-on-Write</h2>

<ul>
  <li><strong>Copy-on-Write</strong> (COW) allows both parent and child processes to initially share the same pages in memory (ë˜‘ê°™ì€ í”„ë¡œì„¸ìŠ¤ ì´ë¯¸ì§€ë¥¼ copyí•˜ì—¬ ê°€ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë˜‘ê°™ì€ ì£¼ì†Œ ê³µê°„ì„ ê³µìœ í•¨)
    <ul>
      <li>childëŠ” ë³„ë„ì˜ ì£¼ì†Œ ê³µê°„ì´ ë§Œë“¤ì–´ì§€ì§€ ì•ŠìŒ</li>
      <li>If either process <strong>modifies</strong> a shared page, only then is the page <strong>copied</strong>
        <ul>
          <li>write í•˜ëŠ” ê²½ìš° copyë¥¼ ë§Œë“ ë‹¤!</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>COW allows more efficient process creation as only modified pages are copied
    <ul>
      <li>ì‹œê°„ë„ ì ê²Œ ê±¸ë¦¬ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ë„ good!</li>
    </ul>
  </li>
  <li>In general, free pages are allocated from a <strong>pool</strong> of <strong>zero-fill-on-demand pages</strong>
    <ul>
      <li>Pool should always(í•­ìƒ, ë¯¸ë¦¬) have free frames for fast demand page execution
        <ul>
          <li>Donâ€™t want to have to free a frame as well as other processing on page fault</li>
        </ul>
      </li>
      <li>Why zero-out a page before allocating it?</li>
    </ul>
  </li>
  <li><strong>vfork()</strong> variation on fork() system call has <strong>parent suspend</strong> and child using copy-on-write address space of parent
    <ul>
      <li>Designed to have child call <strong>exec()</strong></li>
      <li>Very efficient</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="before-process-1-modifies-page-c">Before Process 1 Modifies Page C</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234106691.png" alt="image-20221123234106691" /></p>

<p><br /></p>

<h2 id="after-process-1-modifies-page-c">After Process 1 Modifies Page C</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234120807.png" alt="image-20221123234120807" /></p>

<p><br /></p>

<h2 id="what-happens-if-there-is-no-free-frame---ì‹œí—˜">What Happens if There is no Free Frame? - ì‹œí—˜</h2>

<ul>
  <li>ì™œ free frameì´ ì—†ìŒ? -&gt; Used up by process pages (process pageì— ì˜í•´ ëª¨ë‘ ì‚¬ìš©ë˜ì—ˆê¸° ë•Œë¬¸)</li>
  <li>Also in demand from the kernel, I/O buffers, etc</li>
  <li>How much to allocate to each?
    <ul>
      <li>í”„ë¡œì„¸ìŠ¤ ë‹¹ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” free frameì˜ ê°œìˆ˜ ì œí•œ
        <ul>
          <li>ëª¨ë“  pageê°€ ë‹¤ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><em>â€œì‹¤ì œ ë©”ëª¨ë¦¬ì— ë¹„ì–´ìˆëŠ” Frameì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì–´ë–¡í•˜ì§€?â€</em></p>
  </li>
  <li><strong>Page replacement</strong> â€“ find some page in memory, but not really in use, page it out</li>
  <li>ì¦‰, í˜„ì¬ ìì‹ ì´ ì°¨ì§€í•˜ê³  ìˆëŠ” Frameì„ ì§€ê¸ˆ ë‹¹ì¥ ì‹¤í–‰í•´ì•¼ í•  Pageì—ê²Œ ë„˜ê²¨ ì¤„ Victim Frameì„ ì°¾ëŠ” ê³¼ì •</li>
  <li>ì œí•œëœ í˜ì´ì§€ ê°œìˆ˜ë¥¼ ê°€ì§„ í”„ë¡œì„¸ìŠ¤ê°€ í˜ì´ì§€ë¥¼ êµì²´í•  ë•Œ ë­˜(ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”) ë¹¼ê³  ë„£ì„ì§€ ê²°ì •í•˜ëŠ”</li>
  <li>Algorithm â€“ terminate? swap out? replace the page? 
    - What page (of a job) in memory is going to be replaced by a new page which must be brought in ? (ê¸°ì¤€ì´ ë­ì„?)</li>
  <li><mark>Performance â€“ want an algorithm which will result in minimum number of page faults </mark>
    <ul>
      <li>ì˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” pageë¥¼ êµì²´í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª©í‘œë¡œ í•´ì•¼ì§€ ì„±ëŠ¥ì´ ê·¹ëŒ€í™”ë¨.</li>
    </ul>
  </li>
  <li>Same page may be brought into memory several times</li>
  <li>Reduce the # of page faults</li>
</ul>

<p><br /></p>

<h2 id="page-replacement">Page Replacement</h2>

<ul>
  <li>Prevent <strong>over-allocation</strong> of memory by modifying page-fault service routine to include page replacement</li>
  <li>Use <strong>modify (dirty) bit</strong> to reduce overhead of page transfers â€“ only modified pages are written to disk
    <ul>
      <li>page inì„ í•˜ê³  ì½ê¸°ë§Œ í–ˆìœ¼ë©´ page outì„ í•˜ì§€ ì•Šì•„ë„ ë˜ëŠ”ë° page inì„ í•˜ê³  ìˆ˜ì •ì„ í–ˆë‹¤ë©´ <strong>ë°˜ë“œì‹œ</strong> page outì„ í•´ì£¼ì–´ì•¼ í•œë‹¤.</li>
      <li>page outì´ ë˜ì–´ì•¼ í•˜ëŠ”ì§€ ì•„ë‹Œì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” bitê°€ modify bit(dirty bit)</li>
      <li>ì¦‰, Modify BitëŠ” í˜„ì¬ ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°€ ìˆëŠ” Pageë“¤ ì¤‘ì—ì„œ ë‚´ë¶€ ë°ì´í„°ê°€ ë°”ë€Œì—ˆëŠ”ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” Bitì´ë©°, ë‚´ë¶€ ë°ì´í„°ê°€ ë°”ë€Œì—ˆë‹¤ë©´ Diskì™€ì˜ ë™ê¸°í™”ë¥¼ ìœ„í•´ Swap-out ë  í•„ìš”ê°€ ìˆë‹¤.
        <ul>
          <li>ì´ëŸ¬í•œ Swap-In/Swap-outì€ ë§ì€ costë¥¼ ë°œìƒì‹œí‚¤ëŠ”ë°, ê·¸ë˜ì„œ Victim Frameì„ ì°¾ì„ ë•ŒëŠ” Modify bitê°€ 0, ì¦‰ Swap-out ë  í•„ìš” ì—†ëŠ” Frameì„ ìš°ì„ ì ìœ¼ë¡œ ì°¾ì•„ì•¼ í•œë‹¤.(Swap-out ë  í•„ìš”ê°€ ì—†ìœ¼ë‹ˆ ê·¸ ìë¦¬ì— ë®ì–´ ì”Œì›Œë²„ë¦¬ë©´ ê·¸ë§Œì´ê¸° ë•Œë¬¸)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Page replacement completes separation between logical memory and physical memory â€“ large virtual memory can be provided on a smaller physical memory</li>
</ul>

<p><br /></p>

<h2 id="need-for-page-replacement">Need For Page Replacement</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234231861.png" alt="image-20221123234231861" /></p>

<p><br /></p>

<h2 id="basic-page-replacement">Basic Page Replacement</h2>

<ol>
  <li>Find the location of the desired page on disk. (ì›í•˜ëŠ” Pageë¥¼ Diskì—ì„œ ì°¾ëŠ”ë‹¤.)</li>
  <li>
    <p>Find a free frame: (ë¹„ì–´ìˆëŠ” Frameì„ ì°¾ëŠ”ë‹¤.)</p>

    <ul>
      <li>
        <p>If there is a free frame, use it.</p>
      </li>
      <li>
        <p><strong>If there is no free frame</strong>, use a page replacement algorithm to select a <strong>victim frame</strong>.</p>
        <ul>
          <li>Write victim frame to disk if dirty (ë§Œì•½ dirtyë©´ <strong>swap out</strong>ì„ ë¨¼ì € í•´ì¤˜ì•¼ í•¨.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Bring the desired page into the (newly) free frame. Update the page and frame tables.
    <ul>
      <li>Diskì—ì„œ ê°€ì ¸ì˜¨ Pageë¥¼ 2ë²ˆ ê³¼ì •ì—ì„œ ì°¾ì€ Frame ìœ„ì¹˜ì— swap-in í•˜ê³  Frame Tableê³¼ Page Tableì„ update ì‹œí‚¨ë‹¤.</li>
    </ul>
  </li>
  <li>Continue the process by restarting the instruction that caused the trap
    <ul>
      <li>instruction ì¬ ì‹¤í–‰</li>
    </ul>
  </li>
</ol>

<p>Note now potentially 2 page transfers for page fault â€“ increasing EAT</p>

<p><br /></p>

<h2 id="page-replacement-1">Page Replacement</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234316255.png" alt="image-20221123234316255" /></p>

<ul>
  <li>1ë²ˆì— ì˜í•´ì„œ f ìœ„ì¹˜ì— ìˆëŠ” victim frameì„ swap outí•˜ê¸° ë•Œë¬¸ì— page tableì—ì„œ fì— ëŒ€í•œ ê²ƒì„ v -&gt; ië¡œ ë°”ê¿”ì¤€ë‹¤.</li>
  <li>3ë²ˆì— ì˜í•´ì„œ page in ë˜ê¸° ë•Œë¬¸ì— ë‹¤ì‹œ f ëŠ” i-&gt;vë¡œ ë°”ë€ë‹¤. (ìƒˆë¡œìš´ ê²ƒìœ¼ë¡œ ë°”ë€Œì—ˆìŒ!)</li>
</ul>

<p><br /></p>

<h2 id="page-and-frame-replacement-algorithms">Page and Frame Replacement Algorithms</h2>

<ul>
  <li><strong>Frame-allocation algorithm</strong> determines
    <ul>
      <li>How many frames to give each process</li>
      <li>Which frames to replace</li>
    </ul>
  </li>
  <li><strong>Page-replacement algorithm</strong>
    <ul>
      <li>Want lowest page-fault rate on both first access and re-access</li>
    </ul>
  </li>
  <li>Evaluate algorithm by running it on a particular string of memory references (<strong>reference string</strong>) and computing <strong>the number of page faults</strong> on that string
    <ul>
      <li><strong>String is just page numbers, not full addresses</strong></li>
      <li>Repeated access to the same page does not cause a page fault</li>
      <li>Results depend on number of frames available</li>
    </ul>
  </li>
  <li>In all our examples, the reference string is</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234425976.png" alt="image-20221123234425976" /></p>

<p><br /></p>

<h2 id="graph-of-page-faults-versus-the-number-of-frames">Graph of Page Faults Versus The Number of Frames</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234436585.png" alt="image-20221123234436585" /></p>

<p>ì„±ëŠ¥ì´ ë‚˜ë¹ ì§€ì§€ ì•ŠëŠ” ì„ ì—ì„œ frameìˆ˜ë¥¼ ìµœì†Œí™”</p>

<p>frame ìˆ˜ë¥¼ ë„ˆë¬´ ëŠ˜ë ¤ë„ overhead</p>

<p><br /></p>

<h2 id="first-in-first-out-fifo-algorithm">First-In-First-Out (FIFO) Algorithm</h2>

<ul>
  <li>ë§ ê·¸ëŒ€ë¡œ ì‹¤ì œ ë©”ëª¨ë¦¬ì— ì˜¬ë¼ì˜¨ ì§€ (Frameì„ ì°¨ì§€í•œ ì§€) ê°€ì¥ ì˜¤ë˜ëœ Frameì„ ì„ íƒí•œë‹¤.</li>
  <li>Reference string: 7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1</li>
  <li>Replace page which has been in memory for the largest period of time (íƒ‘ì¬ëœ ì‹œì ì´ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ)</li>
  <li>3 frames (3 pages can be in memory at a time per process)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234511222.png" alt="image-20221123234511222" /></p>

<ul>
  <li>ê°€ì¥ ì˜¤ë˜ëœ ê±¸ ê°ˆì•„ì¹˜ìš°ë©´ì„œ ì§„í–‰</li>
  <li>Can vary by reference string: consider 1,2,3,4,1,2,5,1,2,3,4,5
    <ul>
      <li>Adding more frames can cause more page faults!
        <ul>
          <li>Beladyâ€™s Anomaly (ê·œì¹™ì„±ì´ ì—†ë“œë¼.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>How to track ages of pages?
    <ul>
      <li>Just use a FIFO queue</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="first-in-first-out-fifo-algorithm-1">First-In-First-Out (FIFO) Algorithm</h2>

<ul>
  <li>Reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5</li>
  <li>3 frames (3 pages can be in memory at a time per process)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234549107.png" alt="image-20221123234549107" /></p>

<ul>
  <li>4 frames</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234600941.png" alt="image-20221123234600941" /></p>

<ul>
  <li>FIFO Replacement â€“ Beladyâ€™s Anomaly
    <ul>
      <li>more frames =&gt; less page faults</li>
      <li>frameì„ ë” ì¤¬ë”ë‹ˆ page faultsê°€ ëŠ˜ì–´ë‚¬ë„¤? -&gt; ëª¨ìˆœì´ ì¡´ì¬</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="fifo-illustrating-beladys-anamoly">FIFO Illustrating Beladyâ€™s Anamoly</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234627860.png" alt="image-20221123234627860" /></p>

<p><br /></p>

<h2 id="beladys-anomaly---ì‹œí—˜">Beladyâ€™s Anomaly - ì‹œí—˜</h2>

<ul>
  <li>For certain replacement strategies, the page fault rate may increase for certain strings as the number of allocated frames increases</li>
  <li>Stack property
    <ul>
      <li><img src="https://media.geeksforgeeks.org/wp-content/uploads/stackbased.png" alt="img" /></li>
      <li>At each point in any page reference string, the set of pages which would be in memory, if n pages were saved, is a subset of the pages which would be in memory if (n+1) pages were saved
        <ul>
          <li>í˜ì´ì§€ ì°¸ì¡° ë¬¸ìì—´ì˜ ê° ì§€ì ì—ì„œ, nê°œì˜ í˜ì´ì§€ê°€ ì €ì¥ë˜ë©´ ë©”ëª¨ë¦¬ì— ìˆëŠ” í˜ì´ì§€ ì§‘í•©ì€ (n+1)ê°œì˜ í˜ì´ì§€ê°€ ì €ì¥ë˜ë©´ ë©”ëª¨ë¦¬ì— ìˆëŠ” í˜ì´ì§€ì˜ í•˜ìœ„ ì§‘í•©ì…ë‹ˆë‹¤.</li>
        </ul>
      </li>
      <li><strong>FIFO</strong> exhibits beladyâ€™s anomaly because <strong>it does not have stack property</strong></li>
      <li><mark>ì™œ FIFOëŠ” stack propertyë¥¼ ê°–ì§€ ì•Šì„ê¹Œ?</mark>
        <ul>
          <li>Beladyâ€™s Anomaly  ë•Œë¬¸ì— ì–´ì©Œê³  ì €ì©Œê³ </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>beladyâ€™s anomaly í˜„ìƒì´ ì¼ì–´ë‚˜ëŠ” ì´ìœ ëŠ” stack propertyë¥¼ ê°–ê³  ìˆì§€ ì•Šê¸° ë•Œë¬¸</li>
</ul>

<p><br /></p>

<h2 id="optimal-algorithm">Optimal Algorithm</h2>

<ul>
  <li>Replace page that will not be used for longest period of time
    <ul>
      <li>ê°€ì¥ ì˜¤ë«ë™ì•ˆ ì‚¬ìš©ë˜ì§€ ì•Šì„ Frameì„ Victim Frameìœ¼ë¡œ ì„ íƒ</li>
      <li>Replace page whose next reference is furthest in the future</li>
      <li>9 is optimal for the example</li>
      <li>ê°€ì¥ ì¢‹ì€ ì•Œê³ ë¦¬ì¦˜ì´ë¼ì„œ optimalì´ë¼ëŠ” ì´ë¦„ì´ ë¶™ìŒ</li>
    </ul>
  </li>
  <li>How do you know this?
    <ul>
      <li>Canâ€™t read the future (êµ¬í˜„ì´ ë¶ˆê°€ëŠ¥í•¨â€¦ - ë¯¸ë˜ì˜ íŒ¨í„´ì„ ë³´ê³  í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—)</li>
    </ul>
  </li>
  <li>Used for measuring how well your algorithm performs(ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì´ ì¢‹ëƒ ì•ˆ ì¢‹ëƒ ë¹„êµë§Œ ê°€ëŠ¥)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234718477.png" alt="image-20221123234718477" /></p>

<p><br /></p>

<ul>
  <li>Idea is to postpone next fault as long as possible</li>
  <li>4 frames example</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234738988.png" alt="image-20221123234738988" /></p>

<ul>
  <li>ì–˜ëŠ” stack propertyë¥¼ ê°–ê³  ìˆì–´ì„œ page faultsê°€ ì¤„ì—ˆì–´!</li>
</ul>

<p><br /></p>

<h2 id="least-recently-used-lru-algorithm">Least Recently Used (LRU) Algorithm</h2>

<ul>
  <li><strong>Use past</strong> knowledge rather than future (ê³¼ê±°ì˜ íŒ¨í„´ì„ ê°€ì§€ê³  algorithm ê²°ì •)
    <ul>
      <li>ê°€ì¥ ì˜¤ë«ë™ì•ˆ ì‚¬ìš©ë˜ì§€ ì•Šì€ Pageì˜ Frameì„ ì„ íƒ!</li>
    </ul>
  </li>
  <li>Select page for replacement which has not been used for the longest period of time</li>
  <li>Associate time of last use with each page
    <ul>
      <li>ì‚¬ìš©ëœ ì§€ ê°€ì¥ ì˜¤ë˜ëœ pageê°€ victimì´ ë˜ì–´ì•¼ í•¨(ê³¼ê±°ì—ë„ ì‚¬ìš© ì•ˆ ëìœ¼ë©´ ë‚˜ì¤‘ì—ë„ ì‚¬ìš© ì•ˆë˜ê² ì§€~)</li>
    </ul>
  </li>
  <li>Idea: recent past reflects behavior of near future
    <ul>
      <li>Page least likely to be used in near future is page used furthest in the past</li>
      <li>FIFO: time, LRU: Use</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234803960.png" alt="image-20221123234803960" /></p>

<ul>
  <li>12 faults â€“ better than FIFO but worse than OPT</li>
  <li>Generally good algorithm and frequently used</li>
  <li>But how to implement?</li>
  <li>ì‚¬ìš© ì‹œì ì„ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ LRUì—ì„œ í•µì‹¬ í¬ì¸íŠ¸</li>
  <li>ê°€ì¥ ìµœê·¼ì— ì‹¤í–‰ë˜ì—ˆìœ¼ë©´ ê±”ëŠ” victimì´ ë  ìˆ˜ ì—†ìŒ</li>
</ul>

<p><br /></p>

<h2 id="more-example">More example</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234840541.png" alt="image-20221123234840541" /></p>

<ul>
  <li>NF - No fault</li>
  <li>CF - Cold Faults</li>
  <li>F - Fault</li>
  <li>ìƒˆë¡œ ë“¤ì–´ì˜¤ëŠ” ê±¸ topì— ê³„ì†í•´ì„œ ë‘ëŠ” í‘œí˜„ ë°©ì‹ - ë’¤ì— ìˆëŠ” ê²ƒë“¤ì€ í•˜ë‚˜ì”© ì•„ë˜ë¡œ ë°€ì–´ì„œ ì œì¼ ì•„ë˜ ìˆë˜ ê²ƒì´ victimì´ ëœë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="lru-algorithm-cont">LRU Algorithm (Cont.)</h2>

<ul>
  <li>We can expect god performance, â€œif past is reflections of future behaviorâ€</li>
  <li>Problem: <strong>difficult</strong> to implement efficiently: <strong>Stack</strong>, <strong>Counter</strong></li>
  <li><strong>Counter implementation</strong>
    <ul>
      <li>Every page entry has a counter; every <strong>time</strong> page is referenced through this entry, copy the clock into the counter. (pageê°€ referenceê°€ ë  ë•Œë§ˆë‹¤)</li>
      <li>When a page needs to be changed, look at the counters to find <strong>smallest value</strong> (to determine which are to change).
        <ul>
          <li>Search through table needed (ë¹„êµë¥¼ í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ê°ê°ì„ search í•´ì•¼ í•¨.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Stack implementation</strong>
    <ul>
      <li>keep a stack of page numbers in a doubly linked list form:</li>
      <li>Page referenced:
        <ul>
          <li>move it to the top</li>
          <li>ìµœëŒ€ : requires 6 pointers to be changed -&gt; why?
            <ul>
              <li>í˜„ì¬ pageê°€ stackì— ì¡´ì¬í•œë‹¤ë©´ í•´ë‹¹ ê°’ì„ stackì˜ topìœ¼ë¡œ ì˜®ê²¨ ì£¼ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ìµœëŒ€ 6ê°œì˜ í¬ì¸í„°ë¥¼ ë°”ê¾¸ì–´ ì£¼ì–´ì•¼ í•˜ëŠ” overheadê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>But each update more expensive</li>
      <li>No search for replacement (ìŠ¤íƒì˜ topì´ LRU ì¼ê²ƒì´ê³ (ê°€ì¥ ìµœê·¼ ì‚¬ìš©) ë§¨ ì•„ë˜ ê¹”ë¦° ê²Œ victimì´ ë  ê²ƒì´ê¸° ë•Œë¬¸ )</li>
    </ul>
  </li>
  <li>LRU and OPT are cases of <strong>stack algorithms</strong> that donâ€™t have Beladyâ€™ s
    <ul>
      <li>stack propertyë¥¼ ê°€ì§!</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="use-of-a-stack-to-record-the-most-recent-page-references">Use Of A Stack to Record The Most Recent Page References</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123234932918.png" alt="image-20221123234932918" /></p>

<p><mark>í•œ ë²ˆ í•´ ë³´ê¸°!</mark></p>

<p><br /></p>

<h2 id="lru-approximation-algorithmsìœ ì‚¬-lru">LRU Approximation Algorithms(ìœ ì‚¬ LRU)</h2>

<ul>
  <li>
    <p>LRU needs special hardware and still slow</p>
  </li>
  <li>Inexact LRU
    <ul>
      <li>Select page for replacement which has not been used recently</li>
    </ul>
  </li>
  <li>Reference bit ì‚¬ìš© (by hardware êµ¬í˜„)
    <ul>
      <li>With each page associate a bit, initially = 0</li>
      <li>When page is referenced bit set to 1</li>
      <li>Periodically clear bits.</li>
      <li>Replace the one which is 0 (if one exists).
        <ul>
          <li>We do not know the order, however (ëˆ„ê°€ ë ˆí¼ëŸ°ìŠ¤ê°€ ë¨¼ì € ëëŠ” ì§€ ëª¨ë¦„)</li>
        </ul>
      </li>
    </ul>

    <h3 id="1-additional-reference-bit-ì‚¬ìš©-ì•ì„ -ë¬¸ì œ-í•´ê²°">1. Additional reference bit ì‚¬ìš© (ì•ì„  ë¬¸ì œ í•´ê²°)</h3>

    <ul>
      <li>Shift register</li>
      <li>Maintain use bit for each page</li>
      <li>at periods, shift use bit into register</li>
      <li>Will shift in a 1 if used in that period, shift in 0 otherwise</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123235025452.png" alt="image-20221123235025452" /></p>

<p>ê°€ì¥ ì‘ì€ ê°’ì´ ì œì¼ ì˜¤ë˜ìˆì—ˆë˜ page</p>

<ul>
  <li>ì˜¤ë¥¸ìª½ìœ¼ë¡œ shift ë˜ê¸° ë•Œë¬¸ì— ê°€ì¥ ì˜¤ë˜ ëœ ê²ƒì€ msbë¶€í„° ì­‰ 0ì¼ ê²ƒì´ê¸° ë•Œë¬¸ì—</li>
</ul>

<p><br /></p>

<h3 id="3-second-chance-algorithm">3. Second chance algorithm</h3>

<ul>
  <li>Generally <strong>FIFO</strong>, plus hardware-provided reference bit  (FIFO + reference bit)</li>
  <li>Clock replacement.</li>
  <li>reference ë˜ë©´ reference bitë¥¼ 1ë¡œ ë°”ê¿ˆ</li>
  <li>If page to be replaced (in clock order) has
    <ul>
      <li>Reference bit = 0 -&gt; replace it</li>
      <li>Reference bit = 1. then:
        <ul>
          <li>set reference bit 0, leave page in memory. (í•œ ë²ˆ ë” ê¸°íšŒë¥¼ ì¤€ë‹¤.)</li>
          <li>replace next page (in clock order), subject to same rules.(-&gt; ë‹¤ë¥¸ victimì„ ì°¾ì•„ ë– ë‚¨)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ëª¨ë“  pageì˜ reference bitê°€ 1ì´ë¼ë©´ ê²°êµ­ì€ FIFOì™€ ë˜‘ê°™ì´ ì‘ë™</li>
</ul>

<p><br /></p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123235108592.png" alt="image-20221123235108592" /></p>

<p>1ë²ˆìœ¼ë¡œ setting ë˜ì–´ ìˆìœ¼ë©´ ë°”ë¡œ victimìœ¼ë¡œ ì„ ì •í•˜ì§€ ì•Šê³  ë‘ë²ˆ ì§¸ ë‹¤ì‹œ ì²´í¬í•˜ê² ë‹¤.</p>

<p><br /></p>

<h3 id="3-enhanced-second-chance-algorithm">3. Enhanced Second-Chance Algorithm</h3>

<ul>
  <li>Improve algorithm by using <strong>reference bit</strong> and <strong>modify bit</strong> (if available) in concert</li>
  <li>Take ordered pair (reference, modify)</li>
</ul>

<ol>
  <li>(0, 0) neither recently used not modified â€“ best page to replace</li>
  <li>(0, 1) not recently used but modified â€“ not quite as good, must write out before replacement</li>
  <li>(1, 0) recently used but clean â€“ probably will be used again soon</li>
  <li>(1, 1) recently used and modified â€“ probably will be used again soon and need to write out before replacement</li>
</ol>

<ul>
  <li>When page replacement called for, use the clock scheme but use the four classes replace page in lowest non-empty class
    <ul>
      <li>Might need to search circular queue several times</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="counting-algorithms">Counting Algorithms</h2>

<ul>
  <li>Keep a counter of the number of references that have been made to each page.
    <ul>
      <li>Not common</li>
      <li>Access ëœ íšŸìˆ˜ë¥¼ Page tableì˜ ê° Pageì—ë‹¤ê°€ ì €ì¥ì„ í•´ì„œ ê·¸ ê°’ìœ¼ë¡œ Victim pageë¥¼ ì„ íƒí•œë‹¤.</li>
    </ul>
  </li>
  <li><strong>1. LFU (Least Frequently Used)</strong>
    <ul>
      <li>Algorithm: replaces page with smallest count.
        <ul>
          <li>count ê°’, ì¦‰ access ëœ íšŸìˆ˜ê°€ ê°€ì¥ ì ì€ í˜ì´ì§€ë¥¼ ì„ íƒ</li>
        </ul>
      </li>
      <li>Suffers from the situation in which a page is used heavily during initial phase, but then is never used again
        <ul>
          <li>ì´ˆë°˜ì—ë§Œ ë§ì´ ì‚¬ìš©ë˜ê³  ë‚˜ì¤‘ì— ì˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” pageì™€ ì´ˆë°˜ì—” ì˜ ì‚¬ìš©ë˜ì§€ ì•Šë‹¤ê°€ í›„ë°˜ë¶€ì— ë§ì´ ì‚¬ìš©ë˜ëŠ” í˜ì´ì§€ì˜ ê²½ìš° LRUë¥¼ ì˜ ì°¾ì•„ë‚´ì§€ ëª»í•  ê²ƒì´ë‹¤.</li>
        </ul>
      </li>
      <li>Solution is to shift the counts right by 1 bit at regular intervals, forming an exponentially decaying average usage</li>
    </ul>
  </li>
  <li><strong>2. MFU (Most Frequently Used) Algorithm</strong>
    <ul>
      <li>count ê°’, ì¦‰ access ëœ íšŸìˆ˜ê°€ ê°€ì¥ ë§ì€ í˜ì´ì§€ë¥¼ victimìœ¼ë¡œ ì„ íƒ</li>
      <li>based on the argument that the page with the smallest count was probably just brought in and has yet to be used.
        <ul>
          <li>countê°’ì´ ì‘ì€ í˜ì´ì§€ëŠ” ìµœê·¼ì— íƒ‘ì¬ëœ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.ë¼ê³  í•´ì„</li>
        </ul>
      </li>
      <li>ë§ì´ access ë˜ì—ˆë‹¤ë©´ ì•ìœ¼ë¡œëŠ” ì°¸ì¡°ë˜ì§€ ì•Šì„ ê²ƒì´ë¼ê³  íŒë‹¨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="page-buffering-algorithms">Page-Buffering Algorithms</h2>

<p>demand pagingì˜ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•œ ê³¼ì •ì˜ ì¼ì¢…ë“¤</p>

<ul>
  <li>Keep a <strong>pool</strong> of free frames, always (poolì„ ì‚¬ìš©)
    <ul>
      <li>Then frame available when needed, not found at fault time</li>
      <li>Read page into free frame and select victim to evict and add to free pool</li>
      <li>When convenient(í¸í•  ë•Œ ì•„ë¬´ ë•Œë‚˜), evict(ì«“ì•„ë‚´ë‹¤) victim</li>
    </ul>
  </li>
  <li>Possibly, keep list of <strong>modified pages</strong> (ìˆ˜ì •ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
    <ul>
      <li>When backing store otherwise idle, write pages there and set to non-dirty</li>
    </ul>
  </li>
  <li>Possibly, keep free frame contents intact and note what is in them
    <ul>
      <li>victimìœ¼ë¡œ ì„ ì •ë˜ì—ˆë˜ frameë¥¼ zero-out(ì´ˆê¸°í™”)ì„ í•˜ì§€ ì•Šê²Œ ë˜ë©´ LRU í˜ì´ì§€ ì„ ì •ì´ ì˜ëª» ë˜ì–´ì§„ ê²ƒì„ ì¡°ê¸ˆ ë³´ì •í•  ìˆ˜ ìˆê²Œëœë‹¤.</li>
      <li>If referenced again before reused, no need to load contents again from disk</li>
      <li>Generally useful to reduce penalty if wrong victim frame selected</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="applications-and-page-replacement">Applications and Page Replacement</h2>

<ul>
  <li>All of these algorithms have OS guessing about future page access</li>
  <li>Some applications have better knowledge â€“ i.e. databases
    <ul>
      <li>ë¯¸ë˜ì˜ íŒ¨í„´ì„ ì•Œê³  ìˆìŒ</li>
    </ul>
  </li>
  <li><strong>Memory intensive applications</strong> can cause double buffering</li>
  <li>OS keeps copy of page in memory as I/O buffer</li>
  <li>Application keeps page in memory for its <strong>own work</strong></li>
  <li>Operating system can given direct access to the disk, getting out of the way of the applications</li>
  <li>Raw disk mode</li>
  <li>Bypasses buffering, locking, etc</li>
</ul>

<p><br /></p>

<h2 id="allocation-of-frames">Allocation of Frames</h2>

<ul>
  <li>Demand paging ì—ì„œëŠ” í”„ë¡œì„¸ìŠ¤ê°€ ë‹¹ì¥ ìˆ˜í–‰í•´ì•¼ í•  ë¶€ë¶„ì— ëŒ€í•´ì„œ ìµœì†Œí•œì˜ Frame ë§Œì„ í• ë‹¹í•˜ê²Œ ëœë‹¤.
    <ul>
      <li>ì´ëŸ¬í•œ Frameì„ í• ë‹¹í•´ ì£¼ëŠ” ë°©ë²•ì—ë„ ëª‡ ê°€ì§€ê°€ ì¡´ì¬í•¨.</li>
    </ul>
  </li>
  <li>Each process needs minimum number of pages.</li>
  <li>Example: IBM 370 â€“ <strong>6 pages</strong> to handle SS MOVE instruction:
    <ul>
      <li>instruction is 6 bytes, might span 2 pages.</li>
      <li>2 pages to handle <strong>from</strong>.</li>
      <li>2 pages to handle <strong>to</strong>.</li>
    </ul>
  </li>
  <li>Maximum of course is total frames in the system</li>
  <li>Two major allocation schemes.
    <ul>
      <li>fixed allocation</li>
      <li>priority allocation</li>
    </ul>
  </li>
  <li>Many variations</li>
</ul>

<p><br /></p>

<h2 id="fixed-allocation">Fixed Allocation</h2>

<ul>
  <li>Equal allocation
    <ul>
      <li>í”„ë¡œì„¸ìŠ¤ ëª©ì ê³¼ ì„±ê²©ì— ìƒê´€ì—†ì´ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ì—ê²Œ ê³ ì •ëœ ì–‘ì˜ Frameì„ í• ë‹¹</li>
      <li>For example, if there are 100 frames (after allocating frames for the OS) and 5 processes, give each process 20 frames</li>
      <li>Keep some as free frame buffer pool</li>
    </ul>
  </li>
  <li>Proportional allocation â€“ Allocate according to the size of process.
    <ul>
      <li>í”„ë¡œì„¸ìŠ¤ í¬ê¸°ì— ë¹„ë¡€í•´ì„œ Frameì„ í• ë‹¹í•´ ì£¼ëŠ” ë°©ë²•</li>
      <li>Dynamic as degree of multiprogramming, process sizes change</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123235451540.png" alt="image-20221123235451540" /></p>

<p><br /></p>

<h2 id="priority-allocation">Priority Allocation</h2>

<ul>
  <li>
    <p>ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ í”„ë¡œì„¸ìŠ¤ì—ê²Œ ê·¸ë§Œí¼ ë” ë§ì€ ì–‘ì˜ Frameì„ í• ë‹¹í•´ ì£¼ëŠ” ë°©ë²•.</p>
  </li>
  <li>Use a proportional allocation scheme using priorities rather than size.</li>
  <li>If process Pi generates a page fault,
    <ul>
      <li>select for replacement one of its frames.</li>
      <li>select for replacement a frame from a process with lower priority number.</li>
    </ul>
  </li>
  <li>FIFOë¥¼ ì œì™¸í•˜ê³ ëŠ” frameì„ ë§ì´ ì£¼ë©´ page faultê°€ ì¤„ì–´ë“¦.</li>
</ul>

<p><br /></p>

<h2 id="global-vs-local-allocation">Global vs. Local Allocation</h2>

<ul>
  <li><strong>Global replacement</strong> â€“ process selects a replacement frame from the set of all frames; one process can take a frame from another
    <ul>
      <li>ëª¨ë“  í”„ë¡œì„¸ìŠ¤ì˜ ëª¨ë“  í˜ì´ì§€ì— victimì„ ì°¾ìŒ
        <ul>
          <li>ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ ê°–ê³  ìˆëŠ” frameë„ victimìœ¼ë¡œ ì„ ì •ê°€ëŠ¥.</li>
        </ul>
      </li>
      <li>But then process execution time can vary greatly</li>
      <li>But greater throughput so more common</li>
    </ul>
  </li>
  <li><strong>Local replacement</strong> â€“ each process selects from only its own set of allocated frames
    <ul>
      <li>í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œë§Œ victimì„ ì°¾ìŒ</li>
      <li>More consistent per-process performance</li>
      <li>But possibly underutilized memory</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="non-uniform-memory-access">Non-Uniform Memory Access</h2>

<ul>
  <li>So far we assume that all memory accessed equally</li>
  <li>Many systems are NUMA â€“ speed of access to memory varies
    <ul>
      <li>Consider system boards containing CPUs and memory, interconnected over a system bus</li>
    </ul>
  </li>
  <li>When a process incurs a page fault, a NUMA-aware virtual memory system will allocate that process a frame as close as possible to the CPU on which the process is running</li>
  <li>Optimal performance comes from allocating memory â€œclose toâ€ the CPU on which the thread is scheduled
    <ul>
      <li>And modifying the scheduler to schedule the thread on the same system board when possible</li>
      <li>Solved by Solaris by creating <strong>lgroups (locality group)</strong>
        <ul>
          <li>Structure to track CPU / Memory low latency groups</li>
          <li>Used my schedule and pager</li>
          <li>When possible schedule all threads of a process and allocate all memory for that process within the lgroup</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="numa-multiprocessing-architecture">NUMA Multiprocessing Architecture</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123235737223.png" alt="image-20221123235737223" /></p>

<p><br /></p>

<h2 id="thrashing">Thrashing</h2>

<ul>
  <li>If a process does not have â€œenoughâ€ pages, the page-fault rate is very high.
    <ul>
      <li>Page fault to get page</li>
      <li>Replace existing frame</li>
      <li>But quickly need replaced frame back</li>
      <li>This leads to:
        <ul>
          <li>low CPU utilization.
            <ul>
              <li>Spending more time paging than executing</li>
            </ul>
          </li>
          <li>operating system thinks that it needs to increase the degree of multiprogramming.</li>
          <li>another process added to the system.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Thrashing = a process is busy swapping pages in and out. (page in-outì„ ë„ˆë¬´ ë§ì´ í•¨.)</li>
  <li>Solution :
    <ul>
      <li>provide a process as many frames as it needs
        <ul>
          <li>ê·¸ê²ƒì´ í•„ìš”í•œ ë§Œí¼ ë§ì€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì œê³µí•œë‹¤.</li>
          <li>demanding pageì˜ ì¥ì ì´ í•˜ë‚˜ë„ ì—†ì–´ì§</li>
        </ul>
      </li>
      <li>Then, How much ? =&gt; Working set model</li>
    </ul>
  </li>
  <li>virtual memory ê¸°ë²•ì˜ êµ¬í˜„ ì›ë¦¬ëŠ” ê·¸ë•Œ ê·¸ë•Œ í•„ìš”í•œ ë¶€ë¶„ë§Œì„ memoryì— ì˜¬ë ¤ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ê³  ë‹¹ì¥ ì‹¤í–‰í•˜ì§€ ì•Šì„ ê²ƒ ê°™ì€ ë¶€ë¶„ì€ ë””ìŠ¤í¬ì— ë³´ê´€í•˜ëŠ” ê²ƒì´ë‹¤.</li>
  <li>ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ë¶€ë¶„ë“¤ì€ page tableì— í‘œì‹œë˜ì–´ ê°ê° í• ë‹¹ ë°›ì€ frameì— ì˜¬ë¼ê°€ê²Œ ëœë‹¤.</li>
  <li>í•˜ì§€ë§Œ ë§Œì•½ í˜„ì¬ ì‹¤í–‰ ì‹œì ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ì´ ë©”ëª¨ë¦¬ ìƒì— ì¡´ì¬í•˜ì§€ ì•Šê³  ë””ìŠ¤í¬ì— ì¡´ì¬í•˜ì—¬ ì—¬ìœ  frameì´ ì—†ë‹¤ë©´ ë””ìŠ¤í¬ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ swap-out ì‹œí‚¬ victim frameì„ ì°¾ì•„ ë””ìŠ¤í¬ë¡œ ë³´ë‚´ê±°ë‚˜ ë®ì–´ì”Œìš´ í›„ ìƒˆë¡œ ì˜¬ë¦° ë¶€ë¶„ì˜ ëª…ë ¹ì–´ë¥¼ ë‹¤ì‹œ ì‹¤í–‰ì‹œí‚¨ë‹¤.</li>
  <li>ì´ëŸ¬í•œ í˜„ìƒì„ Page Faultë¼ê³  í•˜ë©° CPU ìì› íš¨ìœ¨ì„±ì„ ë–¨ì–´ëœ¨ë¦¬ëŠ” í˜„ìƒ ì¤‘ í•˜ë‚˜ì´ë‹¤. ì™œëƒí•˜ë©´ resourceë¥¼ í• ë‹¹ ë°›ì€ ì‹œê°„ ë‚´ì— CPU ìì›ì„ ì‚¬ìš©í•˜ê¸°ë³´ë‹¤ëŠ” I/O ì‘ì—…ì— ì‹œê°„ì„ ë” ì†Œë¹„í•˜ê¸° ë•Œë¬¸ì´ë‹¤.</li>
  <li>Multi-programmingì€ CPU ìì›ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë³´ë‹¤ ë§ì€ í”„ë¡œì„¸ìŠ¤ì—ê²Œ CPUë¥¼ í• ë‹¹í•´ ì£¼ë©´ì„œ ìì›ì„ ë”ìš± ë°”ì˜ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê¸°ë²•ì´ë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="thrashing-cont">Thrashing (Cont.)</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221123235909542.png" alt="image-20221123235909542" /></p>

<ul>
  <li>í•œì •ëœ ìì› ì•ˆì—ì„œ OSëŠ” efficiencyë¥¼ ë†’ì´ê¸° ìœ„í•´ ë” ë§ì€ processë¥¼ ë™ì‹œì— ì‹¤í–‰ì‹œí‚¤ê¸° ìœ„í•´ì„œ memoryì— <strong>ë§ì€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì˜¬ë¦¬ê²Œ ëœë‹¤.</strong></li>
  <li>ì´ë¡œì¨ CPU utilizationì€ ë†’ì•„ì§€ê¸´ í•˜ì§€ë§Œ ë™ì‹œì— ì‹¤í–‰ ì¤‘ì¸ <strong>process ì˜ ê°œìˆ˜ ìì²´ê°€ ë§ì•„ì§€ê¸° ë•Œë¬¸ì—</strong> ê° í”„ë¡œì„¸ìŠ¤ê°€ í• ë‹¹ë°›ì„ ìˆ˜ ìˆëŠ” ìì›ì˜ ì–‘ì€ ì¤„ì–´ë“¤ ìˆ˜ ë°–ì— ì—†ë‹¤.</li>
  <li>ê·¸ë§ì¸ ì¦‰ìŠ¨, í• ë‹¹ ë°›ì„ ìˆ˜ ìˆëŠ” frameì˜ ìˆ˜ë„ ì¤„ì–´ë“ ë‹¤ëŠ” ëœ»ì¸ë°, frameì˜ ìˆ˜ê°€ ì¤„ì–´ë“¤ë©´ ì•ì„œ ë§í–ˆë˜ ê²ƒì²˜ëŸ¼ ê·¸ ë§Œí¼ page faultê°€ ë§ì´ ë°œìƒí•˜ê²Œ ë˜ê³ , ê·¸ëŸ¬ë©´ ìì›ì˜ í™œìš©ë³´ë‹¨ I/O ì‘ì—…ì— ì‹œê°„ì„ ë” ì†Œë¹„í•˜ê²Œ ëœë‹¤.</li>
  <li>ì´ë ‡ê²Œ ë˜ë©´ í”„ë¡œê·¸ë¨ì˜ ì§„í–‰ì†ë„ëŠ” êµ‰ì¥íˆ ëŠë ¤ì§€ê³  CPU utilization ë˜í•œ êµ‰ì¥íˆ ë–¨ì–´ì§€ê²Œ ëœë‹¤.
    <ul>
      <li>ê·¸ëŸ°ë° ë¬¸ì œëŠ” OSëŠ” ì´ëŸ¬í•œ CPU íš¨ìœ¨ì„±ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ memoryì— í”„ë¡œì„¸ìŠ¤ë¥¼ ë”ìš± ì˜¬ë¦¬ê²Œ ëœë‹¤.(í—‰?)</li>
    </ul>
  </li>
  <li>ì´ëŸ° ì•…ìˆœí™˜ìœ¼ë¡œ ì¸í•´ CPU íš¨ìœ¨ì„±ì€ ê¸°í•˜ ê¸‰ìˆ˜ì ìœ¼ë¡œ ë–¨ì–´ì§€ê²Œ ë˜ê³ (ìœ„ ê·¸ë˜í”„ì™€ ê°™ì´) ê²°êµ­ í”„ë¡œê·¸ë¨ì˜ ë¹„ì •ìƒì ì¸ ì¢…ë£Œë¡œ ì´ì–´ì§€ëŠ”ë°</li>
  <li>ë°”ë¡œ ì´ëŸ° í˜„ìƒì„ Thrasingì´ë¼ê³  í•œë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="thrashing-diagram">Thrashing Diagram</h2>

<ul>
  <li>Why does demand paging work?
    <ul>
      <li>Locality model: Program references cluster(ì§‘í•©) in localities
        <ul>
          <li>gotoë¥¼ ì‚¬ìš©í•˜ë©´ localityë¥¼ ìœ„ë°°í•˜ê¸° ì‰¬ì›€</li>
        </ul>
      </li>
      <li>Locality is set of pages actively being used together</li>
      <li>Once start referring to page within a locality, will continue to refer them for some time</li>
      <li>Process migrates from one locality to another.
        <ul>
          <li>Once locality is exited (stop referring pages in locality), those pages will be referred to in frequently (in near future)</li>
        </ul>
      </li>
      <li>Localities may <strong>overlap</strong>.</li>
    </ul>
  </li>
  <li>Why does thrashing occur?
    <ul>
      <li>âˆ‘ size of locality &gt; total memory size
        <ul>
          <li>Limit effects by using local or priority page replacement</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="locality-in-a-memory-reference-pattern">Locality In A Memory-Reference Pattern</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124000045242.png" alt="image-20221124000045242" /></p>

<ul>
  <li>ì´ëŸ¬í•œ Locality mapì„ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯ì´ í˜„ ì‹œì ì—ì„œë¶€í„° ì¼ì • ì‹œì  ì „ì˜ localityë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ì˜ locality ì˜ì—­ì„ ì¶”ì •í•˜ê²Œ ëœë‹¤.</li>
  <li>ê·¸ë˜ì„œ localityê°€ ë¶„ê¸°ë˜ëŠ” ì‹œì (ì¦‰, localityì˜ ì˜ì—­ì´ ê¸‰ë³€í•˜ëŠ” êµ¬ê°„)ì—ì„œëŠ” ìˆœê°„ì ìœ¼ë¡œ page faultì˜ íšŸìˆ˜ê°€ ì¹˜ì†Ÿê²Œ ë˜ì§€ë§Œ ì‹œê°„ì´ ì§€ë‚  ìˆ˜ë¡ ìˆ˜ì¹˜ëŠ” ì•ˆì •í™” ëœë‹¤.</li>
  <li>ì´ë ‡ë“¯ í˜„ì¬ ì‹œì ìœ¼ë¡œë¶€í„° ê³¼ê±°ì˜ localityë¥¼ ì¸¡ì •í•˜ê²Œ ë  ë•Œ ì´ ì‹œì ì˜ ê°„ê²©ì„ Working set Sizeë¼ê³  í•œë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="working-set-model">Working-Set Model</h2>

<p>ì ì •ì„ ì˜ frame ê°œìˆ˜ê°€ ì–¼ë§ˆë¥¼ ë§í•˜ëŠ” ê²ƒì´ëƒ?</p>

<ul>
  <li>Based on locality</li>
  <li>Strategy :
    <ul>
      <li><strong>prevents thrashing</strong> while keeping the degree of multiprogramming as high as possible</li>
      <li>Increase/decrease # of frames allocated to a job <strong>based on locality</strong></li>
    </ul>
  </li>
  <li>â–³ = working-set window = a fixed number of page references
    <ul>
      <li>Approximate of programâ€™s locality</li>
      <li>Example: 10,000 instruction</li>
    </ul>
  </li>
  <li>WSSi (working set of Process Pi ) = total number of pages referenced in the most recent â–³ (varies in time)
    <ul>
      <li>if â–³ too small will not encompass entire locality, lead too many page faults.</li>
      <li>if â–³ too large will encompass several localities.</li>
      <li>if â–³ = âˆ =&gt; will encompass entire program.</li>
    </ul>
  </li>
  <li>D = âˆ‘ WSSi = total demand frames
    <ul>
      <li>approximation of locality</li>
    </ul>
  </li>
  <li>if D &gt; m =&gt; Thrashing</li>
  <li>Policy if D &gt; m, then suspend one of the processes.</li>
</ul>

<p><br /></p>

<h2 id="working-set-model-1">Working-set model</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124000545018.png" alt="image-20221124000545018" /></p>

<ul>
  <li>10ê°œì˜ pageê°€ reference ë˜ëŠ” ê²ƒì„ working set windowë¡œ ì¡ì•˜ë‹¤.
    <ul>
      <li>10ê°œì˜ pageê°€ reference ë˜ëŠ” ë™ì•ˆ 5ê°œì˜ pageê°€ reference ë˜ì—ˆë‹¤.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="keeping-track-of-the-working-set">Keeping Track of the Working Set</h2>

<ul>
  <li>Approximate with <strong>interval timer</strong> + <strong>a reference bit</strong></li>
  <li>Example: â–³ = 10,000
    <ul>
      <li>Timer interrupts after every 5000 time units.</li>
      <li>Keep in memory 2 bits for each page.</li>
      <li>Whenever a timer interrupts copy and sets the values of all reference bits to 0.</li>
      <li>If one of the bits in memory = 1 =&gt; page in working set.</li>
    </ul>
  </li>
  <li>Why is this not completely accurate?</li>
  <li>Improvement = 10 bits and interrupt every 1000 time units.</li>
  <li>of frames allocated to a job can vary, based on the # of pages in its working set</li>
</ul>

<p><br /></p>

<h2 id="page-fault-frequency-scheme">Page-Fault Frequency Scheme</h2>

<ul>
  <li>More direct approach than WSS</li>
  <li>How to prevent thrashing -&gt; control the page fault rate</li>
  <li>Establish â€œacceptableâ€ page-fault rate &amp; control it.
    <ul>
      <li>If actual rate too low, process loses frame.</li>
      <li>If actual rate too high, process gains frame.</li>
    </ul>
  </li>
  <li>Check for reallocation only when a job experiences a fault</li>
  <li>upper boundì™€ lower bound ì‚¬ì´ì— ì˜ ìˆë„ë¡</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124000710522.png" alt="image-20221124000710522" /></p>

<p><br /></p>

<h2 id="working-sets-and-page-fault-rates">Working Sets and Page Fault Rates</h2>

<ul>
  <li>Direct relationship between working set of a process and its page-fault rate</li>
  <li>Working set changes over time</li>
  <li>Peaks and valleys over time</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124000732898.png" alt="image-20221124000732898" /></p>

<ul>
  <li>We use a â€œuse bitâ€ &amp; â€œclockâ€</li>
  <li>Define some parameter t, length of time</li>
  <li>When a page fault occurs</li>
  <li>if time_since_last_fault &lt;= t then place new page in working set</li>
  <li>else 
mark for reallocation all pages not referenced since last fault</li>
</ul>

<p><br /></p>

<h2 id="process-creation">Process Creation</h2>

<ul>
  <li>Virtual memory allows other benefits during process creation:</li>
  <li>Copy-on-Write</li>
  <li>Memory-Mapped Files</li>
</ul>

<p><br /></p>

<h2 id="memory-mapped-files">Memory-Mapped Files</h2>

<ul>
  <li>File I/O using open(), read(), write() requires system call &amp; disk access
    <ul>
      <li>Open(), read(), write() ì‹œìŠ¤í…œ í˜¸ì¶œì„ ì‚¬ìš©í•˜ì—¬ ë””ìŠ¤í¬ì— ìˆëŠ” íŒŒì¼ì„ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì´ ë§¤ë²ˆ ì ‘ê·¼ë  ë•Œë§ˆë‹¤ ì‹œìŠ¤í…œ í˜¸ì¶œì„ í•´ì•¼ í•˜ê³  ë””ìŠ¤í¬ë¥¼ ì ‘ê·¼í•´ì•¼ í•œë‹¤. ì´ì™€ê°™ì€ ë°©ë²• ëŒ€ì‹  ì…/ì¶œë ¥ì„ ë©”ëª¨ë¦¬ ì°¸ì¡° ë°©ì‹ìœ¼ë¡œ ëŒ€ì‹ í•  ìˆ˜ë„ ìˆë‹¤.</li>
    </ul>
  </li>
  <li>Memory-mapped file I/O allows file I/O to be treated as routine memory access by <strong>mapping</strong> a disk block to a page in memory
    <ul>
      <li>ë©”ëª¨ë¦¬ ë§¤í•‘(memory mapping)ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì ‘ê·¼ ë°©ì‹ì€ í”„ë¡œì„¸ìŠ¤ì˜ ê°€ìƒ ì£¼ì†Œ ê³µê°„ ì¤‘ ì¼ë¶€ë¥¼ ê´€ë ¨ëœ íŒŒì¼ì— í• ì• í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.</li>
    </ul>
  </li>
  <li>A file is initially read using demand paging
    <ul>
      <li>A page-sized portion of the file is read from the file system into a physical page</li>
      <li>Subsequent reads/writes to/from the file are treated as ordinary memory accesses</li>
    </ul>
  </li>
  <li>Simplifies and speeds file access by driving file I/O through memory rather than read() and write() system calls</li>
  <li>Also allows several processes to map the same file allowing the pages in memory to be shared</li>
  <li>But when does written data make it to disk? â€“
    <ul>
      <li>Periodically and / or at file close() time</li>
      <li>For example, when the pager scans for dirty pages</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="memory-mapped-file-technique-for-all-io">Memory-Mapped File Technique for all I/O</h2>

<ul>
  <li>Some OS choose to memory-map a file regardless of whether the file was specified as memory-mapped</li>
  <li>Some OS provide memory mapping only through a specific system call and uses the standard system calls to perform file I/O
    <ul>
      <li>memory mapped files for standard I/O</li>
      <li>In Solaris, process can explicitly request memory mapping a file via mmap() system call</li>
      <li>Now file mapped into process address space</li>
      <li>For standard I/O (open(), read(), write(), close()), mapping file into kernel address space</li>
      <li>Process still does read() and write()
        <ul>
          <li>Copies data to and from kernel space and user space</li>
        </ul>
      </li>
      <li>Uses efficient memory management subsystem
        <ul>
          <li>Avoids needing separate subsystem</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>COW can be used for read/write non-shared pages</li>
</ul>

<p><br /></p>

<h2 id="memory-mapped-files-1">Memory Mapped Files</h2>

<p>Memory mapped files can be used for shared memory (although again via separate system calls)</p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124001024607.png" alt="image-20221124001024607" /></p>

<p><br /></p>

<h2 id="memory-mapped-shared-memory-in-windows">Memory-Mapped Shared Memory in Windows</h2>

<p>ìƒëµ</p>

<p><br /></p>

<h2 id="shared-memory-in-windows-api---ìƒëµ">Shared Memory in Windows API - ìƒëµ</h2>

<ul>
  <li>First create a file mapping for file to be mapped
    <ul>
      <li>Then establish a view of the mapped file in processâ€™s virtual address space</li>
    </ul>
  </li>
  <li>Consider producer / consumer
    <ul>
      <li>Producer create shared-memory object using memory mapping features</li>
      <li>Open file via CreateFile(), returning a HANDLE</li>
      <li>Create mapping via CreateFileMapping() creating a named shared-memory object</li>
      <li>Create view via MapViewOfFile()</li>
    </ul>
  </li>
  <li>Sample code in Textbook</li>
</ul>

<p><br /></p>

<h2 id="memory-compression">Memory Compression</h2>

<ul>
  <li><strong>An alternative to paging</strong></li>
  <li>Rather than paging out modified frames to swap space, <strong>compress</strong> several frames into a single frame, <mark>enabling the system to reduce memory usage without resorting(ì˜ì§€) to swapping pages </mark></li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124001214880.png" alt="image-20221124001214880" /></p>

<p><br /></p>

<h2 id="allocating-kernel-memory">Allocating Kernel Memory</h2>

<ul>
  <li>Treated <strong>differently</strong> from user memory</li>
  <li>Often allocated from a <strong>free-memory pool</strong>
    <ul>
      <li>Kernel requests memory for structures of varying sizes</li>
      <li>Some kernel memory needs to be contiguous
        <ul>
          <li>I.e. for device I/O</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ê²°êµ­ kernelë„ ë©”ëª¨ë¦¬ì— ì¡´ì¬í•˜ê³  ì½”ë“œê°€ ìˆ˜í–‰ë˜ì–´ì•¼ í•˜ëŠ”ë° ì»¤ë„ë„ ë©”ëª¨ë¦¬ í• ë‹¹ì„ ë°›ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë°©ì‹ì— ëŒ€í•´ì„œ ì†Œê°œí•´ ë³´ë„ë¡ í•˜ê² ë‹¤.
    <ul>
      <li>ê·¸ ì „ì— ëŒ€ë¶€ë¶„ kernelì—ì„œì˜ ì½”ë“œë“¤ì€ paging ê¸°ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì™œëƒí•˜ë©´ page-in, page-outê³¼ ê°™ì€ ë™ì‘ì„ í•˜ë©´ ì†ë„ê°€ ëŠë ¤ì§€ê¸° ë•Œë¬¸ì— ì´ê²ƒì´ ì‹œìŠ¤í…œ ì „ì²´ì— ì˜í–¥ì„ ë¯¸ì¹  ì—¬ì§€ê°€ ì¶©ë¶„í•˜ê¸° ë•Œë¬¸ì´ë‹¤.</li>
    </ul>
  </li>
  <li>ê·¸ë˜ì„œ ë‚˜ì˜¨ ë©”ëª¨ë¦¬ í• ë‹¹ ë°©ì‹ì—ëŠ”  Buddy Systemê³¼ Slab Allocatorê°€ ìˆë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="buddy-system---ë™ì‘ì›ë¦¬-ì¤‘ìš”">Buddy System - ë™ì‘ì›ë¦¬ ì¤‘ìš”</h2>

<ul>
  <li>Allocates memory from fixed-size segment consisting of physically-contiguous pages
    <ul>
      <li>ê³ ì •ëœ í¬ê¸°ì˜ segmentë¥¼ í• ë‹¹í•´ ì¤€ë‹¤.</li>
      <li>ê³ ì •ëœ í¬ê¸°ë¼ëŠ” ê²ƒì€ 2ì˜ ì§€ìˆ˜ì„± í¬ê¸°ë¥¼ ê°€ì ¸ì•¼ í•¨ì„ ë§í•œë‹¤.(ìµœì†Œ 4K)</li>
    </ul>
  </li>
  <li>Memory allocated using <strong>power-of-2 allocator</strong>
    <ul>
      <li>Satisfies requests in units sized as power of 2</li>
      <li>Request rounded up to next highest power of 2</li>
      <li>When smaller allocation needed than is available, current chunk split into two buddies of next-lower power of 2
        <ul>
          <li>Continue until appropriate sized chunk available</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>For example, assume 256KB chunk available, kernel requests 21KB
    <ul>
      <li><strong>Split</strong> into A<sub>L</sub> and A<sub>r</sub> of 128KB each
        <ul>
          <li>One further divided into BL and BR of 64KB
            <ul>
              <li>One further into CL and CR of 32KB each â€“ one used to satisfy request</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>ë§Œì•½ 21KBë¥¼ ìš”ì²­í•˜ëŠ”ë° 256KBê°€ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤ë©´ ê·¸ê²ƒì„ 2ê°œë¡œ ê³„ì† ë‚˜ëˆ„ì–´ì„œ ì ë‹¹í•œ í¬ê¸°ë¥¼ í• ë‹¹í•´ ì¤€ë‹¤.</li>
      <li>ê·¸ëŸ°ë° í•œìª½ë§Œ ë‚˜ëˆ ì§€ëŠ” ê²Œ ì•„ë‹ˆë¼ ëª¨ë‘ ì§ì„ ë§ì¶°ì„œ ë‚˜ëˆ ì§„ë‹¤.</li>
    </ul>
  </li>
  <li>Advantage â€“ quickly coalesce unused chunks into larger chunk (í¬ê¸°ê°€ í° ìš”ì²­ì´ ì˜¤ë©´ ì¬ë¹¨ë¦¬ í•©ì³ì„œ ì£¼ë©´ ëœë‹¤.)</li>
  <li>Disadvantage - <strong>fragmentation</strong></li>
</ul>

<p><br /></p>

<h2 id="buddy-system-allocators">Buddy System AllocatorS</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124001505542.png" alt="image-20221124001505542" /></p>

<p><br /></p>

<h2 id="slab-allocator---ë™ì‘ì›ë¦¬-ì¤‘ìš”">Slab Allocator - ë™ì‘ì›ë¦¬ ì¤‘ìš”</h2>

<ul>
  <li>Alternate strategy</li>
  <li><strong>Slab</strong> is one or more physically contiguous pages
    <ul>
      <li>ë¬¼ë¦¬ì ìœ¼ë¡œ ì—°ì†ëœ í•˜ë‚˜ ì´ìƒì˜ í˜ì´ì§€ë¡œ êµ¬ì„±ëœ ì˜ì—­</li>
    </ul>
  </li>
  <li><strong>Cache</strong> consists of one or more slabs
    <ul>
      <li>slabì—ì„œ ì‚¬ìš©í•˜ëŠ” í•˜ë‚˜ì˜ ì„ì‹œ ë³´ê´€ì†Œ ê°œë… (ìš°ë¦¬ê°€ ì•„ëŠ” cache X)</li>
    </ul>
  </li>
  <li>Single cache for each unique kernel data structure
    <ul>
      <li>Each cache filled with <strong>objects</strong> â€“ instantiations of the data structure</li>
    </ul>
  </li>
  <li>When cache created, filled with objects marked as free</li>
  <li>When structures stored, objects marked as used</li>
  <li>If slab is full of used objects, next object allocated from empty slab
    <ul>
      <li>If no empty slabs, new slab allocated</li>
    </ul>
  </li>
  <li>Benefits include <strong>no fragmentation</strong>, fast memory request satisfaction
    <ul>
      <li>ë©”ëª¨ë¦¬ì˜ ê¸°ë³¸ ë‹¨ìœ„ê°€ kernel objectì¸ë° ê·¸ size ë§Œí¼ cacheë¥¼ êµ¬ì„±í•˜ê¸° ë•Œë¬¸ì— fragmentationì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ.</li>
    </ul>
  </li>
  <li>ì •ë¦¬í•˜ìë©´ ì´ ë°©ì‹ì€ ë¯¸ë¦¬ ë‹¤ì–‘í•œ sizeì˜ cacheë¥¼ ë§Œë“¤ì–´ ë†“ëŠ” ê²ƒì´ë‹¤. ì¦‰, í•˜ë‚˜ì˜ kernel data structureì— ëŒ€í•œ ë¹ˆ objectë¥¼ ë§Œë“¤ì–´ ë†“ëŠ” ê²ƒ.</li>
  <li>kernelì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” structureë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë†“ìœ¼ë©´ ìš”ì²­ì´ ìˆì„ ë•Œ ë°”ë¡œë°”ë¡œ í• ë‹¹í•´ ì£¼ë©´ ëœë‹¤. ê·¸ë¦¬ê³  ì‚¬ìš©ì´ ì™„ë£Œë˜ë©´ íšŒìˆ˜í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ í•˜ë©´ êµ‰ì¥íˆ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<p><br /></p>

<h2 id="slab-allocation">Slab Allocation</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124001551700.png" alt="image-20221124001551700" /></p>

<p>ì´ë ‡ê²Œ ë˜ë©´ ë‹¤ì–‘í•œ sizeë¥¼ ë§Œë“¤ì–´ ë†“ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— fragmentationì„ ì¤„ì¼ ìˆ˜ ìˆê³ , ë©”ëª¨ë¦¬ ìš”ì²­ì— ëŒ€í•´ì„œ ë¹¨ë¦¬ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.</p>

<p><br /></p>

<h2 id="slab-allocator-in-linux">Slab Allocator in Linux</h2>

<ul>
  <li>
    <p>For example process descriptor is of type <code class="language-plaintext highlighter-rouge">struct task_struct </code> - PCB</p>
  </li>
  <li>
    <p>Approx 1.7KB of memory</p>
  </li>
  <li>
    <p>New task -&gt; allocate new struct from cache</p>
  </li>
  <li>
    <p>Will use existing free <code class="language-plaintext highlighter-rouge">struct task_struct </code></p>
  </li>
  <li>
    <p>Slab can be in three possible states</p>

    <ol>
      <li>
        <p>Full â€“ all used</p>
      </li>
      <li>
        <p>Empty â€“ all free</p>
      </li>
      <li>
        <p>Partial â€“ mix of free and used</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Upon request, slab allocator</p>

    <ol>
      <li>
        <p>Uses free struct in partial slab</p>
      </li>
      <li>
        <p>If none, takes one from empty slab</p>
      </li>
      <li>
        <p>If no empty slab, create new empty</p>
      </li>
    </ol>
  </li>
</ul>

<p><br /></p>

<h2 id="slab-allocator-in-linux-cont">Slab Allocator in Linux (Cont.)</h2>

<ul>
  <li>Slab started in Solaris, now wide-spread for both kernel mode and user memory in various OSes</li>
  <li>Linux 2.2 had SLAB, now has both SLOB and SLUB allocators
    <ul>
      <li>SLOB for systems with limited memory
        <ul>
          <li>Simple List of Blocks â€“ maintains 3 list objects for small, medium, large objects</li>
        </ul>
      </li>
      <li>SLUB is performance-optimized SLAB removes per-CPU queues, metadata stored in page structure</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-considerations--prepaging">Other Considerations â€“ Prepaging</h2>

<ul>
  <li>Prepaging
    <ul>
      <li>To reduce the large number of page faults that occurs at process startup</li>
      <li>Prepage all or some of the pages a process will need, before they are referenced
        <ul>
          <li>Bring in last working set</li>
        </ul>
      </li>
      <li>But if prepaged pages are unused, I/O and memory was wasted</li>
      <li>Assume s pages are prepaged and Î± of the pages is used
        <ul>
          <li>Is cost of s * Î± save pages faults &gt; or &lt; than the cost of prepaging s * (1- Î±) unnecessary pages?</li>
          <li>Î± near zero =&gt; prepaging loses</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-issues--page-size">Other Issues â€“ Page Size</h2>

<ul>
  <li>Sometimes OS designers have a choice
    <ul>
      <li>Especially if running on custom-built CPU</li>
    </ul>
  </li>
  <li>Page size selection must take into consideration:
    <ul>
      <li>Memory utilization : favors small page, internal fragmentation</li>
      <li>Page table size : : favors larger pages (fewer entries)</li>
      <li><strong>Resolution</strong></li>
      <li>I/O overhead
        <ul>
          <li>Transfer once located pages relatively fast
            <ul>
              <li>favor large pages</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Number of page faults: : favor larger pages</li>
      <li>Locality
        <ul>
          <li>Favors small pages because
            <ul>
              <li>Better estimate of locality</li>
              <li>Remind portions job which are not being used</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>TLB size and effectiveness</li>
    </ul>
  </li>
  <li>Always power of 2, usually in the range 2<sup>12</sup> (4,096 bytes) to 2<sup>22</sup> (4,194,304 bytes)</li>
  <li>On average, growing over time</li>
</ul>

<p><br /></p>

<h2 id="other-issues--tlb-reach">Other Issues â€“ TLB Reach</h2>

<ul>
  <li>TLB Reach - The amount of memory accessible from the TLB</li>
  <li>TLB Reach = (TLB Size) X (Page Size)</li>
  <li>Ideally, the working set of each process is stored in the TLB
    <ul>
      <li>Otherwise there is a high degree of page faults</li>
    </ul>
  </li>
  <li>Increase the Page Size
    <ul>
      <li>This may lead to an increase in fragmentation as not all applications require a large page size</li>
    </ul>
  </li>
  <li>Provide Multiple Page Sizes
    <ul>
      <li>This allows applications that require larger page sizes the opportunity to use them without an increase in fragmentation</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-considerations">Other Considerations</h2>

<ul>
  <li>How many pages allocated to a job?
    <ul>
      <li>Minimum is related to architecture
        <ul>
          <li>PDP-8: at most 1 memory address in an instruction
            <ul>
              <li>1 page instruction, 2 page operand (indirection) -&gt; 3 page</li>
            </ul>
          </li>
          <li>PDP-11
            <ul>
              <li>2 memory addresses in instruction</li>
              <li>Instruction could be 2 or 3 words long
                <ul>
                  <li>Â» 2 pages for instruction, 4 pages for operands
                    <ul>
                      <li>=&gt; 6 pages</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-consideration-cont">Other Consideration (Cont.)</h2>

<ul>
  <li>Thrashing
    <ul>
      <li>More time spent moving pages in &amp; out of memory than doing actual work</li>
      <li>Occurs when too few frames allocated to job</li>
      <li>Situation can be made worse by CPU scheduling strategy
        <ul>
          <li>Since jobs in I/O queue when waiting for pages, CPU can become under-utilized</li>
          <li>More jobs can be brought into system, further degrading performance</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Too many pages
    <ul>
      <li>It is possible to have too low fault rate</li>
      <li>Memory. CPU under-utilized</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-consideration-cont---xxxx">Other Consideration (Cont.) - XXXX</h2>

<ul>
  <li>Page size selection
    <ul>
      <li>table size : favors larger pages (fewer entries)</li>
      <li>Memory utilization: favors small page, internal fragmentation</li>
      <li>I/O overhead
        <ul>
          <li>Transfer once located pages relatively fast</li>
        </ul>
      </li>
      <li>favor large pages</li>
      <li>Locality
        <ul>
          <li>Favors small pages because
            <ul>
              <li>Better estimate of locality</li>
              <li>Remind portions job which are not being used</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Page fault : favor larger pages â€¢</li>
    </ul>
  </li>
  <li>Trend is toward larger page size
    <ul>
      <li>Cpu speed, MM increasing faster than disk speed</li>
      <li>Page faults are more costly today</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="other-consideration-cont-1">Other Consideration (Cont.)</h2>

<ul>
  <li>Program structure</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124002349853.png" alt="image-20221124002349853" /></p>

<p><br /></p>

<h2 id="other-issues--io-interlock---xxxx">Other Issues â€“ I/O interlock - XXXX</h2>

<ul>
  <li>I/O interlock and addressing</li>
  <li>Consider I/O - Pages that are used for copying a file from a device must be locked from being selected for eviction by a page replacement algorithm
    <ul>
      <li>** When demand paging is used, we sometimes need to allow some of the pages to be locked in memory</li>
      <li>A process issues an I/O request, and is put in a queue for that I/O device</li>
      <li>Meanwhile CPU is given to other processes</li>
      <li>These processes cause page fault, uses global replacement</li>
      <li>One of them replaces the page containing the memory buffer for the waiting process</li>
      <li>The pages are paged out</li>
      <li>Later, when the I/O request advances to the head of the device queue, I/O occurs to the specified address</li>
      <li>However, this frame belongs to another process</li>
    </ul>
  </li>
  <li>Solution
    <ul>
      <li>Never to execute I/O to user memory: copy overhead (system memory, I/O device)</li>
      <li>Allow pages to be locked into memory : do not select for replacement</li>
    </ul>
  </li>
  <li>Between high &amp; low priority processes</li>
</ul>

<p><br /></p>

<h2 id="reason-why-frames-used-for-io-must-be-in-memory---xxxx">Reason Why Frames Used For I/O Must Be In Memory - XXXX</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221124002457581.png" alt="image-20221124002457581" /></p>

<p><br /></p>

<h2 id="demand-segmentation---xxxx">Demand Segmentation - XXXX</h2>

<ul>
  <li>Demand paging is the most efficient virtual memory system</li>
  <li>Used when insufficient hardware to implement demand paging.
    <ul>
      <li>Intel 80286 does not include paging features, but does have segments</li>
    </ul>
  </li>
  <li>OS/2 allocates memory in segments, which it keeps track of through segment descriptors</li>
  <li>Segment descriptor contains a valid bit to indicate whether the segment is currently in memory.
    <ul>
      <li>If segment is in main memory, access continues,</li>
      <li>If not in memory, segment fault.</li>
    </ul>
  </li>
</ul>
:ET