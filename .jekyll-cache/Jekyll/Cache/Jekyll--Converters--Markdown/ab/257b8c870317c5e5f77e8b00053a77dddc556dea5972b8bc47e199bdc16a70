I"TP<p>1, 2 장 출제 x (참고자료로 사용) - 여기까지 시험범위</p>

<p>[toc]</p>

<h1 id="chapter-5-cpu-scheduling">Chapter 5: CPU Scheduling</h1>

<ul>
  <li>Basic Concepts</li>
  <li>Scheduling Criteria</li>
  <li>Scheduling Algorithms</li>
  <li>Thread Scheduling</li>
  <li>Multiple-Processor Scheduling</li>
  <li>Real-Time CPU Scheduling</li>
  <li>Operating Systems Examples</li>
  <li>Algorithm Evaluation</li>
</ul>

<p><br /></p>

<h2 id="objectives">Objectives</h2>

<ul>
  <li>To introduce <strong>CPU scheduling</strong>, which is the basis for multiprogrammed operating systems</li>
  <li>To describe various CPU-scheduling algorithms</li>
  <li>To discuss evaluation criteria for selecting a CPU-scheduling algorithm for a particular system</li>
  <li>To examine the scheduling algorithms of several operating systems</li>
</ul>

<p><br /></p>

<h2 id="basic-concepts">Basic Concepts</h2>

<ul>
  <li>목적: <strong>Maximum CPU utilization</strong> obtained with multiprogramming <span style="color:green">(시험)</span>
    <ul>
      <li>When one process has to wait, OS takes the CPU away from that process and gives the CPU to another process</li>
    </ul>
  </li>
  <li>The success of CPU scheduling depends on the property
    <ul>
      <li>CPU – I/O Burst Cycle</li>
      <li>Process execution consists of a cycle of CPU execution and I/O wait.
        <ul>
          <li>Process execution begins with CPU burst</li>
          <li>Process execution ends with CPU burst</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>CPU burst distribution
    <ul>
      <li>An I/O bound program typically have many very short CPU burst</li>
      <li>A CPU bound program might have a few very long CPU burst</li>
      <li>Distribution can be important in the selection of an appropriate CPU scheduling algorithms</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="alternating-sequence-of-cpu-and-io-bursts">Alternating Sequence of CPU And I/O Bursts</h2>

<ul>
  <li>Maximum CPU utilization obtained with multiprogramming</li>
  <li>CPU–I/O Burst Cycle – Process  execution consists of a cycle of  CPU execution and I/O wait</li>
  <li>CPU burst followed by I/O burst</li>
  <li>CPU burst distribution is of main concern</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151336894.png" alt="image-20220927151336894" /></p>

<p><br /></p>

<h2 id="histogram-of-cpu-burst-times">Histogram of CPU-burst Times</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151354687.png" alt="image-20220927151354687" /></p>

<p>짧은 CPU burst가 많다. -&gt; multi program이 성공할 수 있는 근거</p>

<p><br /></p>

<h2 id="cpu-schedulershort-term-scheduler중요시험">CPU Scheduler(short-term scheduler)(중요)<span style="color:green">(시험)</span></h2>

<ul>
  <li><strong>Short-term scheduler</strong> selects from among the processes in memory that are ready to execute, and allocates the CPU to one of them.
    <ul>
      <li>Queue may be ordered in various ways</li>
      <li><strong>Ready queue</strong> may be implemented as FIFO Q, priority Q, tree, linked list</li>
    </ul>
  </li>
  <li>The records in the q are generally PCBs of the processes</li>
  <li>CPU scheduling decisions may take place when a process:
    <ol>
      <li>Switches from <strong>running</strong> to <strong>waiting</strong> state.</li>
      <li>Switches from <strong>running</strong> to <strong>ready</strong> state.</li>
      <li>Switches from <strong>waiting</strong> to <strong>ready</strong>. (우선순위가 높은 프로세스의 경우 waiting에서 running으로 갈 여지도 있음)</li>
      <li><strong>Terminates</strong>.</li>
    </ol>
  </li>
  <li>Scheduling under 1 and 4 is nonpreemptive.
    <ul>
      <li>스스로 끝났거나 waiting으로 갔기 때문에</li>
    </ul>
  </li>
  <li>Preemptive scheduling is possible under 2 and 3
    <ul>
      <li>하지만 고려사항이 있음
        <ul>
          <li>Consider access to shared data (data consistency)</li>
          <li>Consider preemption while in kernel mode (kernel data의 protection)</li>
          <li>Consider interrupts occurring during crucial OS activities</li>
        </ul>
      </li>
      <li>2번 runnung -&gt; ready : time quantum으로 강제로 CPU를 뺏기 때문</li>
      <li>waiting에서 event가 completion이 되었다면 running을 해야 하는데 ready를 거쳤다가 가게된다.
        <ul>
          <li>이때, 해당 process가 우선순위가 굉장히 높다면 설령 ready queue에 여러 다른 프로세스가 있어도 곧바로 running으로 갈 수 있는 여지도 있다.</li>
          <li>즉, 우선순위가 무지하게 높은 프로세스가 waiting이 끝나서 ready로 가는 경우 preemption이 일어난다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="preemptive-vs-non-preemptive-scheduling">Preemptive vs. Non-preemptive scheduling</h2>

<ul>
  <li>Non-Preemptive scheduling
    <ul>
      <li>Once the CPU has been allocated to a process, the process  keeps the CPU until it release the CPU either
        <ul>
          <li>by terminating or</li>
          <li>by switching to the waiting state</li>
        </ul>
      </li>
      <li>Windows 3.1 Apple Mach OS</li>
    </ul>
  </li>
  <li>Preemptive scheduling
    <ul>
      <li>Case of two processes sharing data</li>
      <li>Design of Kernel
        <ul>
          <li>During the process of system call
            <ul>
              <li>UNIX waits either <strong>for a system call to complete</strong> or <strong>for I/O block take place before doing a context switch</strong></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="dispatcher">Dispatcher</h2>

<ul>
  <li>Dispatcher module gives control of the CPU to the process selected by the short-term scheduler; this involves:
    <ul>
      <li>switching context (by OS)
        <ul>
          <li>context가 바뀔 때 해당 process가 block 되면서 남긴 running snapshot 정보를 PCB에 저장해 두었다가 다시 실행 될 때 해당 running snapshot을 복원하여 실행된다.</li>
        </ul>
      </li>
      <li>switching to user mode</li>
      <li>jumping to the proper location in the user program to restart that program</li>
    </ul>
  </li>
  <li>Dispatch latency – time it takes for the dispatcher to stop one process and start another running.
    <ul>
      <li>real-time processing을 할 때, 이를 최소화 시키는 것이 중요함.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="scheduling-criteria뭐가-더-좋은지를-비교할-수-있는-기준">Scheduling Criteria(뭐가 더 좋은지를 비교할 수 있는 기준)</h2>

<ul>
  <li>Different algorithms have different properties which may favor 1 class of  process over another
    <ul>
      <li>Need criteria to measure performance of various algorithms</li>
      <li>목적에 따라 다른 기준 적용</li>
    </ul>
  </li>
  <li>CPU utilization – keep the CPU as busy as possible <span style="color:green">(시험)</span>
    <ul>
      <li>Percentage of time CPU is busy
        <ul>
          <li>0~100 % CPU <strong>overload</strong>(100), too many waiting jobs
            <ul>
              <li>0: CPU가 사용자 process는 사용하지 않고 오직 OS만</li>
              <li>100: OS는 실행이 안되고 사용자 process만 계속해서 실행됨.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Throughput – # of processes that complete their execution per time unit
    <ul>
      <li>단위 시간당 얼마나 많은 process가 실행되었는지</li>
      <li><strong>Size of job affect throughput</strong></li>
    </ul>
  </li>
  <li>Turnaround time – amount of time to execute a particular process (<strong>running + waiting,</strong> not ready)<span style="color:green">(시험)</span>
    <ul>
      <li>N개의 job을 실행하는 데 걸린 총 시간</li>
      <li>process가 실행되고나서 종료될 때까지의 시간</li>
      <li>Total waiting time at all queues &amp; execution time (batch?)
        <ul>
          <li>execution time: running state에서 머문 시간</li>
          <li>total waiting time at all queues: waiting state에서 머문 시간</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Waiting time
    <ul>
      <li>amount of time a process has been waiting <strong>in the ready</strong>,
        <ul>
          <li><mark>waiting time은 ready에서 머문 시간!!!!!!!!!!!!!</mark></li>
          <li>ready는 실행을 하고 싶은데 못하고 있는 상황이기 때문에</li>
        </ul>
      </li>
      <li>CPU scheduling alg. Does not affect the amount of time during which a process executes or does I/O
        <ul>
          <li>CPU scheduling 알고리즘이 ready queue에서 대기한 시간에는 영향을 주지만 running 상태나 waiting 상태에서 머문 시간에는 아무런 영향도 주지 않는다.</li>
        </ul>
      </li>
      <li>It affects only the amount of time that a process spends waiting in the  Ready Q</li>
    </ul>
  </li>
  <li>Response time – amount of time it takes from when a request was submitted until the first response is produced, not output (for time-sharing environment)
    <ul>
      <li>프로세스 요청(실행 요구)된 순간부터 사용자가 응답을 받은 딱 그 순간까지 걸린 시간</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="optimization-criteria">Optimization Criteria</h2>

<ul>
  <li>Max CPU utilization</li>
  <li>Max throughput</li>
  <li>Min turnaround time</li>
  <li>Min waiting time</li>
  <li>Min response time</li>
  <li><strong>Fairness</strong>
    <ul>
      <li>No particular job should be overly penalized(피해를 받는) through CPU  scheduling</li>
      <li>리눅스의 aging 기법과 같은 애가 이를 해결함.(일정 시간이 지날수록 우선순위가 점점 높아짐)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="scheduling-wo-multiprogramming">Scheduling w/o Multiprogramming</h2>

<ul>
  <li>Process A, B : each job requires 4 sec CPU time</li>
  <li>Assuming each exhibit following behavior
    <ul>
      <li>CPU burst 1sec, I/O burst 1 sec -&gt; 완전히 실행되기 위해선 4sec CPU burst, 3 sec I/O burst 필요</li>
      <li>Strategy: 1 job run to completion</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151918471.png" alt="image-20220927151918471" /></p>

<ul>
  <li>CPU utilization = busy time / total = 8/14 = 57 %</li>
  <li>Throughput = 2 jobs/ 14 secs = 1/7</li>
  <li>Turnaround time</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151937774.png" alt="image-20220927151937774" /></p>

<p><br /></p>

<h2 id="scheduling-with-multiprogramming">Scheduling with Multiprogramming</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151959948.png" alt="image-20220927151959948" /></p>

<ul>
  <li>Throughput = 1/4 (not 1/7, 위 사진에서 오타남)</li>
</ul>

<p><br /></p>

<h2 id="scheduling-types">Scheduling Types</h2>

<ul>
  <li>Non Preemptive (internal stimulus)
    <ul>
      <li>Job allocated CPU and can remain an CPU until
        <ul>
          <li>Completes, I/O request, System call</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Preemptive (external stimulus)
    <ul>
      <li>A job on CPU can be removed (at any time) and replaced with <strong>another user process</strong></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="first-come-first-servedfcfs-scheduling">First-Come, First-Served(FCFS) Scheduling</h2>

<ul>
  <li>Non-preemptive</li>
  <li>Jobs are given time on CPU in order in which request in (ready queue)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152101148.png" alt="image-20220927152101148" /></p>

<ul>
  <li>Suppose that the processes arrive in the order: P1 , P2 , P3  The Gantt Chart for the schedule is:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152113269.png" alt="image-20220927152113269" /></p>

<ul>
  <li>Waiting time for P1 = 0; P2 = 24; P3 = 27
    <ul>
      <li>Average waiting time: (0 + 24 + 27)/3 = 17</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="fcfs-scheduling-cont">FCFS Scheduling (Cont.)</h2>

<p><strong>Suppose</strong> that the processes arrive in the order P2 , P3 , P1 .</p>

<ul>
  <li>The Gantt chart for the schedule is:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152157395.png" alt="image-20220927152157395" /></p>

<ul>
  <li>Waiting time for P1 = 6; P2 = 0; P3 = 3
    <ul>
      <li>Average waiting time: (6 + 0 + 3)/3 = 3</li>
    </ul>
  </li>
  <li>Much better than previous case.</li>
  <li><strong>Convoy effect</strong> - short process behind long process
    <ul>
      <li>short process가 long process 뒤에 서있는 효과</li>
      <li>쇼핑카트에 물건이 많은 사람이 맨 앞에 서있으면 오래 걸림.</li>
    </ul>
  </li>
  <li>CPU bound job may benefit
    <ul>
      <li>CPU utilization이 높아지기 때문에</li>
    </ul>
  </li>
  <li>I/O bound may be penalized
    <ul>
      <li>waiting 시간이 길어지기 때문에</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="fcfs-scheduling-cont-1">FCFS Scheduling (Cont.)</h2>

<ul>
  <li>Problem
    <ul>
      <li>Wide variance in turnaround time  <span style="color:green">(시험)</span></li>
      <li>Suceptible(민감) to convoy effect</li>
      <li>Bad for small jobs</li>
      <li>Troublesome for timesharing system</li>
    </ul>
  </li>
  <li>Advantage
    <ul>
      <li>Easy to implement</li>
      <li>Fast (to pick next job to run)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="shortest-job-first-sjf-scheduling">Shortest-Job-First (SJF) Scheduling</h2>

<ul>
  <li>Associate with each process the length of its next CPU burst.
    <ul>
      <li>Use these lengths to schedule the process with the shortest time.</li>
      <li>Ready list is sorted in increasing order</li>
    </ul>
  </li>
  <li>Two schemes:
    <ul>
      <li><strong>Non-preemptive</strong>
        <ul>
          <li>once CPU given to the process it cannot be  preempted until completes its CPU burst.</li>
        </ul>
      </li>
      <li>Preemptive
        <ul>
          <li>if a new process arrives with CPU burst length <strong>less than remaining time of current executing process</strong>, preempt(뺏는다.).</li>
          <li>This scheme is known as the  Shortest-Remaining-Time-First (SRTF).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>SJF is optimal – gives minimum average waiting time for a given set of processes.
    <ul>
      <li>The difficulty is knowing the length of the next CPU request</li>
      <li><strong>How to know length of the next CPU burst?</strong> -&gt; Could ask the user(정확도가 좀 떨어짐)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="example-of-non-preemptive-sjf">Example of Non-Preemptive SJF</h2>

<p>이해를 위해 실제로 그럴 확률은 적지만 I/O burst가 없는 상황을 예로 보겠다.</p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152353544.png" alt="image-20220927152353544" /></p>

<ul>
  <li>
    <p>SJF (non-preemptive)</p>
  </li>
  <li>
    <p>P2가 먼저 왔더라도 P1이 실행된 이후에 Burst time을 따져봤을 때 P3가 더 짧기 때문에 먼저 실행한다.</p>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152405017.png" alt="image-20220927152405017" /></p>

<ul>
  <li>Average waiting time = (0 + 6 + 3 + 7)/4 = 4</li>
</ul>

<p><br /></p>

<h2 id="example-of-preempitve-sjf">Example of Preempitve SJF</h2>

<p><mark>아래 차트 그리는 문제 나올 듯</mark></p>

<p>앞과 같은 예제 - preemptive 버전</p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152427425.png" alt="image-20220927152427425" /></p>

<ul>
  <li>SJF (preemptive)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152440692.png" alt="image-20220927152440692" /></p>

<ul>
  <li>running 상태에 진입을 했어도 preemption 조건이 만족되면 preempt를 실행한다.
    <ul>
      <li>P1은 0초에 도착하여 P1 밖에 없으므로 실행을 하다가 2초가 되었을 때 P2가 도착하는데 이 때 P1의 남은 Burst Time은 5초이고 P2는 4초이므로 preemption을 진행하여 P2가 CPU를 빼앗아 실행을 진행한다.</li>
    </ul>
  </li>
  <li>Average waiting time = (9 + 1 + 0 + 2) / 4 = 3</li>
</ul>

<p><br /></p>

<h2 id="example-of-shortest-remaining-time-first">Example of Shortest-remaining-time-first</h2>

<ul>
  <li>Now we add the concepts of varying arrival times and preemption to  the analysis</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152507314.png" alt="image-20220927152507314" /></p>

<ul>
  <li>Preemptive SJF Gantt Chart</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152518038.png" alt="image-20220927152518038" /></p>

<ul>
  <li>Average waiting time = [(10-1)+(1-1)+(17-2)+5-3)]/4 = 26/4 = 6.5 msec</li>
</ul>

<p><br /></p>

<h2 id="problem">problem</h2>

<ul>
  <li>Starvation  -  프로세스가 끊임없이 필요한 컴퓨터 자원을 가져오지 못하는 상황
    <ul>
      <li>fairness 문제</li>
      <li>The granting of service to particular job is postponed forever</li>
      <li>Infinite wait</li>
      <li>Ex) job A 20
        <ul>
          <li>B 3</li>
          <li>C 3 …</li>
          <li>A가 너무 길어서 다른 프로세스가 올 때마다 다른 프로세스를 실행하느라 A를 계속 실행을 못하게 됨</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="determining-length-of-next-cpu-burst">Determining Length of Next CPU Burst</h2>

<ul>
  <li>Although SJF is optimal, it <strong>can not be implemented</strong>.
    <ul>
      <li>There is <strong>no way to know</strong> the length of the next CPU burst</li>
      <li>Can only predict the length.</li>
    </ul>
  </li>
  <li>The next CPU burst is <strong>predicted</strong> as an exponential average of the  measured lengths of previous CPU burst</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152732740.png" alt="image-20220927152732740" /></p>

<ul>
  <li>Commonly, α set to ½</li>
</ul>

<p><br /></p>

<h2 id="examples-of-exponential-averaging">Examples of Exponential Averaging</h2>

<ul>
  <li>α =0
    <ul>
      <li>tau<sub>n+1</sub> = tau<sub>n</sub></li>
      <li>Recent history does not count.</li>
      <li>Current conditions are assumed to be transient</li>
    </ul>
  </li>
  <li>α =1
    <ul>
      <li>tau<sub>n+1</sub> = t<sub>n</sub></li>
      <li>전에 실행되었던 실측치 만으로 tau_n+1 을 결정</li>
      <li>Only the actual last CPU burst counts.</li>
      <li>History is assumed to be <strong>old</strong> and <strong>irrelevant</strong> (Fig. 5.3 α =0.5)</li>
    </ul>
  </li>
  <li>If we expand the formula, we get:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152922082.png" alt="image-20220927152922082" /></p>

<ul>
  <li>Since both α and (1 - α) are less than or equal to 1, each successive term has less weight than its predecessor
    <ul>
      <li>그 전보다 낮은 weight를 가지게 됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="prediction-of-the-length-of-the-next-cpu-burst">Prediction of the Length of the Next CPU Burst</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153000704.png" alt="image-20220927153000704" /></p>

<p>tau가 실측치 t에 거의 근사한 모습이다.</p>

<p><br /></p>

<h2 id="priority-scheduling">Priority Scheduling</h2>

<ul>
  <li>A <strong>priority</strong> number (임의로 주어진 integer) is associated with <strong>each process</strong>
    <ul>
      <li>SJF와는 조금 다름(SJF는 next CPU burst time만으로 결정)</li>
      <li>PS는 각 process에게 주어진 priority number로 결정</li>
    </ul>
  </li>
  <li>The CPU is allocated to the process with the highest priority  (smallest integer = highest priority).
    <ul>
      <li>Preemptive
        <ul>
          <li>Control the length of time a job is on CPU</li>
          <li>실행 중간에 자기보다 우선순위가 높은 애가 생기면 뺏김.</li>
        </ul>
      </li>
      <li>Non-preemptive</li>
    </ul>
  </li>
  <li>SJF is a priority scheduling where priority is the predicted next CPU burst time.</li>
  <li>Problem define = Starvation –&gt; low priority processes may never execute.</li>
  <li><strong>Solution</strong> define =  <strong>Aging</strong> –&gt; as time progresses, increase the priority of the  process
    <ul>
      <li>ready queue에 머문 시간이 길어질 수록 priority가 높아짐</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="example-of-priority-scheduling">Example of Priority Scheduling</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153130274.png" alt="image-20220927153130274" /></p>

<ul>
  <li>Priority scheduling Gantt Chart</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153142972.png" alt="image-20220927153142972" /></p>

<ul>
  <li>Average waiting time = 41/5 = 8.2 msec</li>
</ul>

<p><br /></p>

<h2 id="round-robin-rr">Round Robin (RR)</h2>

<ul>
  <li>Designed for time sharing systems</li>
  <li>Each process gets a small unit of CPU time (<strong>time quantum</strong>), usually 10-100 milliseconds.  After this time has elapsed, the process is preempted and added to the <strong>end</strong> of the ready  queue.
    <ul>
      <li>time quantum: running state에서 머무를 수 있는 최대 시간</li>
    </ul>
  </li>
  <li>If there are n processes in the ready queue and the time quantum is q, then each  process gets 1/n of the CPU time in chunks of at most q time units at once. <mark>No process  waits more than (n-1)q time units. </mark>
    <ul>
      <li><strong>fairness 보장</strong>하는 방식!!!</li>
    </ul>
  </li>
  <li>Performance of RR <strong>depends</strong> heavily on the <strong>size of Time Quantum</strong>
    <ul>
      <li>q large =&gt; FIFO
        <ul>
          <li>Good for CPU bound, bad for interactive job</li>
          <li>Less context switch</li>
        </ul>
      </li>
      <li>q small =&gt;
        <ul>
          <li>Processor sharing
            <ul>
              <li>Appears(착각) to user as though each of n processes has its own processor running at 1/n the speed of real processor</li>
            </ul>
          </li>
          <li>q must be large with respect to context switch, otherwise overhead is too high.
            <ul>
              <li>context switching을 너무 자주 하면서 생기는 overhead</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="example-rr-with-time-quantum--20">Example: RR with Time Quantum = 20</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153348488.png" alt="image-20220927153348488" /></p>

<ul>
  <li>The Gantt chart is:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153357582.png" alt="image-20220927153357582" /></p>

<ul>
  <li>P2는 burst time이 17이라 20이라는 time quantum을 다 사용하지 않고 마무리됨</li>
  <li>Typically, <strong>higher average turnaround</strong> than SJF, <strong>but better response</strong>.</li>
  <li>q should be large compared to context switch time</li>
  <li>q usually 10ms to 100ms, context switch &lt; 10 usec</li>
</ul>

<p><br /></p>

<h2 id="how-a-smaller-time-quantum-increases-context-switches">How a Smaller Time Quantum Increases Context Switches</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153433105.png" alt="image-20220927153433105" /></p>

<p>high time quantum makes overhead</p>

<p><br /></p>

<h2 id="turnaround-time-varies-with-the-time-quantum">Turnaround Time Varies With The Time Quantum</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153457114.png" alt="image-20220927153457114" /></p>

<p>올바른 time quantum 값을 정하기 어려움(비례하거나 반비례하지 않음)</p>

<p><br /></p>

<h2 id="mulitilevel-queue-scheduling">Mulitilevel Queue Scheduling</h2>

<ul>
  <li><strong>Ready queue is partitioned</strong> into separate <strong>queues</strong>: 
foreground (interactive) 
background (batch)</li>
  <li>Process permanently in a given queue</li>
  <li>Each queue has its own scheduling algorithm,
    <ul>
      <li><strong>foreground – RR (Round Robin)</strong></li>
      <li><strong>background – FCFS (First come First served)</strong></li>
    </ul>
  </li>
  <li>Scheduling must be done between the queues.
    <ul>
      <li>Fixed priority preemptive scheduling;
        <ul>
          <li>i.e., serve all from  foreground then from background.  (foreground에 하나라도 있으면 그거먼저(preemption) scheduling)</li>
          <li>Possibility of starvation.</li>
        </ul>
      </li>
      <li>Time slice – each queue gets a certain amount of CPU time  which it can schedule amongst its processes; i.e., 80% to foreground in RR, 20% to background in FCFS
        <ul>
          <li>starvation reduces</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multilevel-queue-scheduling">Multilevel Queue Scheduling</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153552854.png" alt="image-20220927153552854" /></p>

<p><br /></p>

<h2 id="multilevel-feedback-queue-scheduling">Multilevel Feedback Queue Scheduling</h2>

<p>feedback을 허용하는 방식</p>

<ul>
  <li><strong>In a Multi-level queue</strong> scheduling, processes are permanently assigned to a queue on entry to the system (queue 간의 이동을 금지)
    <ul>
      <li>Processes do not move between queues</li>
    </ul>
  </li>
  <li>A process can move between the various queues;
    <ul>
      <li>If a process uses too much CPU time, it will be moved to a lower priority queue</li>
      <li>A process that waits too long in a lower priority queue may be moved  to a higher priority queue
        <ul>
          <li>aging can be implemented this way. (prevents starvation)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Multilevel-feedback-queue scheduler defined by the following parameters:
    <ul>
      <li>number of queues</li>
      <li>scheduling algorithms for each queue</li>
      <li>method used to determine when to upgrade a process</li>
      <li>method used to determine when to demote a process</li>
      <li>method used to determine which queue a process will enter when that  process needs service
        <ul>
          <li>I/O bound or interactive processes to the higher priority q</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multilevel-feedback-queues">Multilevel Feedback Queues</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153706500.png" alt="image-20220927153706500" /></p>

<p>interactive 성격을 띠는 process는 CPU burst time이 짧기 때문에 quantum 값을 작게 준다.</p>

<ul>
  <li>아래로 갈 수록 우선순위가 낮은 큐</li>
</ul>

<p>우선순위가 낮아질 수록 quantum 값을 크게 줌.</p>

<p>FCFS는 time quantum이 존재하지 않는다.</p>

<ul>
  <li>사용할 수 있다면 CPU time을 만들어 바로 사용할 수 있는 방식이기 때문에</li>
</ul>

<p><br /></p>

<h2 id="example-of-multilevel-feedback-queue">Example of Multilevel Feedback Queue</h2>

<ul>
  <li>Three queues:
    <ul>
      <li>Q0 – RR, time quantum 8 milliseconds</li>
      <li>Q1 – RR, time quantum 16 milliseconds</li>
      <li>Q2 – FCFS</li>
    </ul>
  </li>
  <li>Scheduling
    <ul>
      <li>A new job enters queue Q0 which is served FCFS.
        <ul>
          <li>When it gains CPU, job receives 8 milliseconds.</li>
          <li>If it does not finish in 8 milliseconds, job is moved to queue Q1 .</li>
        </ul>
      </li>
      <li>At Q1 job is again served FCFS and receives 16 additional milliseconds.
        <ul>
          <li>If it still does not complete, it is preempted and moved to queue Q2</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>우선순위가 높은 곳에서도 안 끝나면 넌 낮은데로 가버렷! 그래도 안 끝나면 넌 FCFS로 가버렷!(무조건 끝나게)</li>
</ul>

<p><br /></p>

<h2 id="review-scheduler-activations">Review: Scheduler Activations</h2>

<ul>
  <li>Communication between kernel and <strong>thread library</strong>
    <ul>
      <li>Both M:M and Two-level models require communication to maintain the appropriate number of  kernel threads allocated to the application</li>
      <li>This communication allows an application to maintain  the correct number kernel threads for performance</li>
    </ul>
  </li>
  <li>Typically use an intermediate data structure between user  and kernel threads - <strong>lightweight process (LWP)</strong> : 자료구조의 일종(유저스레드와 커널스레드에 mapping 정보를 담는)
    <ul>
      <li>한 애플리케이션에서 사용될 커널 스레드의 갯수를 타협하는 애</li>
      <li>Appears to be a virtual processor on which process  can schedule user thread to run</li>
      <li>Each LWP attached to kernel thread</li>
      <li>OS schedules kernel threads to run on a physical  processor</li>
      <li>If a kernel thread blocks, LWP blocks, and user-level  thread attached to LWP also blocks</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154038193.png" alt="image-20220927154038193" /></p>

<ul>
  <li>OS의 CPU scheduler가 하는 결정: 여러 개 커널 thread 중에서 어떤 커널 thread가 먼저 실행 될지
    <ul>
      <li>CPU에 의해서 실행되기 때문에 kernel thread라고 불리는 것.</li>
    </ul>
  </li>
  <li>user level(<mark>thread library</mark>)하는 결정: 어떤 user thread가 LWP에 할당될 것인가</li>
</ul>

<p><br /></p>

<h2 id="review-scheduler-activations-1">Review: Scheduler Activations</h2>

<p>How many LWPs(i.e., kernel thread) to create? (for user thread)</p>

<ul>
  <li>CPU-bound application running on a processor:
    <ul>
      <li>only one thread can run at a time, so one LWP is sufficient</li>
      <li>Other type of application may require multiple LWPs (concurrent threads)</li>
    </ul>
  </li>
  <li>An LWP is required for each concurrent blocking system call</li>
  <li>Scheduler activations
    <ul>
      <li>a communication mechanism from the kernel to the thread library</li>
      <li>Kernel provides an application with a set of LWPs</li>
      <li>Kernel must inform an application about certain events (upcall)
        <ul>
          <li>Ex: <strong>notify which application thread is about to block</strong> -&gt; 그럼 다른 유저스레드 할당할 수 있겠네??</li>
          <li>Upcalls are handled by the thread library with an upcall handler, which  must run on a LWP – Kernel allocates a new LWP to the application,
            <ul>
              <li>available kernel thread의 갯수를 조정해주는 -&gt; upcall</li>
            </ul>
          </li>
          <li>upcall handler 실행, blocking thread의 state save</li>
          <li>blocking thread를 실행하던 기존 LWP는 반납</li>
          <li>upcall handler는 이 LWP에 다른 thread를 scheduling 함.</li>
          <li>Blocking 해제시, event upcall 처리용 LWP, block되었던 thread 실행용 LWP 할당</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="thread-scheduling-contention-scope">Thread Scheduling: Contention scope</h2>

<ul>
  <li>When threads supported by OS, <strong>threads</strong> (not processes) are scheduled,</li>
  <li>user-level과 kernel-level threads의 차이는 scheduling 되는 방법에 있음</li>
  <li>User-level threads are managed by thread library, kernel is unaware of them
    <ul>
      <li>To run on CPU, user-level threads should be mapped to kernel-level threads</li>
      <li>Typically use an intermediate data structure between user and kernel threads  called <strong>lightweight process (LWP)</strong>
        <ul>
          <li>Appears to be a virtual processor on which process can schedule user  thread to run</li>
          <li>Thread library schedules user-level threads to run on available LWP
            <ul>
              <li>CPU에 의해 실행되는 것을 의미하는 것이 아님.</li>
            </ul>
          </li>
          <li>Each LWP attached to kernel thread</li>
          <li>How many LWPs to create? - managed by thread library</li>
        </ul>
      </li>
      <li>Known as <strong>process-contention scope (PCS)</strong> <mark>since scheduling competition is within the process  </mark><span style="color:green">(시험)</span>
        <ul>
          <li>어플리케이션 내에서</li>
        </ul>
      </li>
      <li>PCS is done via priority set by programmer</li>
      <li>Both M:M and Two-level models require communication to maintain the  appropriate number of kernel threads allocated to the application</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="contention-scope시험">Contention scope<span style="color:green">(시험)</span></h2>

<ul>
  <li>Kernel thread are scheduled onto available CPU is <strong>system-contention scope</strong> (SCS) – competition <strong>among all threads in system</strong></li>
  <li>System using O:O(one-to-one) model (window, Linux) schedules threads <strong>using only SCS</strong>
    <ul>
      <li>선발할 이유가 없음, 어차피 OS는 소속을 보지 않기 때문에</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="pthread-scheduling">Pthread Scheduling</h2>

<ul>
  <li>We studied POSIX Pthread programming in previous chapter
    <ul>
      <li>pthread_create( )</li>
    </ul>
  </li>
  <li>API allows specifying either PCS or SCS during thread creation
    <ul>
      <li>PTHREAD_SCOPE_PROCESS schedules threads using PCS scheduling</li>
      <li>PTHREAD_SCOPE_SYSTEM schedules threads using SCS scheduling</li>
    </ul>
  </li>
  <li>Can be limited by OS – Linux and Mac OS X only allow  PTHREAD_SCOPE_SYSTEM</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154217241.png" alt="image-20220927154217241" /></p>

<p><br /></p>

<h2 id="pthread-scheduling-api시험">Pthread Scheduling API<span style="color:green">(시험)</span></h2>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="c1"> </span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="c1"> </span><span class="cp">
#define NUM_THREADS 5 
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span> 
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">scope</span><span class="p">;</span>
    <span class="n">pthread_t</span> <span class="n">tid</span><span class="p">[</span><span class="n">NUM</span> <span class="n">THREADS</span><span class="p">];</span> 
    <span class="n">pthread_attr_t</span> <span class="n">attr</span><span class="p">;</span> 
    <span class="cm">/* get the default attributes */</span> 
    <span class="n">pthread_attr_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">);</span> 
    <span class="cm">/* first inquire on the current scope */</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pthread_attr_getscope</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">scope</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to get scheduling scope</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="k">else</span> <span class="p">{</span> 
        <span class="k">if</span> <span class="p">(</span><span class="n">scope</span> <span class="o">==</span> <span class="n">PTHREAD_SCOPE_PROCESS</span><span class="p">)</span> 
            <span class="n">printf</span><span class="p">(</span><span class="s">"PTHREAD_SCOPE_PROCESS"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">scope</span> <span class="o">==</span> <span class="n">PTHREAD_SCOPE_SYSTEM</span><span class="p">)</span> 
            <span class="n">printf</span><span class="p">(</span><span class="s">"PTHREAD_SCOPE_SYSTEM"</span><span class="p">);</span> 
        <span class="k">else</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Illegal scope value.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="p">}</span>
    <span class="cm">/* set the scheduling algorithm to PCS or SCS */</span> 
    <span class="n">pthread_attr_setscope</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="n">PTHREAD_SCOPE_SYSTEM</span><span class="p">);</span> 
    <span class="cm">/* create the threads */</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
        <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span><span class="n">runner</span><span class="p">,</span><span class="nb">NULL</span><span class="p">);</span> 
    <span class="cm">/* now join on each thread */</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
        <span class="n">pthread_join</span><span class="p">(</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span> 
<span class="p">}</span> 
<span class="cm">/* Each thread will begin control in this function */</span> 
<span class="kt">void</span> <span class="o">*</span><span class="nf">runner</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">param</span><span class="p">)</span>
<span class="p">{</span> 
    <span class="cm">/* do some work ... */</span> 
    <span class="n">pthread_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> 
<span class="p">}</span> 

</code></pre></div></div>

<p><br /></p>

<h2 id="multiple-processor-scheduling">Multiple-Processor Scheduling</h2>

<ul>
  <li>CPU scheduling more complex when multiple CPUs are available.</li>
  <li>Multiprocessor system
    <ul>
      <li>Systems that provide multiple processors, each one contains single-core CPU</li>
      <li>Currently, applies to
        <ul>
          <li>Multi-core CPU</li>
          <li>Multi-threaded cores</li>
          <li>NUMA(non uniform memory access) systems
            <ul>
              <li>CPU마다 자기만 access하는 memory가 있다. (그래서 memory마다 접근하는 시간이 다 다르다.)</li>
            </ul>
          </li>
          <li>Heterogeneous multiprocessing (하는 일 특화)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Homogeneous processors</strong> within a multiprocessor.
    <ul>
      <li>Any available processor can be used to run any process in the queue</li>
    </ul>
  </li>
  <li><strong>Heterogeneous processors</strong>
    <ul>
      <li>Only programs compiled for a given processor’s instruction set could  be run on that processor</li>
    </ul>
  </li>
  <li>Allows several processes to run <strong>in parallel by providing multiple physical  processors</strong></li>
</ul>

<p><br /></p>

<h2 id="approaches-to-multiple-processor-scheduling">Approaches to Multiple-Processor Scheduling</h2>

<ul>
  <li><strong>Asymmetric</strong> multiprocessing
    <ul>
      <li>only one processor handles scheduling decision, I/O processing and  system activities such as accessing the system data structures
        <ul>
          <li>cpu 중에 대장인 master cpu가 있다.</li>
          <li>한 cpu가 스케쥴링, I/O 프로세싱을 지시하고 나머지 cpu는 시키는 일을 받아서 한다.</li>
        </ul>
      </li>
      <li>The other processors only execute use code</li>
      <li>alleviating the need for data sharing. (메모리 쉐어링을 할 필요가 없음.)</li>
      <li>Much simpler than symmetric multiprocessing</li>
    </ul>
  </li>
  <li><strong>Symmetric</strong> multiprocessing (SMP) - each processor is <strong>self-scheduling</strong>,
    <ul>
      <li>모두 동등한 cpu이다. 스케쥴링도 cpu 별로 각자 알아서 한다</li>
      <li>all processes in common ready queue (has race condition problem),</li>
      <li>or each has its own private queue of ready processes
        <ul>
          <li>Currently, most common</li>
        </ul>
      </li>
      <li>Load sharing
        <ul>
          <li>Common ready queue, and are scheduled onto any available  processor</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multiple-processor-scheduling---load-balancing">Multiple-Processor Scheduling - Load Balancing</h2>

<ul>
  <li>If SMP, need to keep all CPUs loaded for efficiency</li>
  <li>Load balancing attempts to keep workload evenly distributed</li>
  <li>Push migration – periodic task checks load on each processor, and if  found pushes task from overloaded CPU to other CPUs
    <ul>
      <li>실행 상태(live)에서 이주 시킨다.</li>
    </ul>
  </li>
  <li>Pull migration – idle(한가한) processors pulls waiting task from busy processor</li>
</ul>

<p><br /></p>

<h2 id="processor-affinity친화적인">Processor affinity(친화적인)</h2>

<ul>
  <li>
    <p>CPU 별로 특성이 있는 경우</p>
  </li>
  <li>실행중인 프로세서에서 계속 실행시키면
    <ul>
      <li>Cache memory 잔상을 이용하여 fast successive memory access 효과 기대</li>
    </ul>
  </li>
  <li>common ready queue</li>
  <li>private ready queue : 보다 나은 processor affinity 효과</li>
  <li>process has affinity for processor on which it is currently running
    <ul>
      <li>soft affinity : process affinity를 반드시 보장해야 하는 것은 아닌
        <ul>
          <li>되도록이면 이렇게 하자</li>
        </ul>
      </li>
      <li>hard affinity : 반드시 보장해야 하는
        <ul>
          <li>무조건 이렇게 해야 해</li>
        </ul>
      </li>
      <li>Variations including processor sets</li>
    </ul>
  </li>
  <li>프로세스가 돌다가 waiting 상태가 되었을 때 다시 돌아오려고 할 때 돌던 곳으로 돌아와서 실행하는 것이 좋은가 아니면 load balance를 고려했을 때 해당 프로세스가 실행될 지점의 load가 큰 경우 어떻게 해야 하는가?</li>
</ul>

<p><br /></p>

<h2 id="numa-and-cpu-scheduling">NUMA and CPU Scheduling</h2>

<p>Memory architecture도 processor affinity에 영향을 줌</p>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154620887.png" alt="image-20220927154620887" /></p>

<p>Note that memory-placement algorithms can  also consider affinity</p>

<p><br /></p>

<h2 id="multicore-processors">Multicore Processors</h2>

<ul>
  <li>Recent trend to place multiple processor cores on same physical chip</li>
  <li>Each core appears to OS to be a separate logical CPU</li>
  <li>Faster and consumes less power</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154656267.png" alt="image-20220927154656267" /></p>

<p><br /></p>

<h2 id="multicore-processors-1">Multicore Processors</h2>

<ul>
  <li>Memory stall
    <ul>
      <li>메모리 access 와 CPU 성능 차이 때문에 CPU가 놀고 있는 것</li>
    </ul>
  </li>
  <li>Resulted from speed gap between CPU and memory, cache miss</li>
  <li>Multiple threads per core also growing
    <ul>
      <li>Takes advantage of memory stall to make progress on another thread  while memory retrieve happens</li>
    </ul>
  </li>
  <li><strong>Multithreaded processing core</strong> in which several <strong>hardware threads</strong> are assigned to each core <strong>(chip multi-threading or hyper-threading)</strong>
    <ul>
      <li>If one hardware thread stalls while waiting for memory, the core can switch to  another thread</li>
      <li>Oracle Sparc M7 processor 8 threads per core, 8 cores per processor, thus  providing OS with 64 logical CPUs</li>
    </ul>
  </li>
</ul>

<hr />

<p>atomic operation: instruction cycle을 중지시킬 interrupt는 존재하지 않음.</p>

<hr />

<p><br /></p>

<h2 id="multithreaded-multicore-system">Multithreaded Multicore System</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154752640.png" alt="image-20220927154752640" /></p>

<p>hyper thread: memory stall 시간 안에 여러 개의 thread를 concurrent하게 실행 함.</p>

<p><br /></p>

<h2 id="heterogeneous-multiprocessing">Heterogeneous multiprocessing</h2>

<ul>
  <li><strong>Homogeneous multiprocessing</strong>
    <ul>
      <li>All processors are identical in terms of capabilities, allowing any  thread can run any processing core</li>
      <li>Memory access time can be vary according to load balancing,  processor affinity policy,</li>
    </ul>
  </li>
  <li>Mobile systems include multi-core architecture that run the same  instruction set
    <ul>
      <li>But each core may be different in terms of clock speed, power  consumption management</li>
      <li>For ARM processors, Higher performance big core consumes more  energy</li>
      <li>Little core consumes less energy</li>
      <li>CPU scheduler assign tasks considering the characteristics of task</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="real-time-systems">Real-Time systems</h2>

<ul>
  <li>
    <p>일 처리가 의미있는 시간 안에 완료되는 System</p>
  </li>
  <li><strong>Hard real-time systems</strong> - required to complete <strong>a critical task</strong> within a  guaranteed amount of time.
    <ul>
      <li>Resource reservation</li>
      <li>Scheduler should know exactly how long each os function takes to  perform and be guaranteed to take a maximum amount of time</li>
      <li>Such a guarantee is impossible in a general purpose system</li>
      <li>프로세스가 탑재되기 전에 실행 시간이 미리 정해져 있음</li>
    </ul>
  </li>
  <li><strong>Soft real-time systems</strong> – requires that critical processes receive priority  over less fortunate ones.
    <ul>
      <li>전화가 연결될 때 ring-back tone과 같은(특정 시간 안에 끝나는 것이 보장되지 않음)
        <ul>
          <li>ring-back tone이 routing이 빠르게 되면 금방 들리겠지만 routing이 느리게 되면 몇십초 있다가 들릴 수 있다.</li>
        </ul>
      </li>
      <li>Priority scheduling w/O aging
        <ul>
          <li>Starvation possible</li>
        </ul>
      </li>
      <li>Dispatch latency must be small
        <ul>
          <li>The smaller the dispatch latency, the faster a real-time process  can start execution once it is runnable</li>
          <li>Many os waits for either a system call to complete or for an I/O  block to take place before doing a context switch</li>
          <li>Dispatch latency can be long</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="real-time-scheduling">Real-Time Scheduling</h2>

<ul>
  <li>In general, real-time operating systems must provide:
    <ol>
      <li>Preemptive, priority-based scheduling</li>
      <li>Preemptive kernels</li>
      <li>Latency must be minimized</li>
    </ol>
  </li>
</ul>

<p>kernel code를 실행 중에 우선순위가 높은 프로세스가 들어오면 preemption</p>

<p><br /></p>

<h2 id="event-latency">Event Latency</h2>

<ul>
  <li>Event latency is the amount of time from when an event occurs to  when it is serviced.
    <ul>
      <li>Software event – timer expiration</li>
      <li>Hardware event</li>
    </ul>
  </li>
  <li>Different latency requirements for the events</li>
  <li>It should be minimize event latency</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155042925.png" alt="image-20220927155042925" /></p>

<p><br /></p>

<h2 id="real-time-cpu-schduling">Real-Time CPU Schduling</h2>

<ul>
  <li>Soft real-time systems - no guarantee as to when critical realtime process will be scheduled</li>
  <li>Hard real-time systems - task must be serviced by its deadline</li>
  <li>Two types of latencies affect  performance
    <ol>
      <li><strong>Interrupt latency</strong> – time from  arrival of interrupt at CPU to  start of routine that services  interrupt
        <ul>
          <li>interrupt가 발생하고 (CPU가 인지하고) ISR(Interrupt Service Routine)이 실행되는 시간까지의 간격</li>
        </ul>
      </li>
      <li><strong>Dispatch latency</strong> – time for  schedule to take current  process off CPU and switch  to another
        <ul>
          <li>현재 돌고있는 프로세스를 끌어내리고 새로 run 할 프로세스로 바꾸는 시간</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155301424.png" alt="image-20220927155301424" /></p>

<ul>
  <li>
    <p>In Linux ISR이 두 개로 나눠짐, Top half, Bottom half</p>
  </li>
  <li>interrupt를 CPU가 감지하기 까지 걸린 시간(delay)
    <ul>
      <li>interrupt 우선순위가 낮을 수록 이 delay가 커진다.</li>
    </ul>
  </li>
  <li>context switch: 프로세스의 잔상을 저장
    <ul>
      <li>우선순위가 높은 놈이 있으면 interrupt를 처리하고 다시 되돌아 온다는 보장이 없는데 그러면 되돌아오지 않기 때문에 context switching이 필요하다.</li>
    </ul>
  </li>
  <li>interrupt latency: 이벤트가 발생한 시점부터 ISR이 딱 실행될 때까지의 시간</li>
</ul>

<p><br /></p>

<h2 id="interrupt-latency">Interrupt latency</h2>

<ul>
  <li>Kernel Data structure가 수정되는 동안 Interrupt disable 된 시간 최소화</li>
</ul>

<p><br /></p>

<h2 id="dispatch-latency시험">Dispatch latency<span style="color:green">(시험)</span></h2>

<ul>
  <li>Amount of time required for dispatcher to stop one process and start another.</li>
  <li>To keep dispatch latency low, we need to allow
    <ul>
      <li><strong>Conflict phase</strong> of dispatch latency (수 msecs): <span style="color:green">(시험)</span>
        <ul>
          <li>Preemption of any process running in the kernel</li>
          <li>Release by low-priority processes <strong>resources</strong> needed by a high-priority
            <ul>
              <li>우선순위가 낮은 프로세스가 자원을 갖고 있는 경우 priority inversion</li>
              <li>prioity inversion: 순식간에 우선순위를 확 올려줘서 빨리 끝내게 하는</li>
              <li>ex) system call을 실행 중에 우선순위가 높은 놈이 큐에 들어오면 preemption이 진행되어야 하는데 안전하게 system call이 끝난 뒤에 하자니 real-time system이 보장되지 않기 때문에 이를 kernel에서 뺏어야 하는데 우선 순위가 높은 놈이 지금 쓰고 있던 놈의 자원을 필요로 할 수 있기 때문에 이를 priority inversion을 사용해서 너 높은 우선순위 줄테니까 빨리 끝내!!! 하고 끝나면 다시 원래의 값으로 돌린다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155343341.png" alt="image-20220927155343341" /></p>

<ul>
  <li>interrupt processing: interrupt latency + ISR time</li>
  <li>dispatch latency</li>
</ul>

<p><br /></p>

<h2 id="dispatch-latency">Dispatch latency</h2>

<ul>
  <li>Insert preemption points in long duration system calls, which check to see whether  a high priority process needs to be run
    <ul>
      <li>Context switch can be taken place only at preemption points</li>
      <li>Preemption points can be placed at only safe locations in kernel
        <ul>
          <li>Kernel data structures are not being modified</li>
        </ul>
      </li>
      <li>Only a few preemption points possible</li>
    </ul>
  </li>
  <li>Make the entire kernel pre-emptible
    <ul>
      <li>All kernel DS must be protected through the use of synchronization  mechanism</li>
      <li>Priority inversion
        <ul>
          <li>Higher priority process needs to read or modify kernel data that are  currently being accessed by lower priority process</li>
          <li>Higher priority process would be waiting for a lower priority one to finish</li>
          <li>Can be solved by priority inheritance protocol, in which all low priority  processes inherit the high priority until they are done with the resource  in question
            <ul>
              <li>When they are finished, their priority reverts to its original value</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="priority-based-scheduling">Priority-based Scheduling</h2>

<ul>
  <li>For real-time scheduling, scheduler must support preemptive, priority-based  scheduling
    <ul>
      <li>But only guarantees soft real-time</li>
    </ul>
  </li>
  <li>For hard real-time must also provide ability to meet deadlines
    <ul>
      <li>deadline이 중요!</li>
      <li>Admission control</li>
    </ul>
  </li>
  <li>Processes have new characteristics: periodic ones require CPU at constant intervals
    <ul>
      <li>Has processing time t, deadline d, period p</li>
      <li>0 ≤ t ≤ d ≤ p</li>
      <li>Rate of periodic task is 1/p</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155522120.png" alt="image-20220927155522120" /></p>

<ul>
  <li>p: event 처리 시간</li>
  <li>d: deadline</li>
  <li>d &lt; p 이면 real time 프로세싱이라고 할 수 없음
    <ul>
      <li>데드라인이 지나서 처리하는 것은 real time 의 의미를 살리지 못한 것</li>
    </ul>
  </li>
  <li>d &gt; p 이면 처리 못한 애가 있는데 다음 거를 처리하게 되는 경우 발생</li>
</ul>

<p><br /></p>

<h2 id="rate-monotonic-scheduling-1시험">Rate Monotonic Scheduling (1)<span style="color:green">(시험)</span></h2>

<p>rate monotonic: 주기의 역순으로 우선순위를 설정</p>

<p>즉, 빈도(frequency)가 높은 애가 높은 우선순위를 갖는다.</p>

<ul>
  <li>Schedules <strong>periodic tasks</strong> using a <strong>static priority</strong> with preemption</li>
  <li>A priority is assigned based on the inverse of its period -&gt; 1/p</li>
  <li>Shorter periods = higher priority;</li>
  <li>Longer periods = lower priority</li>
  <li>Period: P1 = 50, p2 = 100</li>
  <li>Processing time: t1 = 20, t2 = 35</li>
  <li>CPU utilization = ti/pi ,    p1 -&gt; 20/50 = 0.4,    p2 -&gt; 35/100 = 0.35
    <ul>
      <li>실제 처리에 필요한 시간의 비율</li>
    </ul>
  </li>
  <li>Total CPU utilization = <strong>0.75</strong> -&gt; both meet their deadlines
    <ul>
      <li>둘 다 deadline 안에 처리가 가능하다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="rate-monotonic-scheduling-2">Rate Monotonic Scheduling (2)</h2>

<p>만약 우선순위가 p이면 (not 1/p)</p>

<p>deadline이 주기랑 같다고 가정</p>

<ul>
  <li>
    <p>If p2 is assigned higher priority than p1 -&gt; p1 will miss its deadline</p>

    <ul>
      <li>
        <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155646648.png" alt="image-20220927155646648" /></p>
      </li>
      <li>
        <p>p2는 deadline안에 처리가 됨.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>P<sub>1</sub> is assigned a higher priority than P<sub>2</sub> . (rate monotonic) -&gt; both can meet deadlines</p>
    <ul>
      <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155708991.png" alt="image-20220927155708991" /></li>
      <li>p2가 30초 동안 실행되다가 P1 주기에 도달하여 이제 누가 우선순위가 높은지 따져봐야 되는데 P1의 deadline이 더 짧기 때문에 P2를 preemption하게 된다.
        <ul>
          <li>P1=50, P2=100</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="missed-deadlines-with-rate-monotonic-scheduling-3">Missed Deadlines with Rate Monotonic Scheduling (3)</h2>

<p>rate monotonic scheduling은 완벽한 하드 리얼타임 시스템이 될 수 없음.</p>

<ul>
  <li>Optimal in which static priority is used</li>
  <li>Period: P1 = 50, p2 = 80 -&gt; p1 will be assigned higher priority</li>
  <li>Processing time: t1 = 25, t2 = 35</li>
  <li>Total CPU utilization = (25/50) + (35/80) = 0.94 -&gt; p2 can not meet deadline
    <ul>
      <li>6%가 남아있기 때문에 가능할 것처럼 보이지만 진행 과정을 보면 P2가 끝나지 못했는데 P2 주기가 다가온 것을 볼 수 있다.</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155747221.png" alt="image-20220927155747221" /></p>

<p><br /></p>

<h2 id="earliest-deadline-first-scheduling-edf시험">Earliest Deadline First Scheduling (EDF)<span style="color:green">(시험)</span></h2>

<ul>
  <li>지금시점으로부터 deadline이 제일 임박한 애를 먼저 스케쥴링
    <ul>
      <li>주기가 짧은 놈이 preemption 되는 것이 아니라, 데드라인이 가장 작은 놈에게 <strong>preemption을</strong> 줌</li>
    </ul>
  </li>
  <li>
    <p>하드 리얼타임 시스템이 가능함!</p>
  </li>
  <li>Dynamic Priorities are assigned according to deadlines:
    <ul>
      <li>Rate Monotonic과 다르게 우선순위가 계속해서 바뀐다.
        <ul>
          <li>rate monotonic은 한 번 결정되면 바뀌지 않음(주기가 바뀌는 것이 아니기 때문에)</li>
        </ul>
      </li>
      <li><strong>the earlier the deadline, the higher the priority</strong>;
        <ul>
          <li>지금 시점에서!!!!!!!!</li>
        </ul>
      </li>
      <li>the later the deadline, the lower the priority</li>
    </ul>
  </li>
  <li>Priorities are adjusted to reflect the deadline of newly runnable process</li>
  <li>Period: P1 = 50, p2 = 80 -&gt; p1 will be assigned higher priority</li>
  <li>Processing time: t1 = 25, t2 = 35</li>
  <li>Rate3 – can not meet, EDF – can meet</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155830622.png" alt="image-20220927155830622" /></p>

<ul>
  <li>0초에 P1, P2가 동시에 시작</li>
  <li>P1이 처음에 우선순위가 높기 때문에 먼저 실행</li>
  <li>25초동안 P1 실행</li>
  <li>P2처리하다가 P1 주기에서 이제 누가 우선순위가 높은지 판정하게 되는데 P1은 이미 끝났기 때문에 deadline이 100이고 P2는 아직 실행 중이기 때문에 deadline이 80이므로 P2가 더 높은 우선순위를 차지하게 되어 preemption이 일어나지 않고 계속 실행된다.</li>
  <li>그러다가 P2 주기에서
    <ul>
      <li>P2 deadline: 160</li>
      <li>P1 deadline: 100</li>
      <li>이므로 P1이 우선순위라 그대로 실행을 진행하고</li>
    </ul>
  </li>
  <li>다시 P1 주기에서는
    <ul>
      <li>P2 deadline: 160</li>
      <li>P1 deadline: 150</li>
      <li>이므로 P1이 우선순위가 더 높기 때문에 현재 실행중이던 P2 process를 preemption 하여 P1 process를 실행한 것이다.</li>
    </ul>
  </li>
</ul>

<p><strong>rate monotonic 보다 real time process를 훨씬 더 보장!!!!</strong></p>

<p><br /></p>

<h2 id="proportional-share-scheduling">Proportional Share Scheduling</h2>

<ul>
  <li>T shares are allocated among all processes in the system
    <ul>
      <li>전체 CPU time의 비율</li>
    </ul>
  </li>
  <li>An application receives <strong>N shares</strong> where N &lt; T</li>
  <li>This ensures <strong>each application</strong> will receive N / T of the total processor time</li>
  <li>Must work with <strong>admission control policy</strong> to guarantee that an application receives its allocated shares of time
    <ul>
      <li>일정 시간의 비율을 할당 받는 것이 보장되지 않으면 거부하는 policy</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="posix-real-time-scheduling">POSIX Real-Time Scheduling</h2>

<ul>
  <li>The POSIX.1b standard</li>
  <li>API provides functions for managing real-time threads</li>
  <li>Defines two scheduling classes for real-time threads:</li>
</ul>

<ol>
  <li>SCHED_FIFO - threads are scheduled using a FCFS strategy with a FIFO  queue. There is no time-slicing for threads of equal priority</li>
  <li>SCHED_RR - similar to SCHED_FIFO except time-slicing occurs for threads of equal priority</li>
  <li>SCHED_OTHER – system specific</li>
</ol>

<ul>
  <li>Defines two functions for getting and setting scheduling policy:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155944084.png" alt="image-20220927155944084" /></p>

<p><br /></p>

<h2 id="posic-real-time-scheduling-api">POSIC Real-Time Scheduling API</h2>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="c1"> </span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="c1"> </span><span class="cp">
#define NUM THREADS 5 
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> 
<span class="p">{</span> 
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">policy</span><span class="p">;</span>
    <span class="n">pthread</span> <span class="n">t</span> <span class="n">tid</span><span class="p">[</span><span class="n">NUM</span> <span class="n">THREADS</span><span class="p">];</span> 
    <span class="n">pthread</span> <span class="n">attr</span> <span class="n">t</span> <span class="n">attr</span><span class="p">;</span> 
    <span class="cm">/* get the default attributes */</span> 
    <span class="n">pthread</span> <span class="n">attr</span> <span class="n">init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">);</span> 
    
    <span class="cm">/* get the current scheduling policy */</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pthread</span> <span class="n">attr</span> <span class="n">getschedpolicy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">policy</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to get policy.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="k">else</span> <span class="p">{</span> 
        
        <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">OTHER</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED OTHER</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">RR</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED RR</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">FIFO</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED FIFO</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        
        <span class="cm">/* set the scheduling policy - FIFO, RR, or OTHER */</span> 
        <span class="k">if</span> <span class="p">(</span><span class="n">pthread</span> <span class="n">attr</span> <span class="n">setschedpolicy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="n">SCHED</span> <span class="n">FIFO</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to set policy.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="cm">/* create the threads */</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM</span> <span class="n">THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
            <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span><span class="n">runner</span><span class="p">,</span><span class="nb">NULL</span><span class="p">);</span> 
        <span class="cm">/* now join on each thread */</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM</span> <span class="n">THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
            <span class="n">pthread</span> <span class="n">join</span><span class="p">(</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span> 
    <span class="p">}</span>
    <span class="cm">/* Each thread will begin control in this function */</span> 
    <span class="kt">void</span> <span class="o">*</span><span class="n">runner</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">param</span><span class="p">)</span>
    <span class="p">{</span> 
        <span class="cm">/* do some work ... */</span> 
        <span class="n">pthread</span> <span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> 
    <span class="p">}</span>
</code></pre></div></div>

<p><br /></p>

<hr />

<p>이 아래의 OS example은 시험에 안나옴 (그 다음은 나옴)</p>

<p>real time processing까지 시험범위</p>

<h2 id="operating-system-examples">Operating System Examples</h2>

<ul>
  <li>Linux scheduling</li>
  <li>Solaris scheduling</li>
  <li>Windows XP scheduling</li>
</ul>

<p><br /></p>

<h2 id="solaris">Solaris</h2>

<ul>
  <li>Priority-based scheduling</li>
  <li>Six classes available</li>
  <li>Time sharing (default)</li>
  <li>Interactive</li>
  <li>Real time</li>
  <li>System</li>
  <li>Fair Share
    <ul>
      <li>Fixed priority</li>
    </ul>
  </li>
  <li>Given thread can be in one class at a time</li>
  <li>Each class has its own scheduling algorithm</li>
  <li>Time sharing is multi-level feedback queue
    <ul>
      <li>Loadable table configurable by sysadmin</li>
    </ul>
  </li>
</ul>

<p>​</p>

<p><br /></p>

<h2 id="solaris-dispatch-table">Solaris Dispatch Table</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160212057.png" alt="image-20220927160212057" /></p>

<p><br /></p>

<h2 id="solaris-scheduling">Solaris Scheduling</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160227596.png" alt="image-20220927160227596" /></p>

<p><br /></p>

<h2 id="solaris-scheduling-cont">Solaris Scheduling (Cont.)</h2>

<ul>
  <li>Scheduler converts class-specific priorities into a per-thread global priority
    <ul>
      <li>Thread with highest priority runs next</li>
      <li>Runs until (1) blocks, (2) uses time slice, (3) preempted by higherpriority thread</li>
      <li>Multiple threads at same priority selected via RR</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="windows-scheduling">Windows Scheduling</h2>

<ul>
  <li>Windows uses priority-based preemptive scheduling</li>
  <li>Highest-priority thread runs next</li>
  <li>Dispatcher is scheduler</li>
  <li>Thread runs until (1) blocks, (2) uses time slice, (3) preempted by  higher-priority thread</li>
  <li>Real-time threads can preempt non-real-time</li>
  <li>32-level priority scheme</li>
  <li>Variable class is 1-15, real-time class is 16-31</li>
  <li>Priority 0 is memory-management thread</li>
  <li>Queue for each priority</li>
  <li>If no run-able thread, runs idle thread</li>
</ul>

<p><br /></p>

<h2 id="windows-priority-classes">Windows Priority Classes</h2>

<ul>
  <li>Win32 API identifies several priority classes to which a process can belong
    <ul>
      <li>REALTIME_PRIORITY_CLASS, HIGH_PRIORITY_CLASS,  ABOVE_NORMAL_PRIORITY_CLASS,NORMAL_PRIORITY_CLASS,  BELOW_NORMAL_PRIORITY_CLASS, IDLE_PRIORITY_CLASS</li>
    </ul>
  </li>
  <li>All are variable except REALTIME</li>
  <li>A thread within a given priority class has a relative priority
    <ul>
      <li>TIME_CRITICAL, HIGHEST, ABOVE_NORMAL, NORMAL, BELOW_NORMAL,  LOWEST, IDLE</li>
    </ul>
  </li>
  <li>Priority class and relative priority combine to give numeric priority</li>
  <li>Base priority is NORMAL within the class</li>
  <li>If quantum expires, priority lowered, but never below base</li>
</ul>

<p><br /></p>

<h2 id="windows-priority-classes-cont">Windows Priority Classes (Cont.)</h2>

<ul>
  <li>If wait occurs, priority boosted depending on what was waited for</li>
  <li>Foreground window given 3x priority boost</li>
  <li>Windows 7 added user-mode scheduling (UMS)
    <ul>
      <li>Applications create and manage threads independent of kernel</li>
      <li>For large number of threads, much more efficient</li>
      <li>UMS schedulers come from programming language libraries like  C++ Concurrent Runtime (ConcRT) framework</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="windows-xp-priorities">Windows XP Priorities</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160616698.png" alt="image-20220927160616698" /></p>

<p><br /></p>

<h2 id="linux-scheduling-through-version-25">Linux Scheduling Through Version 2.5</h2>

<ul>
  <li>Prior to kernel version 2.5, ran variation of standard UNIX scheduling algorithm
    <ul>
      <li>Did not support SMP system</li>
      <li>Runnable task의 개수가 증가하면 성능 저하</li>
    </ul>
  </li>
  <li>Version 2.5 moved to constant order O(1) scheduling time
    <ul>
      <li>SMP system 지원,
        <ul>
          <li>Processor affinity. Load balancing 지원</li>
        </ul>
      </li>
      <li>runnable task 개수에 상관없이 constant scheduling</li>
      <li>Worked well, but poor response times for interactive processes</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="linux-scheduling-in-version-2623-">Linux Scheduling in Version 2.6.23 +</h2>

<ul>
  <li>
    <p>O(1) provides excellent performance for SMP, but poor response time for interactive  tasks - Completely Fair Scheduler (CFS)</p>
  </li>
  <li>
    <p>Scheduling is based on Scheduling classes</p>

    <ul>
      <li>
        <p>Each class is assigned a specific priority</p>
      </li>
      <li>
        <p>2 scheduling classes included, others can be added</p>
      </li>
      <li>
        <p>Different scheduling algorithms can be used for different scheduling classes</p>

        <ol>
          <li>
            <p>Default - CFS</p>
          </li>
          <li>
            <p>real-time</p>
          </li>
        </ol>
      </li>
      <li>
        <p>Scheduler picks highest priority task in highest scheduling class</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Priority에 따라 고정 길이의 time quantum을 제공하던 방식 개선</p>

    <ul>
      <li>Rather than quantum based on fixed time allotments, CFS assigns a proportion  of CPU time to each task</li>
      <li>This proportion is calculated based on nice value from -20 to +19</li>
      <li>CFS does not use discrete values of time slices and instead identifies target  latency
        <ul>
          <li>interval of time during which task should run at least once</li>
        </ul>
      </li>
      <li>Proportions of CPU time are allocated from the value of targeted latency</li>
      <li>Target latency can increase if number of active tasks increases</li>
    </ul>
  </li>
  <li>CFS scheduler does not directly assign priorities</li>
  <li>CFS records how long each task has run by maintaining per task virtual run  time in variable vruntime
    <ul>
      <li>Vruntime is associated with decay factor based on priority of task
        <ul>
          <li>lower priority is higher decay rate</li>
          <li>high priority is lower decay rate</li>
        </ul>
      </li>
      <li>Normal default priority (nice value 0) yields
        <ul>
          <li>virtual run time = actual run time</li>
        </ul>
      </li>
      <li>Low priority : virtual run time &gt; actual run time</li>
      <li>High priority : virtual run time &lt; actual run time</li>
    </ul>
  </li>
  <li>To decide next task to run, scheduler picks task with lowest virtual run time</li>
  <li>Assume that two tasks have the same nice values, one task is I/O bound, the  other is CPU bound
    <ul>
      <li>The value of vruntime will eventually be lower for I/O bound task than  for CPU bound task</li>
      <li>Higher priority will be given for I/O bound task</li>
      <li>if CPU bound task is executing when I/O bound task becomes eligible  to run
        <ul>
          <li>Preemption by I/O bound task: Preemptive, priority based</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="linux-scheduling-cont">Linux Scheduling (Cont.)</h2>

<ul>
  <li>Real-time scheduling according to POSIX.1b
    <ul>
      <li>Real-time tasks have static priorities (0 ~ 99)</li>
    </ul>
  </li>
  <li>Any task scheduled using SCHED_FIFO or SCHED_RR real-time policy runs  at higher priority than normal non-real-time tasks</li>
  <li>All other normal tasks dynamic based on nice value plus or minus 5
    <ul>
      <li>Nice value of -20 maps to global priority 100</li>
      <li>Nice value of +19 maps to priority 139</li>
      <li>Map into global priority with numerically lower values indicating higher  priority</li>
      <li>Interactivity of task determines plus or minus
        <ul>
          <li>More interactive -&gt; more minus</li>
        </ul>
      </li>
      <li>Priority recalculated when task expired</li>
      <li>This exchanging arrays implements adjusted priorities</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161205643.png" alt="image-20220927161205643" /></p>

<p><br /></p>

<h2 id="priorities-and-time-slice-length">Priorities and Time-slice length</h2>

<p>CPU를 얼마나 사용했냐에 따라서 등급을 조정</p>

<ul>
  <li>Two priority ranges: time-sharing and real-time
    <ul>
      <li>real-time은 우선순위가 동적으로 조정되지 않음</li>
    </ul>
  </li>
  <li>Real-time range from 0 to 99 and nice value from 100 to 140</li>
  <li>Higher priority gets larger q
    <ul>
      <li>우선순위가 높을 수록 time quantum을 높게 줌.</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161247767.png" alt="image-20220927161247767" /></p>

<ul>
  <li>real-time이 100개, other task(normal task)가 40개</li>
  <li>real-time은 철저한 우선순위 기반</li>
  <li>normal task는 계속해서 우선순위가 바뀜</li>
  <li>주어진 time quantum을 다 쓰는 경우에 우선 순위가 내려감</li>
</ul>

<p><br /></p>

<h2 id="list-of-tasks-indexed-according-to-priorities">List of Tasks Indexed According to Priorities</h2>

<ul>
  <li>Task runnable as long as time left in time slice (active)
    <ul>
      <li>다 실행되지 못하고 preemption 된 경우는 active queue에 머물러 있고</li>
    </ul>
  </li>
  <li>If no time left (expired), not runnable until all other tasks use their slices
    <ul>
      <li>time slice가 남아있는 경우 expired queue로 넘어간다.</li>
    </ul>
  </li>
  <li>All runnable tasks tracked in per-CPU <strong>runqueue</strong> data structure
    <ul>
      <li>Two priority arrays (active, expired)</li>
      <li>Tasks indexed by priority</li>
      <li>When no more active, arrays are exchanged
        <ul>
          <li>active queue에 있는 것들이 전부 expired로 넘어가면 그때 두 queue(active, expired)는 바뀌게 된다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161321720.png" alt="image-20220927161321720" /></p>

<p><br /></p>

<h2 id="cfs-performance">CFS Performance</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161336095.png" alt="image-20220927161336095" /></p>

<p><br /></p>

<h2 id="algorithm-evaluation">Algorithm Evaluation</h2>

<ul>
  <li>How to select CPU-scheduling algorithm for an OS?</li>
  <li>Determine criteria, then evaluate algorithms</li>
  <li>Deterministic modeling
    <ul>
      <li>Type of analytic evaluation</li>
      <li>Takes a particular predetermined workload and defines the performance  of each algorithm for that workload</li>
      <li>Simple but only answer to specific cases</li>
    </ul>
  </li>
  <li>Consider 5 processes arriving at time 0</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161408493.png" alt="image-20220927161408493" /></p>

<p><br /></p>

<h2 id="deterministic-evaluation">Deterministic Evaluation</h2>

<ul>
  <li>For each algorithm, calculate minimum average waiting time</li>
  <li>Simple and fast, but requires exact numbers for input, applies only to those  inputs
    <ul>
      <li>FCS is 28ms
        <ul>
          <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161438283.png" alt="image-20220927161438283" /></li>
        </ul>
      </li>
      <li>Non-preemptive SFJ is 13ms:
        <ul>
          <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161449469.png" alt="image-20220927161449469" /></li>
        </ul>
      </li>
      <li>RR is 23ms:
        <ul>
          <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161506156.png" alt="image-20220927161506156" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="queueing-models">Queueing Models</h2>

<ul>
  <li>Generally no static set of processes to use for deterministic modeling</li>
  <li>Compute criterion using two distributions</li>
  <li>Describes the arrival of processes, and CPU and I/O bursts probabilistically
    <ul>
      <li>Distribution of CPU and I/O bursts</li>
      <li>Arrival-time distribution - Distribution of times when processes  arrive in the system
        <ul>
          <li>Commonly exponential, and described by mean</li>
          <li>Computes average throughput, utilization, waiting time, etc</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Computer system described as network of servers,
    <ul>
      <li>each server has queue of waiting processes
        <ul>
          <li>CPU with ready queue, I/O with device queue</li>
        </ul>
      </li>
      <li>Knowing arrival rates and service rates</li>
      <li>Computes utilization, average queue length, average wait time, etc</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="littles-formula">Little’s Formula</h2>

<ul>
  <li>
    <p>n = average queue length</p>
  </li>
  <li>
    <p>W = average waiting time in queue</p>
  </li>
  <li>
    <p>λ = average arrival rate into queue</p>
  </li>
  <li>
    <p>Little’s law – in steady state, processes leaving queue must equal processes  arriving,</p>

    <p>thus n = λ x W</p>
  </li>
  <li>
    <p>Valid for any scheduling algorithm and arrival distribution</p>
  </li>
  <li>
    <p>For example, if on average 7 processes arrive per second, and normally 14  processes in queue, then average wait time per process = 2 seconds</p>
  </li>
</ul>

<p><br /></p>

<h2 id="simulations">Simulations</h2>

<p>가상의 실시간을 소프트웨어로 구현하고, 시뮬레이션 돌리기</p>

<ul>
  <li>Queueing models limited</li>
  <li>Simulations more accurate
    <ul>
      <li>Programmed model of computer system</li>
      <li>Clock is a variable</li>
      <li>Gather statistics indicating algorithm performance</li>
      <li>Data to drive simulation gathered via
        <ul>
          <li>Random number generator according to probabilities</li>
          <li>Distributions defined mathematically or empirically</li>
          <li>Trace tapes record sequences of real events in real  systems</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="evaluation-of-cpu-schedulers-by-simulation">Evaluation of CPU Schedulers by Simulation</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161753590.png" alt="image-20220927161753590" /></p>

<p><br /></p>

<h2 id="implementation">Implementation</h2>

<ul>
  <li>Even simulations have limited accuracy</li>
  <li>Just implement new scheduler and test in real systems
    <ul>
      <li>High cost, high risk</li>
      <li>Environments vary</li>
    </ul>
  </li>
  <li>Most flexible schedulers can be modified per-site or per-system</li>
  <li>Or APIs to modify priorities</li>
  <li>But again environments vary</li>
</ul>

:ET