I"§:<p><br /></p>

<p>wayëŠ” í•œ cache(set) addressì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ì¥ì†Œê°€ ëª‡ ê°œê°€ ìˆëŠëƒ?ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ì</p>

<p>ì• ì´ˆì— tagë¥¼ ë¹„êµí•˜ëŠ” ê²ƒì€ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë ¤ì„œ fully associative ê°™ì€ ê²½ìš° Tagë¥¼ ëª¨ë‘ ë¹„êµí•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ parallel í•˜ê²Œ ëª¨ë‘ ë¹„êµí•˜ìë‹ˆ hardware ë¥¼ ë„ˆë¬´ ë¬´ê²ê²Œ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.</p>

<p>ê·¸ë˜ì„œ ì´ë¥¼ ìœ„í•œ íŠ¹ë³„í•œ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ”ë° ê·¸ê²ƒì´ ë°”ë¡œ Content addressable Memory(CAM) ì´ë¼ê³  í•œë‹¤.</p>

<p><br />
direct mapped (b=2)</p>

<ul>
  <li>block sizeê°€ 2ì¸ direct mapped</li>
  <li>
    <p>í•œ addressë¥¼ ê°€ì ¸ì˜¬ ë•Œ ê·¸ê²ƒê³¼ ì¸ì ‘í•œ addressë„ í•˜ë‚˜ ê°™ì´ ê°€ì ¸ì˜¤ëŠ”ë° ì´ ë‘˜ì˜ ì¸ì ‘í•´ ìˆì„ ê²ƒì´ê¸° ë•Œë¬¸ì— <strong>ê°™ì€ tag</strong>ë¥¼ ê°€ì§€ê³  ìˆì„ ê²ƒì´ë‹¤.</p>
  </li>
  <li>ê·¸ë ‡ê¸° ë•Œë¬¸ì— ë³„ë„ì˜ tag ë‘ ê°œê°€ í•„ìš”í•œ ê²ƒì´ ì•„ë‹ˆë¼ ê°™ì€ tagì— ë‘ ê°œì˜ addressê°€ ë“¤ì–´ê°€ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤.</li>
</ul>

<hr />

<p>Q) block sizeê°€ í¬ë©´ pollution dataê°€ ë“¤ì–´ì˜¬ ìˆ˜ë„ ìˆëŠ”ë° ì™œ ì´ë ‡ê²Œ í•˜ëƒ</p>

<p>A) Spatial Locality, ì¦‰, ê·¸ dataë¥¼ ê°€ì ¸ì™”ë‹¤ëŠ” ê²ƒì€ ê·¸ ê·¼ì²˜ì˜ dataë¥¼ ê°€ì ¸ì˜¬ ê°€ëŠ¥ì„±ì´ í¬ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<p>Q) êµìˆ˜ë‹˜ ì§ˆë¬¸ìˆìŠµë‹ˆë‹¤ í˜¹ì‹œ 2-wayì™€ 4-wayì¼ë•ŒëŠ” tagë¥¼ ë¹„êµí•˜ëŠ”ë° 8-wayì¼ë•Œë§Œ camì„ ì´ìš©í•˜ëŠ”ê²ƒ ì¸ê°€ìš” ?</p>

<p>A) b</p>

<hr />

<p>fully associativeëŠ” delayê°€ ê¸¸ì–´ì„œ cacheì—ì„œëŠ” ì‚¬ìš©ëª»í•˜ì§€ë§Œ virtual memoryì—ì„œëŠ” ì‚¬ìš©í•œë‹¤.</p>

<p><br /></p>

<h2 id="spatial-locality">Spatial Locality?</h2>

<ul>
  <li>Increase block size:
    <ul>
      <li>Block size, b = 4 words</li>
      <li>C = 8 words</li>
      <li>Direct mapped (1 block per set)</li>
      <li>Number of blocks, B = 2 (C/b = 8/4 = 2)</li>
    </ul>
  </li>
</ul>

<p><img src="https://user-images.githubusercontent.com/79521972/168721989-b4c21b9b-1cbc-4ce7-88c7-1a6ebaeaadbb.png" alt="image" /></p>

<p><br /></p>

<h2 id="cache-with-larger-block-size">Cache with Larger Block Size</h2>

<p><img src="https://user-images.githubusercontent.com/79521972/168722037-425c9329-baa6-4af5-af77-5c9e59f0b5e7.png" alt="image" /></p>

<p>hitì¸ ê²½ìš°ë¥¼ íŒë‹¨í•˜ì—¬ Hitì¼ ë•Œ memory addressì˜ ê°’ì„ ì½ì–´ dataë¡œ ê°€ì ¸ì˜¨ë‹¤.</p>

<p><br /></p>

<h2 id="direct-mapped-cache-performance">Direct Mapped Cache Performance</h2>

<p><img src="https://user-images.githubusercontent.com/79521972/168724373-ecab6642-edac-4fa4-8a4c-60f5a0206e28.png" alt="image" /></p>

<p>0x4: 000<span style="color:red">0</span><strong>01</strong>00</p>

<p>0xC: 000<span style="color:red">0</span><strong>11</strong>00</p>

<p>0x8: 000<span style="color:red">0</span><strong>10</strong>00</p>

<ul>
  <li>ë¹¨ê°„ìƒ‰ -&gt;  set number (ìœ„ ê·¸ë¦¼ì—ì„œ setì´ ë‘ ê°œì´ê¸° ë•Œë¬¸ì— 1 bitê°€ í•„ìš”í•˜ë‹¤.)</li>
  <li>bold ì²´ -&gt; block offset  (ìœ„ ê·¸ë¦¼ì—ì„œ blockì˜ ê°¯ìˆ˜ê°€ 4ê°œì´ê¸° ë•Œë¬¸ì— 2bitê°€ í•„ìš”í•˜ë‹¤.)</li>
</ul>

<p>í•œ ë²ˆ ê°€ì ¸ì˜¬ ë•Œ missê°€ ë‚˜ëŠ”ë° (compulsory miss) ê·¸ê±¸ ê°€ì ¸ì˜¬ ë•Œ ê·¼ì²˜ì— ìˆëŠ” ê²ƒì„ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— ê·¸ ì´í›„ì— ê·¸ ì£¼ì†Œë¥¼ ê°€ì ¸ì˜¬ ë•ŒëŠ” compulsory missê°€ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤.</p>

<p>Q) ê·¼ì²˜ì— addressë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ê·¼ì²˜ì˜ ê¸°ì¤€ì´ ë­ì§€? tag? ì•„ë‹ˆë©´ ê·¸ ì´í›„êº¼ë¥¼ ì­‰?</p>

<p>A)</p>

<p><br /></p>

<h2 id="block-size-consideration">Block size Consideration</h2>

<ul>
  <li>Larger blocks should reduce miss rate
    <ul>
      <li>Due to spatial locality</li>
    </ul>
  </li>
  <li>But, in a fixed-sized cache
    <ul>
      <li>Larger blocks =&gt; fewer of them
        <ul>
          <li>More competition =&gt; increased miss rate</li>
        </ul>
      </li>
      <li>Larger blocks =&gt; pollution</li>
    </ul>
  </li>
  <li>Larger miss penalty
    <ul>
      <li>Can override benefit of reduced miss rate</li>
      <li>Early restart and critical-word-first can help</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="types-of-misses">Types of Misses</h2>

<ul>
  <li><strong>Compulsory</strong>: first time data accessed</li>
  <li><strong>Capacity</strong>: cache too small to hold all data of  interest
    <ul>
      <li>ì „ì œì ìœ¼ë¡œ cache sizeê°€ ì‘ì•„ì„œ í•  ìˆ˜ ì—†ì´ ìƒê¸°ëŠ” miss</li>
    </ul>
  </li>
  <li><strong>Conflict</strong>: data of interest maps to same  location in cache
    <ul>
      <li>n-wayë¥¼ ì¡°ê¸ˆ ëŠ˜ë¦¬ë©´ ê´œì°®ì•„ì§€ëŠ” miss (ìš©ëŸ‰ì„ ëŠ˜ë¦¬ê³  tagë¡œ í™•ì¸)</li>
    </ul>
  </li>
</ul>

<p><strong>Miss penalty</strong>: time it takes to retrieve a block from lower level of hierarchy</p>

<p><br /></p>

<h2 id="cache-organization-recap">Cache Organization Recap</h2>

<ul>
  <li>Capacity: C</li>
  <li>Block size: b</li>
  <li>Number of blocks in cache: <strong>B = C/b</strong></li>
  <li>Number of blocks in a set: N (directì˜ ê²½ìš° 1)</li>
  <li>Number of sets: S = B/N</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/79521972/168725294-cccc1950-a96f-417b-aaac-3007e4a79145.png" alt="image" /></p>

<p><br /></p>

<h1 id="chapter-8-memory-systems">Chapter 8: Memory Systems</h1>

<h2 id="cache-replacement-policy">Cache Replacement Policy</h2>

<h2 id="replacement-policy">Replacement Policy</h2>

<ul>
  <li>Cache is too small to hold all data of interest at once</li>
  <li>If cache full: program accesses data X &amp; evicts data Y</li>
  <li><strong>Capacity miss</strong> when access Y again</li>
  <li>How to choose Y to minimize chance of needing it again?
    <ul>
      <li><strong>Least recently used (LRU) replacement</strong>: the least  recently used block in a set evicted</li>
    </ul>
  </li>
  <li>cacheì— ë°ì´í„°ê°€ ë‹¤ì‹œ ë“¤ì–´ì˜¤ê²Œ ë˜ëŠ” ê²½ìš° ê¸°ì¡´ì— ìˆë˜ ê²ƒì„ ë²„ë ¤ì•¼ í• í…ë° ë¬´ìŠ¨ ê¸°ì¤€ìœ¼ë¡œ ë²„ë ¤ì•¼ ë˜ëŠ”ê°€?
    <ul>
      <li>LRU(Least recently used) replacement</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Direct mapped: no choice</li>
  <li>Set associative:
    <ul>
      <li>Prefer non-valid entry, if there is one</li>
      <li>Otherwise, choose among entries in the set Conflict: data of interest maps to same location in cache</li>
    </ul>
  </li>
  <li>Least-recently used (LRU)
    <ul>
      <li>Choose the one unused for the longest time
        <ul>
          <li>Simple for 2-way, manageable for 4-way, <strong>too hard beyond that</strong></li>
          <li>2-wayë‚˜ 4-wayëŠ” managable í•œë° ì—„ì²­ í° ê±´ í˜ë“¦</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Random
    <ul>
      <li>Gives approximately the same performance as LRU for high associativity</li>
      <li>ìƒê°ë³´ë‹¤ ì„±ëŠ¥ì´ ë†’ìŒ(nì´ í´ ë•Œ ê±°ì˜ LRUì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="lru-replacement">LRU Replacement</h2>

<p><img src="https://user-images.githubusercontent.com/79521972/168725967-4a0475b6-c6f0-4cd8-a599-cc71aab047c6.png" alt="image" /></p>

<ul>
  <li>0x04ê°€ ë“¤ì–´ì˜¤ê³  0x24ê°€ ë“¤ì–´ì™”ê¸° ë•Œë¬¸ì— ë” ë¨¼ì € ì“°ì¸ 04ë²ˆì§€ë¥¼ ë°€ì–´ë‚´ê³  ìƒˆë¡œ 54 ë²ˆì§€ê°€ ë“¤ì–´ì˜¤ë„ë¡ í•œë‹¤.</li>
  <li>ë‘˜ ì¤‘ì— ì–´ë–¤ê²Œ ë” ìµœê·¼ì— ì“°ì˜€ëŠ”ì§€ í•­ìƒ trackingì„ í•´ì•¼ í•¨.</li>
</ul>

<p><br /></p>

<h2 id="cache-misses">Cache Misses</h2>

<ul>
  <li>â˜ The next few slides are excerpts from the book, COD. )</li>
  <li>On cache hit, CPU proceeds normally</li>
  <li><strong>On cache miss</strong>
    <ul>
      <li>Stall the CPU pipeline
        <ul>
          <li>accessë¥¼ í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—</li>
        </ul>
      </li>
      <li>Fetch block from <strong>next level</strong> of hierarchy</li>
      <li>Instruction cache miss
        <ul>
          <li>Restart instruction fetch</li>
        </ul>
      </li>
      <li>Data cache miss
        <ul>
          <li>Complete data access</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="write-through">Write-Through</h2>

<ul>
  <li>On data-write hit, could just update the block in cache
    <ul>
      <li>cacheì—ëŠ” writeì´ ë°”ë¡œ ë  ì§€ë¼ë„ ì‹¤ì§ˆì ì€ memoryì— ì¨ì§€ì§€ëŠ” ì•ŠëŠ”ë‹¤.</li>
      <li>But then cache and memory would be inconsistent</li>
    </ul>
  </li>
  <li><strong>Write through</strong>: also update memory
    <ul>
      <li>cacheê°€ update ë  ë•Œë§ˆë‹¤ memoryë„ update í•˜ë„ë¡ í•œë‹¤!
        <ul>
          <li>ì‹œê°„ì´ ì—„ì²­ ê±¸ë¦´ ê²ƒì´ë‹¤ -&gt; bufferë¡œ í•´ê²°</li>
        </ul>
      </li>
      <li>ëŒ€ì‹  cacheì™€ memoryì˜ ë‚´ìš©ì´ ê°™ê²Œ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.</li>
    </ul>
  </li>
  <li>But, makes writes take longer
    <ul>
      <li>e.g., if base CPI = 1, 10% of instructions are stores, write  to memory takes 100 cycles
        <ul>
          <li>Effective CPI = 1 + 0.1Ã—100 = 11</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Solution</strong>: <mark>write buffer</mark>
    <ul>
      <li>Holds data waiting to be written to memory</li>
      <li>CPU continues immediately
        <ul>
          <li><strong>Only stalls on write if write buffer is already full</strong></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="write-back">Write-Back</h2>

<ul>
  <li>Alternative: On data-write hit, just update the block in cache
    <ul>
      <li>Keep track of whether each block is dirty</li>
    </ul>
  </li>
  <li>When a dirty block is replaced
    <ul>
      <li>Write it back to memory</li>
      <li>Can use a write buffer to allow replacing block to be read first</li>
    </ul>
  </li>
</ul>

<p>ë˜ ë‹¤ë¥¸ ë°©ì‹ì€ Write-back ë°©ì‹ì´ë‹¤. ì´ ë°©ì‹ì€ ë¸”ë¡ì´ êµì²´ë  ë•Œë§Œ ë©”ëª¨ë¦¬ì˜ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤. ë°ì´í„°ê°€ ë³€ê²½ëëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ìºì‹œ ë¸”ë¡ë§ˆë‹¤ <code class="language-plaintext highlighter-rouge">dirty</code> ë¹„íŠ¸ë¥¼ ì¶”ê°€í•´ì•¼ í•˜ë©°, ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆë‹¤ë©´ <code class="language-plaintext highlighter-rouge">1</code>ë¡œ ë°”ê¿”ì¤€ë‹¤. ì´í›„ í•´ë‹¹ ë¸”ë¡ì´ êµì²´ë  ë•Œ <code class="language-plaintext highlighter-rouge">dirty</code> ë¹„íŠ¸ê°€ <code class="language-plaintext highlighter-rouge">1</code>ì´ë¼ë©´ ë©”ëª¨ë¦¬ì˜ ë°ì´í„°ë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ë‹¤.</p>

<p><br /></p>

<h2 id="write-miss---write-allocation">Write Miss - Write Allocation</h2>

<ul>
  <li>What should happen on a Write Miss?</li>
  <li>For, Write-through
    <ul>
      <li>Write allocate (or fetch-on-write): fetch the block  followed by write-hit operation</li>
      <li>Write around (or write-no-allocate): not loaded to  cache, and is written directly to memory
        <ul>
          <li>Since programs often write a whole block before reading it (e.g.  initialization)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>For, Write-back
    <ul>
      <li>Usually fetch the block</li>
    </ul>
  </li>
</ul>

<p>ë°ì´í„°ë¥¼ ë³€ê²½í•  ì£¼ì†Œê°€ ìºì‹±ëœ ìƒíƒœê°€ ì•„ë‹ˆë¼ë©´(Write miss) Write-allocate ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤. ë‹¹ì—°í•œ ì–˜ê¸°ì§€ë§Œ, ë¯¸ìŠ¤ê°€ ë°œìƒí•˜ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼ ìºì‹±í•˜ëŠ” ê²ƒì´ë‹¤. write-allocateë¥¼ í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ë‹¹ì¥ì€ resourceë¥¼ ì•„ë‚„ ìˆ˜ ìˆê² ì§€ë§Œ ìºì‹œì˜ ëª©ì ì„ ë‹¬ì„±í•˜ì§€ëŠ” ëª»í•  ê²ƒì´ë‹¤.</p>

<p><br /></p>

<h2 id="example-intrinsity-fastmathì‹œí—˜">Example: Intrinsity FastMATH(ì‹œí—˜)</h2>

<ul>
  <li>Embedded MIPS processor
    <ul>
      <li>12-stage pipeline</li>
      <li>Instruction and data access on each cycle</li>
    </ul>
  </li>
  <li>Split cache: separate I-cache and D-cache
    <ul>
      <li>Each 16-KB: 256 blocks * 16 Words/block</li>
      <li>D-cache: write-through or write-back</li>
    </ul>
  </li>
  <li>SPEC2000 miss rate (benchmark program)
    <ul>
      <li>I-cache: 0.4%</li>
      <li>D-cache: 11.4%</li>
      <li>Weighted average: 3.2%</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="example-intrinsity-fastmath">Example: Intrinsity FastMATH</h2>

<p><img src="https://user-images.githubusercontent.com/79521972/168726950-e68112ea-869e-40fd-aca8-359af5b6aae4.png" alt="image" /></p>

<p>Virtual memoryì™€ í•©ì³ì§„ processor êµ¬ì¡°ê°€ ì¤‘ìš”í•¨ (ì¶”í›„ì— ë°°ìš¸ ê²ƒ)</p>

<p><br /></p>

<h2 id="main-memory-supporting-caches">Main Memory Supporting Caches</h2>

<ul>
  <li>Use DRAMs for main memory
    <ul>
      <li>Fixed width (e.g., 1 word)</li>
      <li>Connected by fixed-width clocked bus
        <ul>
          <li><strong>Bus clock</strong> is typically slower than CPU clock</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Example cache block read
    <ul>
      <li>Assume, 1 bus cycle for <strong>address transfer</strong></li>
      <li>15 bus cycles per <strong>DRAM access</strong></li>
      <li>1 bus cycle per <strong>data transfer</strong></li>
    </ul>
  </li>
  <li>For 4-word block, 1-word-wide DRAM
    <ul>
      <li>Miss penalty = 1 + 4Ã—15 + 4Ã—1 = 65 bus cycles</li>
      <li>Bandwidth = 16 bytes / 65 cycles = 0.25 B/cycle</li>
    </ul>
  </li>
  <li>
    <p>memoryì—ì„œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ addressë¥¼ ì „ë‹¬í•˜ëŠ”ë° í•œ clock ê±¸ë¦°ë‹¤ê³  ê°€ì •( busë¥¼ í†µí•´ ì „ë‹¬)</p>
  </li>
  <li>
    <p>DRAMì´ë‹ˆê¹Œ cellì— ê°€ì„œ ë©”ëª¨ë¦¬ë¥¼ ê°€ì ¸ì™€ì„œ ì ì¬í•˜ëŠ”ë° 15 bus cycleì´ ê±¸ë¦¼.</p>
  </li>
  <li>ì „ë‹¬í•˜ëŠ”ë° 1 bus cycle</li>
</ul>

<p>ê·¸ë ‡ë‹¤ë©´ 4word(16 byte)ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ëª‡ clockì´ ê±¸ë¦´ê¹Œ?</p>

<p>1 + 15 *</p>

<p><br /></p>

<h2 id="increasing-memory-bandwidth">Increasing Memory Bandwidth</h2>

<p><img src="https://user-images.githubusercontent.com/79521972/168727455-cc3e1f01-0465-40cd-b158-a4b54eae54b2.png" alt="image" /></p>

<p><img src="https://user-images.githubusercontent.com/79521972/168727464-fac87e10-1db3-4726-bd1e-4002576a8a2b.png" alt="image" /></p>

<ul>
  <li>
    <p>a-&gt;b : busê°€ 32ì—ì„œ 128ë¡œ ë³€í™”í–ˆë‹¤í•˜ë©´</p>

    <ul>
      <li>4-word wide memory
        <ul>
          <li>Miss penalty = 1 + 15 + 1 = 17 bus cycles</li>
          <li>
            <p>Bandwidth = 16 bytes / 17 cycles = 0.94 B/cycle</p>
          </li>
          <li>
            <p>addressê°€ busë¥¼ í†µí•´ ì˜¤ë©´, ìƒìœ„ addressëŠ” ë˜‘ê°™ê¸° ë•Œë¬¸ì— memory bankì— ë™ì‹œì— ì°¾ì•„ê°„ë‹¤.</p>
          </li>
          <li>ì°¾ì•„ ê°€ëŠ”ë°ëŠ” 15clock, í•˜ë‚˜ì”© ë³´ë‚´ëŠ”ë° 4clock</li>
        </ul>
      </li>
      <li>4-bank interleaved memory
        <ul>
          <li>Miss penalty = 1 + 15 + 4Ã—1 = 20 bus cycles</li>
          <li>Bandwidth = 16 bytes / 20 cycles = 0.8 B/cycle</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>bì˜ busëŠ” 128 bit, cì˜ busëŠ” 32bit</p>
  </li>
  <li>
    <p>cë¥¼ ì“°ëŠ” ê²ƒì´ ì¢‹ë‹¤.</p>
  </li>
</ul>

<p>ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•˜ëŠ”ê²ƒì€
ìºì‹œ í•˜ë‚˜ ì¡´ì¬ &gt; ë©”ëª¨ë¦¬ê°€ ë²„ìŠ¤ë¡œ ì—°ê²° &gt; ë©”ëª¨ë¦¬ êµ¬ì¡°ì´ë‹¤.
ì´ë•Œ, bandwidthë¥¼ ëŠ˜ë¦¬ë©´ í•œë²ˆì— ì´ë™ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì–‘ì´ ëŠ˜ì–´ë‚œë‹¤. busë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” êµ¬ì¡°ë¹„ìš©ì´ ë§ì´ ë“¤ê²Œ ëœë‹¤. ë”°ë¼ì„œ ë¹„ìš©ì—†ì´ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” bankë¼ê³  í•˜ëŠ” ê°œë…ì´ ë„ì…ëœë‹¤.</p>

<p>ì‚¬ì‹¤ ì´í•´ ì˜ ì•ˆ ë¨</p>

<p>https://parksb.github.io/article/29.html</p>

<p>https://velog.io/@blacklandbird/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-8</p>
:ET