I"qÂ<h1 id="chapter-9-memory-management">Chapter 9: Memory Management</h1>

<ul>
  <li>Background</li>
  <li>Logical versus Physical Address Space</li>
  <li>Swapping</li>
  <li>Contiguous Memory Allocation</li>
  <li>Paging</li>
  <li>Segmentation</li>
  <li>Segmentation with Paging</li>
  <li>Structure of the Page Table</li>
  <li>Example: The Intel 32 and 64-bit Architectures</li>
  <li>Example: ARM Architecture</li>
</ul>

<p><br /></p>

<h2 id="objectives">Objectives</h2>

<ul>
  <li>To provide a detailed description of various ways of organizing memory  hardware</li>
  <li>To discuss various memory-management techniques, including paging  and segmentation</li>
  <li>To provide a detailed description of the Intel Pentium, which supports both pure segmentation and segmentation with paging</li>
</ul>

<p><br /></p>

<h2 id="structure---top-level">Structure - Top Level</h2>

<ul>
  <li>components are interleaved</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232502033.png" alt="image-20221002232502033" /></p>

<p><br /></p>

<h2 id="structure--the-cpu">Structure -The CPU</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232615247.png" alt="image-20221002232615247" /></p>

<p><br /></p>

<h2 id="structure---the-control-unit">Structure - The Control Unit</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232722331.png" alt="image-20221002232722331" /></p>

<p><br /></p>

<h2 id="von-neumann-architecture">Von Neumann architecture</h2>

<ul>
  <li>Instructions and data are stored in a single read-write  memory</li>
  <li>Contents of memory are addressable by location without  regard to the type of data contained there</li>
  <li>Execution occurs in sequential fashion unless explicitly  modified</li>
</ul>

<p><br /></p>

<h2 id="what-is-a-program">What is a program?</h2>

<ul>
  <li>A sequence of steps (instructions)</li>
  <li>For each step, an arithmetic or logical operation is done</li>
  <li>For each operation, a different set of control signals is needed</li>
</ul>

<p><br /></p>

<h2 id="instruction-cycle">Instruction Cycle</h2>

<ul>
  <li>Two steps:
    <ul>
      <li>Fetch</li>
      <li>Execute</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232821824.png" alt="image-20221002232821824" /></p>

<p><br /></p>

<h2 id="instruction-cycle-with-interrupts---state-diagram">Instruction Cycle (with Interrupts) - State Diagram</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002232849213.png" alt="image-20221002232849213" /></p>

<p><br /></p>

<h2 id="background">Background</h2>

<ul>
  <li>Program must be brought (from disk) into memory and placed within a  process for it to be run</li>
  <li>Main memory and registers are only storage CPU can access directly</li>
  <li>Memory unit only sees a stream of addresses + read requests, or  address + data and write requests</li>
  <li>Register access in one CPU clock (or less)</li>
  <li>Main memory can take many cycles, causing a stall</li>
  <li>Cache sits between main memory and CPU registers</li>
  <li>Protection of memory required to ensure correct operation
    <ul>
      <li>Multi-programmingÏóêÏÑúÏùò security</li>
      <li>Ïó¨Îü¨ ÌîÑÎ°úÏÑ∏Ïä§Îì§Í∞ÑÏóê Îã§Î•∏ ÌîÑÎ°úÏÑ∏Ïä§Ïùò Î©îÎ™®Î¶¨ ÏòÅÏó≠ Ïπ®Î≤îÏù¥ Ïù¥Î£®Ïñ¥ÏßÄÏßÄ ÏïäÎèÑÎ°ù Í¥ÄÎ¶¨</li>
    </ul>
  </li>
  <li>Memory resource Í¥ÄÎ¶¨
    <ul>
      <li>As a result of CPU scheduling -&gt; improved cpu utilization, response</li>
      <li>CPU schedulingÍ≥º Í∞ôÏù¥ Î©îÎ™®Î¶¨Î•º resource Ï∞®ÏõêÏóêÏÑú Í¥ÄÎ¶¨Ìï¥ÏïºÌï®.  (Î∂ÑÎ∞∞ Î¨∏Ï†ú)</li>
    </ul>
  </li>
  <li>A program resides on a disk as a binary executable file
    <ul>
      <li>Program must be brought into memory and placed within a process  for it to be executed.</li>
      <li>Input queue ‚Äì collection of processes on the disk that are waiting to  be brought into memory for execution.
        <ul>
          <li>Select one of the processes in input queue, load that process  into memory</li>
          <li>Sequence of memory addresses are generated by the running  program (Instruction execution cycles, addressing modes)</li>
          <li>If process terminate, its memory space is made available</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="base-and-limit-registers">Base and Limit Registers</h2>

<ul>
  <li>A pair of base and limit registers define the logical address  space</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233047756.png" alt="image-20221002233047756" /></p>

<p><br /></p>

<h2 id="hardware-address-protection-with-base-and-limit-registers">Hardware Address Protection with Base and Limit Registers</h2>

<ul>
  <li>CPU must check every memory access generated in user mode to  be sure it is between base and limit for that user</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233125230.png" alt="image-20221002233125230" /></p>

<ul>
  <li>the instructions to loading the base and limit registers are privileged</li>
</ul>

<p><br /></p>

<h2 id="address-binding">Address Binding</h2>

<ul>
  <li>Programs on disk, ready to be brought into memory to execute form an input queue
    <ul>
      <li>Without support, must be loaded into address 0000</li>
    </ul>
  </li>
  <li>Inconvenient to have first user process physical address always at 0000
    <ul>
      <li>How can it not be?</li>
      <li>Most systems allow a user process to reside in any part of the physical memory</li>
      <li>First address of user process does not need to be 0</li>
    </ul>
  </li>
  <li>Further, addresses represented in different ways at different stages of a program‚Äôs life</li>
</ul>

<p><br /></p>

<h2 id="background-1">Background</h2>

<ul>
  <li>User programs go through several steps before being executed.
    <ul>
      <li>Source code addresses usually symbolic address</li>
      <li>Compiled code addresses bind to relocatable addresses
        <ul>
          <li>A compiler binds symbolic address to relocatable address</li>
          <li>i.e. ‚Äï14 bytes from beginning of this module‚Äñ</li>
        </ul>
      </li>
      <li>Linker or loader will bind relocatable addresses to absolute  addresses
        <ul>
          <li>i.e. 74014</li>
        </ul>
      </li>
      <li>Each binding maps one address space to another</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233255372.png" alt="image-20221002233255372" /></p>

<p><br /></p>

<h2 id="address-binding-1">Address Binding</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233403794.png" alt="image-20221002233403794" /></p>

<p>START: MOV #3, R1</p>

<p>‚Äã			SUB R2, R3</p>

<p>‚Äã			BNE START</p>

<p>‚Äã			BLE NEXT</p>

<p>‚Äã			MOV VAR1, R3</p>

<p>NEXT : SUB #2, R1</p>

<p>VAR1 : WORD 0</p>

<p><br /></p>

<h2 id="address-binding-2">Address Binding</h2>

<ul>
  <li>Internal addressÎäî pass1,2Î•º ÌÜµÌïòÏó¨ reconcileÎê®.</li>
  <li>Reconcile : give actual address</li>
  <li>But, How about addresses which cannot be reconciled at  assembly?
    <ul>
      <li>References to external modules</li>
      <li>References to absolute address</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="address-binding-3">Address Binding</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233459847.png" alt="image-20221002233459847" /></p>

<ul>
  <li>What is done at each step ?
    <ul>
      <li>Assembler
        <ul>
          <li>Translate assembly language instruction into machine code
            <ul>
              <li>Format instruction words</li>
              <li>Reconciles labels/variables location</li>
              <li>Usually addresses are generated in relocatable form
                <ul>
                  <li>¬ª Assumes first words of program at address zero</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>‚Äã</p>

<p><br /></p>

<h2 id="address-binding-4">Address Binding</h2>

<ul>
  <li>Linker
    <ul>
      <li>Takes various relocatable, assembled modules &amp; combines  them into 1 module
        <ul>
          <li>Reconcile external reference</li>
          <li>Generates load module</li>
          <li>What is in load module
            <ul>
              <li>Machine instruction / data</li>
              <li>Information about size of various parts (code, table  data)</li>
              <li>Relocation information
                <ul>
                  <li>¬ª Addresses which need to be reconciled when  module is placed in a particular location in  memory</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="address-binding-5">Address Binding</h2>

<ul>
  <li>Loader
    <ul>
      <li>Accepts load module, places it into memory</li>
      <li>Reconciling addresses where necessary</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="binding-of-instructions-and-data-to-memory">Binding of Instructions and Data to Memory</h2>

<p>Address binding of instructions and data to memory addresses can happen at three different stages.</p>

<ul>
  <li>Compile time:
    <ul>
      <li>If it is known at compile time where the process will reside in  memory, absolute code can be generated;</li>
      <li>must recompile code if starting location changes.</li>
    </ul>
  </li>
  <li>Load time:
    <ul>
      <li>Must generate relocatable code if memory location is not known at  compile time.</li>
      <li>If the starting address changes, we need to reload the user code</li>
    </ul>
  </li>
  <li>Execution time:
    <ul>
      <li>Binding delayed until run time if the process can be moved during  its execution from one memory segment to another.</li>
      <li>Need hardware support for address maps (e.g., base and limit  registers).</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multistep-processing-of-a-user-program">Multistep Processing of a User Program</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002233809961.png" alt="image-20221002233809961" /></p>

<p><br /></p>

<h2 id="logical-vs-physical-address-space">Logical vs. Physical Address Space</h2>

<ul>
  <li>The concept of a logical address space that is bound to a separate  physical address space is central to proper memory management.
    <ul>
      <li>Logical address ‚Äì generated by the CPU; also referred to as virtual  address.</li>
      <li>Physical address ‚Äì address seen by the memory unit.</li>
    </ul>
  </li>
  <li>Logical and physical addresses are the same in compile-time and loadtime address-binding schemes; logical (virtual) and physical addresses  differ in execution-time address-binding scheme.
    <ul>
      <li><strong>Logical address space</strong> is the set of all logical addresses generated  by a program</li>
      <li><strong>Physical address space</strong> is the set of all physical addresses  generated by a program</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="physical-logical-storage">Physical &amp;¬†Logical storage</h2>

<ul>
  <li>Sharing of memory
    <ul>
      <li>Where is a process information placed?</li>
      <li>How is it later accessed?</li>
      <li>How is security insured?</li>
      <li>Want the addressing to be transparent to user</li>
    </ul>
  </li>
  <li>Physical storage
    <ul>
      <li>Actual storage in hardware memory of machine, usually start at  zero</li>
    </ul>
  </li>
  <li>Logical storage
    <ul>
      <li>Memory as perceived by process
        <ul>
          <li>Can be larger or smaller than physical storage</li>
          <li>Size usually limited by architecture (&lt;&gt;virtual address)</li>
        </ul>
      </li>
      <li>Usually relocatable address</li>
    </ul>
  </li>
  <li>Processes only see logical storage
    <ul>
      <li>Logical address must be translated to physical address</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="memory-management-unit-mmu">Memory-Management Unit (MMU)</h2>

<ul>
  <li>Hardware device that at run time maps virtual to physical address</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234124953.png" alt="image-20221002234124953" /></p>

<ul>
  <li>Many methods possible, covered in the rest of this chapter</li>
  <li>To start, consider simple scheme where the value in the relocation register is  added to every address generated by a user process at the time it is sent to  memory
    <ul>
      <li>Base register now called relocation register</li>
      <li>MS-DOS on Intel 80x86 used 4 relocation registers</li>
    </ul>
  </li>
  <li>The user program deals with logical addresses; it never sees the real physical  addresses
    <ul>
      <li>Execution-time binding occurs when reference is made to location in memory</li>
      <li>Logical address bound to physical addresses</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="dynamic-relocation-using-a-relocation-register">Dynamic relocation using a relocation register</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234148212.png" alt="image-20221002234148212" /></p>

<p><br /></p>

<h2 id="dynamic-loading">Dynamic Loading</h2>

<ul>
  <li>Entire program and data of a process must be in physical memory for the process  to execute
    <ul>
      <li>The size of process is limited to the size of physical memory</li>
    </ul>
  </li>
  <li>To obtain better memory space utilization, dynamic loading can be used
    <ul>
      <li>Routine is not loaded until it is called</li>
      <li>Better memory-space utilization; unused routine is never loaded.</li>
      <li>All routines are kept on disk in a relocatable load format</li>
      <li>When an unloaded routine is needed, relocatable loader is called to load the  desired routine into memory, then control is passed to newly loaded code</li>
      <li>Useful when large amounts of code are needed to handle infrequently  occurring cases.</li>
      <li>No special support from the operating system is required except providing  library routines to implement DL
        <ul>
          <li>implemented through program design.</li>
          <li>OS can help by providing libraries to implement dynamic loading</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="dynamic-linking">Dynamic Linking</h2>

<ul>
  <li>Static linking ‚Äì system libraries and program code combined by the loader into the  binary program image
    <ul>
      <li>shared libraries</li>
    </ul>
  </li>
  <li>Dynamic linking
    <ul>
      <li>Rather than loading being postponed until execution time, Linking is postponed until execution time.</li>
    </ul>
  </li>
  <li>Usually used with system libraries such as language library
    <ul>
      <li>W/O this facility, all programs on a system need to have a copy of their language  library, wastes both disk and memory</li>
    </ul>
  </li>
  <li>Small piece of code, stub, is included in the image for each library routine reference
    <ul>
      <li>Stub is used to locate the appropriate memory-resident library routine.</li>
      <li>Stub replaces itself with the address of the routine, and executes the routine</li>
    </ul>
  </li>
  <li>Operating system checks if routine is in processes‚Äô memory address
    <ul>
      <li>If not in address space, add to address space</li>
    </ul>
  </li>
  <li>Consider applicability to patching system libraries
    <ul>
      <li>Versioning may be needed</li>
    </ul>
  </li>
  <li>Need OS support because of address space problem between different processes</li>
</ul>

<p><br /></p>

<h2 id="swapping">Swapping</h2>

<ul>
  <li>A process can be swapped temporarily out of memory to a backing store, and  then brought back into memory for continued execution</li>
  <li>Total physical memory space of processes can exceed physical memory</li>
  <li>Need execution time binding</li>
  <li><strong>Backing store</strong> ‚Äì fast disk large enough to accommodate copies of all memory  images for all users; must provide direct access to these memory images</li>
  <li><strong>Roll out, roll in</strong> ‚Äì swapping variant used for priority-based scheduling  algorithms; lower-priority process is swapped out so higher-priority process can  be loaded and executed</li>
  <li>Major part of swap time is transfer time; total transfer time is directly proportional  to the amount of memory swapped</li>
  <li>System maintains a <strong>ready queue</strong> of ready-to-run processes which have  memory images on disk</li>
</ul>

<p><br /></p>

<h2 id="swapping-1">Swapping</h2>

<ul>
  <li>Does the swapped out process need to swap back in to same physical  addresses?</li>
  <li>Depends on address binding method
    <ul>
      <li>Plus consider pending I/O to / from process memory space</li>
    </ul>
  </li>
  <li>Modified versions of swapping are found on many systems (i.e., UNIX,  Linux, and Windows)
    <ul>
      <li>Swapping normally disabled</li>
      <li>Started if more than threshold amount of memory allocated</li>
      <li>Disabled again once memory demand reduced below threshold</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="schematic-view-of-swapping">Schematic View of Swapping</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002234528490.png" alt="image-20221002234528490" /></p>

<p><br /></p>

<h2 id="context-switch-time-including-swapping">Context Switch Time including Swapping</h2>

<ul>
  <li>If next processes to be put on CPU is not in memory, need to swap out a process and  swap in target process</li>
  <li>Context switch time can then be very high</li>
  <li>100MB process swapping to hard disk with transfer rate of 50MB/sec
    <ul>
      <li>Plus disk latency of 8 ms</li>
      <li>Swap out time of 2008 ms</li>
      <li>Plus swap in of same sized process</li>
      <li>Total context switch swapping component time of 4016ms (&gt; 4 seconds)</li>
    </ul>
  </li>
  <li>Can reduce if reduce size of memory swapped ‚Äì by knowing how much memory really  being used
    <ul>
      <li>System calls to inform OS of memory use via request memory and release  memory</li>
      <li>request_memory() and release_memory()</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="context-switch-time-including-swapping-1">Context Switch Time including Swapping</h2>

<ul>
  <li>Other constraints as well on swapping
    <ul>
      <li>Pending I/O ‚Äì can‚Äôt swap out as I/O would occur to wrong process</li>
      <li>Or always transfer I/O to kernel space, then to I/O device
        <ul>
          <li>Known as double buffering, adds overhead</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Standard swapping not used in modern operating systems
    <ul>
      <li>But modified version common
        <ul>
          <li>Swap only when free memory extremely low</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="swapping-on-mobile-systems">Swapping on Mobile Systems</h2>

<ul>
  <li>Not typically supported
    <ul>
      <li>Flash memory based
        <ul>
          <li>Small amount of space</li>
          <li>Limited number of write cycles</li>
          <li>Poor throughput between flash memory and CPU on mobile platform</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Instead use other methods to free memory if low
    <ul>
      <li>iOS asks apps to voluntarily relinquish allocated memory
        <ul>
          <li>Read-only data thrown out and reloaded from flash if needed</li>
          <li>Failure to free can result in termination</li>
        </ul>
      </li>
      <li>Android terminates apps if low free memory, but first writes application  state to flash for fast restart</li>
      <li>Both OSes support paging as discussed below</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="memory-management">Memory management</h2>

<ul>
  <li>How memory is allocated to different jobs to hold their (entire or parts of)  load module
    <ul>
      <li>Various levels of memory
        <ul>
          <li>Cache, main memory, secondary storage</li>
          <li>Access slower storage (secondary storage) as infrequently as  possible</li>
          <li>When need to access?
            <ul>
              <li>Fetch instruction</li>
              <li>Fetch data/store data</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Use of main memory
        <ul>
          <li>Utilize to fullest</li>
          <li>Must be shared</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="placement-of-modules-in-memory">Placement of modules in memory</h2>

<ul>
  <li>Main memory must support both OS and user processes
    <ul>
      <li>Kernel remains in main memory</li>
      <li>Memory have security (between kernel and user, between users)</li>
    </ul>
  </li>
  <li>Limited resource, must allocate efficiently</li>
  <li>Determine different placement strategies for user processes</li>
  <li>Compare strategies based on
    <ul>
      <li>Internal fragmentation
        <ul>
          <li>Pieces of memory which are associated with a process but which the  process cannot using
            <ul>
              <li>This space cannot be allocated</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>External fragmentation
        <ul>
          <li>Pieces of free too small to be allocated and are therefore wasted</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Degree of multi-programming
    <ul>
      <li>Measure of number of jobs which can be in system based on the allocation of  some portion of memory for the job‚Äôs use</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="contiguous-allocation">Contiguous Allocation</h2>

<ul>
  <li>Main memory usually into two partitions:
    <ul>
      <li>Resident operating system, usually held in low memory with interrupt vector.</li>
      <li>User processes then held in high memory.</li>
      <li>Each process contained in single contiguous section of memory</li>
    </ul>
  </li>
  <li>Relocation registers used to protect user processes from each other, and  from changing operating-system code and data
    <ul>
      <li>Base register contains value of smallest physical address</li>
      <li>Limit register contains range of logical addresses ‚Äì each logical  address must be less than the limit register</li>
      <li>MMU maps logical address dynamically</li>
      <li>Can then allow actions such as kernel code being transient and  kernel changing size</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="hardware-support-for-relocation-and-limit-registers">Hardware Support for Relocation and Limit Registers</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235106545.png" alt="image-20221002235106545" /></p>

<p><br /></p>

<h2 id="single-partition-allocation">Single-partition allocation</h2>

<ul>
  <li>Single job in memory (All or nothing)
    <ul>
      <li>Place the entire job in the user portion main memory</li>
    </ul>
  </li>
  <li>Where is job placed?
    <ul>
      <li>User job can be at address directly next to kernel space</li>
      <li>Kernel-user or user-kernel depending on interrupt h/w</li>
      <li>Relocation-register scheme used to protect user processes from each other,  and from changing operating-system code and data.</li>
      <li>Relocation register contains value of smallest physical address; limit register  contains range of logical addresses ‚Äì each logical address must be less than  the limit register.</li>
    </ul>
  </li>
  <li>Adv.: Compile time address binding</li>
  <li>Dis, : need recompiling when kernel size changes
    <ul>
      <li>Kernel routine Ï§ë ÏûêÏ£º ÏàòÌñâÎêòÏßÄ ÏïäÎäî programÏùÑ Î∂àÎü¨Îì§ÏùºÎïå
        <ul>
          <li>Place user job at opposite end of memory and allow to grow toward  kernel space</li>
          <li>Translation of logical to physical (execution time biding)
            <ul>
              <li>Security</li>
              <li>Simple addressing</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="multiple-fixed-parition">Multiple fixed parition</h2>

<ul>
  <li>MM is divided into a number of fixed size partition</li>
  <li>When a process arrives, it is placed into one of the partition which are  larger than job itself     -&gt; process is assigned entire partition</li>
  <li>Prob.
    <ul>
      <li>internal fragmentation</li>
      <li>Degree of multiprogramming bounded by # of partitions</li>
    </ul>
  </li>
  <li>Advantages
    <ul>
      <li>Address change easy, because simple addressing</li>
      <li>Easy security</li>
      <li>Easy bookeeping : no free memory management</li>
    </ul>
  </li>
  <li>What if a job does not fit the partition/memory ? (larger than)</li>
</ul>

<p><br /></p>

<h2 id="overlays">Overlays</h2>

<ul>
  <li>Keep in memory only those instructions and data that are needed at any  given time.
    <ul>
      <li>Breaks program into pieces (Fig. 8.2)</li>
      <li>When other instructions are needed, they are loaded into space that  are occupied by instructions that are no longer needed</li>
    </ul>
  </li>
  <li>Needed when process is larger than amount of memory allocated to it.</li>
  <li>Implemented by user, no special support needed from operating system,  programming design of overlay structure is complex</li>
</ul>

<p><br /></p>

<h2 id="multiple---variable-sized-partition-allocation">Multiple - Variable sized partition allocation</h2>

<ul>
  <li>Multiple-partition allocation
    <ul>
      <li>Degree of multiprogramming limited by number of partitions</li>
      <li>Variable-partition sizes for efficiency (sized to a given process‚Äô needs)</li>
      <li>Hole ‚Äì block of available memory; holes of various size are scattered  throughout memory.</li>
      <li>When a process arrives, it is allocated memory from a hole large enough to  accommodate it.</li>
      <li>Process exiting frees its partition, adjacent free partitions combined</li>
      <li>Operating system maintains information about: a) allocated partitions b) free partitions (hole)</li>
      <li>Non internal, external Fragmentation</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235500482.png" alt="image-20221002235500482" /></p>

<p><br /></p>

<h2 id="dynamic-storage-allocation-problem">Dynamic Storage-Allocation Problem</h2>

<p>How to satisfy a request of size n from a list of free holes.</p>

<ul>
  <li>First-fit: Allocate the first hole that is big enough.
    <ul>
      <li>Maintain free space information as a linked list sorted by  address (start, size)to allocate search list, assign first partition  whose size is larger than job</li>
      <li>On fly compaction
        <ul>
          <li>Ability to combine adjacent free space</li>
          <li>Easy to maintain list in order</li>
        </ul>
      </li>
      <li>Long search time</li>
      <li>External fragmentation
        <ul>
          <li>Decreases size of large block</li>
          <li>Potentially increase search time</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Best-fit: Allocate the smallest hole that is big enough; must search entire  list, unless ordered by size. Produces the smallest leftover hole.
    <ul>
      <li>Maintain free space as large of chunks as possible
        <ul>
          <li>Maintain list is sorted in increasing size order</li>
        </ul>
      </li>
      <li>Elements may have to be moved in the list when they change in size</li>
      <li>Remainder is going to be smaller</li>
    </ul>
  </li>
  <li>Worst-fit: Allocate the largest hole; must also search entire list.  Produces the largest leftover hole.
    <ul>
      <li>Maintain list in decreasing size order</li>
      <li>Try to avoid generating small pieces of free space</li>
      <li>Decrease the amount of large free space</li>
    </ul>
  </li>
  <li>First-fit and best-fit better than worst-fit in terms of speed and  storage utilization</li>
  <li>First fit analysis reveals that given N blocks allocated, 0.5 N blocks lost to fragmentation
    <ul>
      <li>1/3 may be unusable -&gt; 50-percent rule</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="fragmentation">Fragmentation</h2>

<ul>
  <li>External fragmentation ‚Äì total memory space exists to satisfy a request,  but it is not contiguous.</li>
  <li>Internal fragmentation ‚Äì allocated memory may be slightly larger than  requested memory; this size difference is memory internal to a partition,  but not being used.</li>
  <li>Reduce external fragmentation by compaction
    <ul>
      <li>Shuffle memory contents to place all free memory together in one  large block.</li>
      <li>Compaction is possible only if relocation is dynamic, and is done at  execution time.</li>
      <li>I/O problem
        <ul>
          <li>Latch job in memory while it is involved in I/O.</li>
          <li>Do I/O only into OS buffers.</li>
        </ul>
      </li>
      <li>Now consider that backing store has same fragmentation problems</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="segmentation">Segmentation</h2>

<ul>
  <li>
    <p>Memory-management scheme that supports user view of memory</p>
  </li>
  <li>
    <p>A program is a collection of segments</p>

    <ul>
      <li>A segment is a logical unit such as:</li>
    </ul>

    <p>main program</p>

    <p>procedure</p>

    <p>function</p>

    <p>method</p>

    <p>object</p>

    <p>local variables, global variables</p>

    <p>common block</p>

    <p>stack</p>

    <p>symbol tablearray</p>
  </li>
</ul>

<p><br /></p>

<h2 id="users-view-of-a-program">User‚Äôs View of a Program</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235912372.png" alt="image-20221002235912372" /></p>

<p><br /></p>

<h2 id="logical-view-of-segmentation">Logical View of Segmentation</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221002235931229.png" alt="image-20221002235931229" /></p>

<p><br /></p>

<h2 id="segmentation-architecture">Segmentation Architecture</h2>

<ul>
  <li>
    <p>Logical address consists of a two tuple:</p>

    <p>&lt;segment-number, offset&gt;,</p>
  </li>
  <li>
    <p>Segment table ‚Äì maps two-dimensional physical addresses; each table entry  has:</p>
  </li>
  <li>
    <p>base ‚Äì contains the starting physical address where the segments reside in  memory</p>
  </li>
  <li>
    <p>limit ‚Äì specifies the length of the segment</p>
  </li>
  <li>
    <p>Segment-table base register (STBR) points to the segment table‚Äôs location in  memory</p>
  </li>
  <li>
    <p>Segment-table length register (STLR) indicates number of segments used by a  program;</p>

    <p>segment number s is legal if s &lt; STLR</p>
  </li>
</ul>

<p><br /></p>

<h2 id="segmentation-architecture-cont">Segmentation Architecture (Cont.)</h2>

<ul>
  <li>Protection
    <ul>
      <li>With each entry in segment table associate:
        <ul>
          <li>validation bit = 0 -&gt; illegal segment</li>
          <li>read/write/execute privileges</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Protection bits associated with segments; code sharing occurs at  segment level</li>
  <li>Since segments vary in length, memory allocation is a dynamic  storage-allocation problem</li>
  <li>
    <p>A segmentation example is shown in the following diagram</p>
  </li>
  <li>Relocation.
    <ul>
      <li>dynamic</li>
      <li>by segment table</li>
    </ul>
  </li>
  <li>Sharing.
    <ul>
      <li>shared segments</li>
      <li>same segment number : self reference</li>
    </ul>
  </li>
  <li>Allocation.
    <ul>
      <li>first fit/best fit</li>
      <li>external fragmentation</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="segmentation-hardware">Segmentation Hardware</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000143452.png" alt="image-20221003000143452" /></p>

<p><br /></p>

<h2 id="example-of-segmentation">Example of Segmentation</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000157093.png" alt="image-20221003000157093" /></p>

<p><br /></p>

<h2 id="sharing-of-segments">Sharing of segments</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000211184.png" alt="image-20221003000211184" /></p>

<p><br /></p>

<h2 id="paging">Paging</h2>

<ul>
  <li>Another solution to external fragmentation
    <ul>
      <li>Physical address space of a process can be noncontiguous; process is  allocated physical memory whenever the latter is available.</li>
      <li>Avoids external fragmentation</li>
      <li>Avoids problem of varying sized memory chunks</li>
    </ul>
  </li>
  <li>Divide physical memory into fixed-sized blocks called frames (size is power of 2,  between 512 bytes and 8192 bytes).</li>
  <li>Divide logical memory into blocks of same size called pages.</li>
  <li>Keep track of all free frames.</li>
  <li>To run a program of size n pages, need to find n free frames and load program.</li>
  <li>Set up a page table to translate logical to physical addresses.</li>
  <li>Backing store likewise split into pages</li>
  <li>Still have Internal fragmentation, External?</li>
</ul>

<p><br /></p>

<h2 id="address-translation-scheme">Address Translation Scheme</h2>

<ul>
  <li>
    <p>Address generated by CPU is divided into:</p>

    <ul>
      <li>Page number (p) ‚Äì used as an index into a page table which  contains base address of each page in physical memory</li>
      <li>Page offset (d) ‚Äì combined with base address to define the  physical memory address that is sent to the memory unit</li>
      <li>
        <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000318696.png" alt="image-20221003000318696" /></p>
      </li>
      <li>For given logical address space 2<sup>m</sup> and page size 2<sup>n</sup></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="address-translation-scheme-1">Address Translation Scheme</h2>

<ul>
  <li>Address generated by CPU is divided into:
    <ul>
      <li>Page number (p) ‚Äì used as an index into a page table which  contains base address of each page in physical memory.</li>
      <li>Page offset (d) ‚Äì combined with base address to define the physical  memory address that is sent to the memory unit.</li>
      <li>Given page size P under logical address A
        <ul>
          <li>p = A div P</li>
          <li>d = A mod P</li>
          <li>Ex) page size = 10 , logical address = 31
            <ul>
              <li>P = 31 div 10 = 3</li>
              <li>D = 31 mod 10 = 1</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="paging-hardware">Paging Hardware</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000440077.png" alt="image-20221003000440077" /></p>

<p><br /></p>

<h2 id="paging-model-of-logical-and-physical-memory">Paging Model of Logical and Physical Memory</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000459434.png" alt="image-20221003000459434" /></p>

<p><br /></p>

<h2 id="paging-example">Paging Example</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000512397.png" alt="image-20221003000512397" /></p>

<p><br /></p>

<h2 id="paging-cont">Paging (Cont.)</h2>

<ul>
  <li>Calculating internal fragmentation
    <ul>
      <li>Page size = 2,048 bytes</li>
      <li>Process size = 72,766 bytes</li>
      <li>35 pages + 1,086 bytes</li>
      <li>Internal fragmentation of 2,048 - 1,086 = 962 bytes</li>
      <li>Worst case fragmentation = 1 frame ‚Äì 1 byte</li>
      <li>On average fragmentation = 1 / 2 frame size</li>
      <li>So small frame sizes desirable?</li>
      <li>But each page table entry takes memory to track</li>
      <li>Page sizes growing over time
        <ul>
          <li>Solaris supports two page sizes ‚Äì 8 KB and 4 MB</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Process view and physical memory now very different</li>
  <li>By implementation process can only access its own memory</li>
</ul>

<p><br /></p>

<h2 id="free-frames">Free Frames</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000622312.png" alt="image-20221003000622312" /></p>

<p><br /></p>

<h2 id="implementation-of-page-table">Implementation of Page Table</h2>

<ul>
  <li>Pages can be mapped into non-contiguous frames</li>
  <li>Page table is kept in main memory.</li>
  <li>Page-table base register (PTBR) points to the page table</li>
  <li>Page-table length register (PTLR) indicates size of the page table
    <ul>
      <li>Rarely does a process use all its address range</li>
    </ul>
  </li>
  <li>In this scheme every data/instruction access requires two memory  accesses. One for the page table and one for the data/instruction.</li>
  <li>
    <p>The two memory access problem can be solved by the use of a special fastlookup hardware cache called associative memory or translation lookaside buffers (TLBs)</p>
  </li>
  <li>Some TLBs store address-space identifiers (ASIDs) in each TLB entry
    <ul>
      <li>uniquely identifies each process to provide address-space protection for  that process</li>
      <li>Otherwise need to flush at every context switch</li>
    </ul>
  </li>
  <li>TLBs typically small (64 to 1,024 entries)</li>
  <li>On a TLB miss, value is loaded into the TLB for faster access next time
    <ul>
      <li>Replacement policies must be considered</li>
      <li>Some entries can be wired down for permanent fast access</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="associative-register">Associative Register</h2>

<ul>
  <li>Associative registers ‚Äì parallel search</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000741601.png" alt="image-20221003000741601" /></p>

<ul>
  <li>Address translation (p, d)
    <ul>
      <li>If p is in associative register, get frame # out.</li>
      <li>Otherwise get frame # from page table in memory</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="paging-hardware-with-tlb">Paging Hardware With TLB</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003000804647.png" alt="image-20221003000804647" /></p>

<p><br /></p>

<h2 id="effective-access-time">Effective Access Time</h2>

<ul>
  <li>
    <p>Associative Lookup = ÔÅ• time unit</p>

    <ul>
      <li>Can be &lt; 10% of memory access time</li>
    </ul>
  </li>
  <li>
    <p>Hit ratio = Œ±</p>

    <ul>
      <li>Hit ratio ‚Äì percentage of times that a page number is found in the associative  registers; ratio related to number of associative registers</li>
    </ul>
  </li>
  <li>
    <p>Consider Œ± = 80%, Œµ = 20ns for TLB search, 100ns for memory access Assume  memory cycle time is 1 microsecond</p>
  </li>
  <li>
    <p>Effective Access Time (EAT)</p>
  </li>
</ul>

<p>EAT = (1 + Œµ) Œ± + (2 + Œµ)(1 ‚Äì Œ±)</p>

<p>= 2 + Œµ ‚Äì Œ±</p>

<ul>
  <li>
    <p>Consider Œ± = 80%, Œµ = 20ns for TLB search, 100ns for memory access</p>

    <ul>
      <li>EAT = 0.80 x 120 + 0.20 x 220 = 140ns</li>
    </ul>
  </li>
  <li>
    <p>Consider slower memory but better hit ratio -&gt; Œ± = 98%, Œµ = 20ns for TLB search,  140ns for memory access</p>

    <ul>
      <li>EAT = 0.98 x 160 + 0.02 x 300 = 162.8ns</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="memory-protection">Memory Protection</h2>

<ul>
  <li>Memory protection implemented by associating protection bit with each  frame to indicate if read-only or read-write access is allowed
    <ul>
      <li>Read only, read-write, execution only bits</li>
    </ul>
  </li>
  <li>Valid-invalid bit attached to each entry in the page table:
    <ul>
      <li>‚Äúvalid‚Äù indicates that the associated page is in the process‚Äô logical  address space, and is thus a legal page</li>
      <li>‚Äúinvalid‚Äù indicates that the page is not in the process‚Äô logical address  space</li>
      <li>Or use PTLR</li>
    </ul>
  </li>
  <li>Page-table length register (PRLR) indicates size of the page table.
    <ul>
      <li>Rarely does a process use all its address range</li>
    </ul>
  </li>
  <li>Any violations result in a trap to the kernel</li>
</ul>

<p><br /></p>

<h2 id="valid-v-or-invalidi-bit-in-a-page-table">Valid (v) or Invalid(i) Bit In A Page Table</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001217135.png" alt="image-20221003001217135" /></p>

<p><br /></p>

<h2 id="shared-pages">Shared Pages</h2>

<ul>
  <li>Shared code
    <ul>
      <li>One copy of read-only (reentrant) code shared among processes  (i.e., text editors, compilers, window systems)</li>
      <li>Similar to multiple threads sharing the same process space</li>
      <li>Also useful for interprocess communication if sharing of read-write  pages is allowed</li>
    </ul>
  </li>
  <li>Private code and data
    <ul>
      <li>Each process keeps a separate copy of the code and data</li>
      <li>The pages for the private code and data can appear anywhere in  the logical address space</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="shared-page-examples">Shared Page Examples</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001303441.png" alt="image-20221003001303441" /></p>

<p><br /></p>

<h2 id="structure-of-the-page-table">Structure of the Page Table</h2>

<ul>
  <li>Memory structures for paging can get huge using straight-forward  methods
    <ul>
      <li>Consider a 32-bit logical address space as on modern  computers</li>
      <li>Page size of 4 KB (212)</li>
      <li>Page table would have 1 million entries (232 / 212)</li>
      <li>If each entry is 4 bytes -&gt; 4 MB of physical address space /  memory for page table alone
        <ul>
          <li>That amount of memory used to cost a lot</li>
          <li>Don‚Äôt want to allocate that contiguously in main memory</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Hierarchical Paging</li>
  <li>Hashed Page Tables</li>
  <li>Inverted Page Tables</li>
</ul>

<p><br /></p>

<h2 id="structure-of-the-page-table-1">Structure of the Page Table</h2>

<ul>
  <li>Memory structures for paging can get huge using straight-forward methods</li>
  <li>Most modern computer systems support a large logical address space (2<sup>32</sup>, 2<sub>64</sub>)
    <ul>
      <li>Consider a 32-bit logical address space , Page size of 4 KB (2<sup>12</sup>)</li>
      <li>Page table would have 1 million (2*20) entries - 2<sup>32</sup> / 2<sup>12</sup>)</li>
      <li>Page table itself is becomes excessively large</li>
      <li>page table consists of (1 million) entries</li>
      <li>If each entry consists of 4 bytes, each process may need up to 4Mb of physical  address space for the page table alone</li>
      <li>Don‚Äôt want to allocate that contiguously in main memory</li>
    </ul>
  </li>
  <li>Hierarchical Paging</li>
  <li>Hashed Page Tables</li>
  <li>Inverted Page Tables</li>
</ul>

<p><br /></p>

<h2 id="hierarchical-page-tables">Hierarchical Page Tables</h2>

<ul>
  <li>Break up the logical address space into multiple page tables</li>
  <li>A simple technique is a two-level page table</li>
  <li>We then page the page table</li>
</ul>

<p><br /></p>

<h2 id="two-level-page-table-scheme">Two-Level Page-Table Scheme</h2>

<p><img src="C:\Users\c_dragon\AppData\Roaming\Typora\typora-user-images\image-20221003001608667.png" alt="image-20221003001608667" /></p>

<p><br /></p>

<h2 id="two-level-paging-example">Two-Level Paging Example</h2>

<ul>
  <li>A logical address (on 32-bit machine with 4K page size) is divided into:
    <ul>
      <li>a page number consisting of 20 bits</li>
      <li>a page offset consisting of 12 bits.</li>
    </ul>
  </li>
  <li>Since the page table is paged, the page number is further divided into:
    <ul>
      <li>a 10-bit page number.</li>
      <li>a 10-bit page offset.</li>
    </ul>
  </li>
  <li>Thus, a logical address is as follows:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001715427.png" alt="image-20221003001715427" /></p>

<ul>
  <li>where pi is an index into the outer page table, and p2 is the displacement within the  page of the outer page table.</li>
  <li>Known as forward-mapped page table</li>
</ul>

<p><br /></p>

<h2 id="address-translation-scheme-2">Address-Translation Scheme</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001727500.png" alt="image-20221003001727500" /></p>

<p><br /></p>

<h2 id="multilevel-paging64-bit-logical-address-space">Multilevel Paging(64-bit Logical Address Space)</h2>

<ul>
  <li>
    <p>If page size is 4 KB (212)</p>

    <ul>
      <li>
        <p>Then page table has 252 entries</p>
      </li>
      <li>
        <p>If we use 2-level paging scheme, inner page tables could be 1 page long  (2**10 4 byte entries)</p>
      </li>
      <li>
        <p>Address would look like</p>

        <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001824871.png" alt="image-20221003001824871" /></p>
      </li>
      <li>
        <p>Outer page table has 242 entries or 244 bytes</p>
      </li>
      <li>
        <p>One solution is to add a 2nd outer page table (Three level paging scheme)</p>
      </li>
      <li>
        <p>But in the following example the 2nd outer page table is still 234 bytes in size</p>

        <ul>
          <li>And possibly 4 memory access to get to one physical memory location</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="three-level-paging-scheme">Three-level Paging Scheme</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003001837935.png" alt="image-20221003001837935" /></p>

<p><br /></p>

<h2 id="four-level-paging-scheme">Four level paging scheme</h2>

<ul>
  <li>
    <p>Since each level is stored as a separate table in memory, covering a  logical address to a physical one may take four memory accesses.  (p1,p2,p3,p4,d)</p>
  </li>
  <li>
    <p>Even though time needed for one memory access is quintupled, caching  permits performance to remain reasonable.</p>
  </li>
  <li>
    <p>Cache hit rate of 98 percent yields:</p>

    <p>effective access time = 0.98 x 120 + 0.02 x 520</p>

    <p>= 128 nanoseconds.</p>
  </li>
</ul>

<p>which is only a 28 percent slowdown in memory access time.</p>

<p><br /></p>

<h2 id="hashed-page-tables">Hashed Page Tables</h2>

<ul>
  <li>A Common approach in case of address spaces &gt; 32 bits.</li>
  <li>The virtual page number is hashed into a page table.
    <ul>
      <li>This page table contains a chain of elements hashing to the same location.</li>
    </ul>
  </li>
  <li>Each element contains (1) the virtual page number (2) the value of the mapped  page frame (3) a pointer to the next element</li>
  <li>Virtual page numbers are compared in this chain searching for a match.
    <ul>
      <li>If a match is found, the corresponding physical frame is extracted.</li>
    </ul>
  </li>
  <li>Variation for 64-bit addresses is clustered page tables
    <ul>
      <li>Similar to hashed but each entry refers to several pages (such as 16) rather  than 1</li>
      <li>Especially useful for sparse address spaces (where memory references are  non-contiguous and scattered)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="hashed-page-table">Hashed Page Table</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002014031.png" alt="image-20221003002014031" /></p>

<p><br /></p>

<h2 id="inverted-page-table">Inverted Page Table</h2>

<ul>
  <li>Each process has a page table associated with it
    <ul>
      <li>Each page table may consists of millions of entries</li>
    </ul>
  </li>
  <li>Rather than each process having a page table and keeping track of all possible  logical pages, track all physical pages
    <ul>
      <li>One entry for each real page (frame) of memory.</li>
      <li>Entry consists of the virtual address of the page stored in that real memory  location, with information about the process that owns that page.</li>
    </ul>
  </li>
  <li>Decreases memory needed to store each page table, but increases time needed to  search the table when a page reference occurs.- whole table might be searched</li>
  <li>Use hash table to limit the search to one ‚Äî or at most a few ‚Äî page-table entries.
    <ul>
      <li>TLB can accelerate access (Associated memory register)</li>
    </ul>
  </li>
  <li>But how to implement shared memory?
    <ul>
      <li>One mapping of a virtual address to the shared physical address</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="inverted-page-table-architecture">Inverted Page Table Architecture</h2>

<ul>
  <li>each virtual address consists of &lt;process-id, page-number, offset&gt;</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002127392.png" alt="image-20221003002127392" /></p>

<p><br /></p>

<h2 id="segmentation-with-paging---multics">Segmentation with Paging - MULTICS</h2>

<ul>
  <li>The MULTICS system solved problems of external fragmentation  and lengthy search times by paging the segments.</li>
  <li>Solution differs from pure segmentation in that the segment-table  entry contains not the base address of the segment, but rather the  base address of a page table for this segment.</li>
</ul>

<p><br /></p>

<h2 id="multics-address-translation-scheme">MULTICS Address Translation Scheme</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002203270.png" alt="image-20221003002203270" /></p>

<p><br /></p>

<h2 id="segmentation-with-paging---intel-386">Segmentation with Paging - Intel 386</h2>

<ul>
  <li>Intel 386 uses segmentation with paging for memory management with a  two-level paging scheme.</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002226872.png" alt="image-20221003002226872" /></p>

<p><br /></p>

<h2 id="example-the-intel-32-and-64-bit-architectures">Example: The Intel 32 and 64-bit Architectures</h2>

<ul>
  <li>Dominant industry chips</li>
  <li>Pentium CPUs are 32-bit and called IA-32 architecture (x-86)</li>
  <li>Current Intel CPUs are 64-bit and called IA-64 architecture</li>
  <li>Many variations in the chips, cover the main ideas here</li>
</ul>

<p><br /></p>

<h2 id="example-the-intel-ia-32-architecture">Example: The Intel IA-32 Architecture</h2>

<ul>
  <li>Supports both segmentation and segmentation with paging
    <ul>
      <li>Each segment can be 4 GB (4*10<sup>9</sup> Bytes)</li>
      <li>Up to 16 K segments per process</li>
      <li>Logical address space of a process is divided into two partitions
        <ul>
          <li>First partition of up to 8 K segments are private to process (kept in local  descriptor table (LDT))</li>
          <li>Second partition of up to 8K segments shared among all processes (kept  in global descriptor table (GDT))</li>
          <li>Each entry in LDT &amp; GDT consists of an 8-byte segment descriptor with  detailed information about a particular segment including base location  and limit of a segment</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="example-the-intel-ia-32-architecture-cont">Example: The Intel IA-32 Architecture (Cont.)</h2>

<ul>
  <li>
    <p>CPU generates logical address</p>

    <ul>
      <li>
        <p>Logical address is a pair of (selector, offset)</p>
      </li>
      <li>
        <p>Selector(16 bits) given to segmentation unit</p>

        <ul>
          <li>
            <p>Which produces linear addresses</p>
          </li>
          <li>
            <p>s designates the segment number,</p>
          </li>
          <li>
            <p>g indicates whether the segment is in GDT or LDT</p>
          </li>
          <li>
            <p>p deals with protection</p>
          </li>
          <li>
            <p>offset (32 bits) specifying the location of the byte within the segment</p>

            <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002437823.png" alt="image-20221003002437823" /></p>
          </li>
        </ul>
      </li>
      <li>
        <p>Linear address given to paging unit</p>

        <ul>
          <li>Which generates physical address in main memory</li>
          <li>Paging units form equivalent of MMU</li>
          <li>Pages sizes can be 4 KB or 4 MB
            <ul>
              <li>For 4KB pages, two-level paging</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="logical-to-physical-address-translation-in-ia-32">Logical to Physical Address Translation in IA-32</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002502914.png" alt="image-20221003002502914" /></p>

<p><br /></p>

<h2 id="intel-ia-32-segmentation">Intel IA-32 Segmentation</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002513358.png" alt="image-20221003002513358" /></p>

<p><br /></p>

<h2 id="intel-ia-32-paging-architecture">Intel IA-32 Paging Architecture</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002529262.png" alt="image-20221003002529262" /></p>

<p><br /></p>

<h2 id="intel-ia-32-page-address-extensions">Intel IA-32 Page Address Extensions</h2>

<ul>
  <li>32-bit address limits led Intel to create page address extension (PAE), allowing  32-bit apps access to more than 4GB of memory space
    <ul>
      <li>Paging went to a 3-level scheme</li>
      <li>Top two bits refer to a page directory pointer table</li>
      <li>Page-directory and page-table entries moved from 32 bits to 64-bits in size
        <ul>
          <li>Base address of page tables and page frames to extend from 20 to 24 bits</li>
        </ul>
      </li>
      <li>Net effect of PAE is increasing address space (from 32 bits) to 36 bits ‚Äì 64GB of physical memory (24 + 12 bit offset)</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002607170.png" alt="image-20221003002607170" /></p>

<p><br /></p>

<h2 id="intel-x86-64">Intel x86-64</h2>

<ul>
  <li>Current generation Intel x86 architecture</li>
  <li>64 bits is ginormous (&gt; 16 exabytes 16*10<sup>18</sup> : 2<sup>64</sup> bytes)</li>
  <li>In practice only implement 48 bit addressing for virtual addressing
    <ul>
      <li>Page sizes of 4 KB, 2 MB, 1 GB</li>
      <li>Four levels of paging hierarchy</li>
    </ul>
  </li>
  <li>Can also use PAE, so virtual addresses are 48 bits and physical  addresses are 52 bits</li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002651857.png" alt="image-20221003002651857" /></p>

<p><br /></p>

<h2 id="example-arm-architecture">Example: ARM Architecture</h2>

<ul>
  <li>Dominant mobile platform chip  (Apple iOS and Google Android  devices for example)</li>
  <li>Modern, energy efficient, 32-bit  CPU</li>
  <li>4 KB and 16 KB pages</li>
  <li>1 MB and 16 MB pages (termed  sections) ÔÅÆ One-level paging for sections, twolevel for smaller pages</li>
  <li>Two levels of TLBs
    <ul>
      <li>Outer level has two micro  TLBs (one data, one  instruction)</li>
      <li>Inner is single main TLB</li>
      <li>First inner is checked, on  miss outers are checked,  and on miss page table  walk performed by CPU</li>
    </ul>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002726169.png" alt="image-20221003002726169" /></p>

<p><br /></p>

<h2 id="armv8-4-level-hierarchical-paging">ARMv8 4-level hierarchical paging</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002742974.png" alt="image-20221003002742974" /></p>

<p><br /></p>

<h2 id="linear-address-in-linux">Linear Address in Linux</h2>

<ul>
  <li>
    <p>Linux uses only 6 segments (kernel code, kernel data, user code, user  data, task-state segment (TSS), default LDT segment)</p>
  </li>
  <li>
    <p>Linux only uses two of four possible modes ‚Äì kernel and user</p>
  </li>
  <li>
    <p>Uses a three-level paging strategy that works well for 32-bit and 64-bit  systems</p>
  </li>
  <li>
    <p>Linear address broken into four parts:</p>

    <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002815700.png" alt="image-20221003002815700" /></p>
  </li>
  <li>
    <p>But the Pentium only supports 2-level paging?!</p>
  </li>
</ul>

<p><br /></p>

<h2 id="three-level-paging-in-linux">Three-level Paging in Linux</h2>

<p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20221003002833465.png" alt="image-20221003002833465" /></p>

<p><br /></p>

<h2 id="comparing-memory-management-startegies">Comparing Memory-Management Startegies</h2>

<ul>
  <li>Hardware support</li>
  <li>Performance</li>
  <li>Fragmentation</li>
  <li>Relocation</li>
  <li>Swapping</li>
  <li>Sharing</li>
  <li>Protection</li>
  <li>-&gt; Refer to summary section in text boo</li>
</ul>
:ET