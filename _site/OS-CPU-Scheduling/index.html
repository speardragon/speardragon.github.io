<!DOCTYPE html> <html lang="en" class="no-js"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>[OS] CPU Scheduling | Jekflix</title> <meta name="description" content="Jekflix is a template for Jekyll inspired by Netflix and made by Thiago Rossener."> <meta name="keywords" content="운영체제, OS"> <!-- Social: Twitter --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="[OS] CPU Scheduling | Jekflix"> <meta name="twitter:description" content="Jekflix is a template for Jekyll inspired by Netflix and made by Thiago Rossener."> <meta property="twitter:image" content="http://localhost:4000/assets/img/blog-image.png"> <meta name="twitter:site" content="@twitter_username"> <!-- Social: Facebook / Open Graph --> <meta property="og:url" content="http://localhost:4000/OS-CPU-Scheduling/"> <meta property="og:title" content="[OS] CPU Scheduling | Jekflix"> <meta property="og:image" content="http://localhost:4000/assets/img/blog-image.png"> <meta property="og:description" content="Jekflix is a template for Jekyll inspired by Netflix and made by Thiago Rossener."> <meta property="og:site_name" content="Jekflix | A blog theme for Jekyll"> <!-- Favicon --> <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" /> <!-- Apple Touch Icons --> <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" /> <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" /> <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" /> <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" /> <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" /> <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" /> <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" /> <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" /> <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" /> <!-- Windows 8 Tile Icons --> <meta name="application-name" content="Jekflix"> <meta name="msapplication-TileColor" content="#141414"> <meta name="msapplication-square70x70logo" content="smalltile.png" /> <meta name="msapplication-square150x150logo" content="mediumtile.png" /> <meta name="msapplication-wide310x150logo" content="widetile.png" /> <meta name="msapplication-square310x310logo" content="largetile.png" /> <!-- Android Lolipop Theme Color --> <meta name="theme-color" content="#141414"> <!-- Fonts --> <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet"> <link rel="stylesheet" href="/assets/css/styles.css"> <link rel="canonical" href="http://localhost:4000/OS-CPU-Scheduling/"> <link rel="alternate" type="application/rss+xml" title="Jekflix | A blog theme for Jekyll" href="http://localhost:4000/feed.xml" /> <!-- Include extra styles --> <!-- JavaScript enabled/disabled --> <script> document.querySelector('html').classList.remove('no-js'); </script> </head> <body class="has-push-menu"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102 l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10 c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5 v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7 c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46 c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29 c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5 S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15 h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5 C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5 C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5 C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5 C20.224,17,20,16.776,20,16.5z"></path></symbol></defs></svg> <header class="bar-header"> <a id="menu" role="button"> <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg> </a> <h1 class="logo"> <a href="/"> Jekflix <span class="version">v3.1.2</span> </a> </h1> <a id="search" class="dosearch" role="button"> <svg class="icon-search"><use xlink:href="#icon-search"></use></svg> </a> <a href="https://github.com/thiagorossener/jekflix-template" class="get-theme" role="button"> Get this theme! </a> </header> <div id="mask" class="overlay"></div> <aside class="sidebar" id="sidebar"> <nav id="navigation"> <h2>Menu</h2> <ul> <li> <a href="http://localhost:4000/">Home</a> </li> <li> <a href="http://localhost:4000/about">About</a> </li> <li> <a href="http://localhost:4000/contact">Contact</a> </li> <li> <a href="http://localhost:4000/feed.xml">Feed</a> </li> </ul> </nav> </aside> <div class="search-wrapper"> <div class="search-form"> <input type="text" class="search-field" placeholder="Search"> <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg> <ul class="search-results search-list"></ul> </div> </div> <section class="content"> <div id="main" role="main"> <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork"> <meta itemprop="headline" content="[OS] CPU Scheduling"> <meta itemprop="description" content="1, 2 장 출제 x (참고자료로 사용) - 여기까지 시험범위"> <meta itemprop="datePublished" content="2022-09-27T00:00:00+09:00"> <div class="page__inner-wrap"> <header> <h1 id="page-title" class="page__title p-name" itemprop="headline"> <a href="http://localhost:4000/OS-CPU-Scheduling/" class="u-url" itemprop="url">[OS] CPU Scheduling </a> </h1> </header> <section class="page__content e-content" itemprop="text"> <aside class="sidebar__right sticky"> <nav class="toc"> <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header> <!-- Add your table of contents here --> </nav> </aside> <p>1, 2 장 출제 x (참고자료로 사용) - 여기까지 시험범위</p> <p>[toc]</p> <h1 id="chapter-5-cpu-scheduling">Chapter 5: CPU Scheduling</h1> <ul> <li>Basic Concepts</li> <li>Scheduling Criteria</li> <li>Scheduling Algorithms</li> <li>Thread Scheduling</li> <li>Multiple-Processor Scheduling</li> <li>Real-Time CPU Scheduling</li> <li>Operating Systems Examples</li> <li>Algorithm Evaluation</li> </ul> <p><br /></p> <h2 id="objectives">Objectives</h2> <ul> <li>To introduce <strong>CPU scheduling</strong>, which is the basis for multiprogrammed operating systems</li> <li>To describe various CPU-scheduling algorithms</li> <li>To discuss evaluation criteria for selecting a CPU-scheduling algorithm for a particular system</li> <li>To examine the scheduling algorithms of several operating systems</li> </ul> <p><br /></p> <h2 id="basic-concepts">Basic Concepts</h2> <ul> <li>목적: <strong>Maximum CPU utilization</strong> obtained with multiprogramming <span style="color:green">(시험)</span> <ul> <li>When one process has to wait, OS takes the CPU away from that process and gives the CPU to another process</li> </ul> </li> <li>The success of CPU scheduling depends on the property <ul> <li>CPU – I/O Burst Cycle</li> <li>Process execution consists of a cycle of CPU execution and I/O wait. <ul> <li>Process execution begins with CPU burst</li> <li>Process execution ends with CPU burst</li> </ul> </li> </ul> </li> <li>CPU burst distribution <ul> <li>An I/O bound program typically have many very short CPU burst</li> <li>A CPU bound program might have a few very long CPU burst</li> <li>Distribution can be important in the selection of an appropriate CPU scheduling algorithms</li> </ul> </li> </ul> <p><br /></p> <h2 id="alternating-sequence-of-cpu-and-io-bursts">Alternating Sequence of CPU And I/O Bursts</h2> <ul> <li>Maximum CPU utilization obtained with multiprogramming</li> <li>CPU–I/O Burst Cycle – Process execution consists of a cycle of CPU execution and I/O wait</li> <li>CPU burst followed by I/O burst</li> <li>CPU burst distribution is of main concern</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151336894.png" alt="image-20220927151336894" /></p> <p><br /></p> <h2 id="histogram-of-cpu-burst-times">Histogram of CPU-burst Times</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151354687.png" alt="image-20220927151354687" /></p> <p>짧은 CPU burst가 많다. -&gt; multi program이 성공할 수 있는 근거</p> <p><br /></p> <h2 id="cpu-schedulershort-term-scheduler중요시험">CPU Scheduler(short-term scheduler)(중요)<span style="color:green">(시험)</span></h2> <ul> <li><strong>Short-term scheduler</strong> selects from among the processes in memory that are ready to execute, and allocates the CPU to one of them. <ul> <li>Queue may be ordered in various ways</li> <li><strong>Ready queue</strong> may be implemented as FIFO Q, priority Q, tree, linked list</li> </ul> </li> <li>The records in the q are generally PCBs of the processes</li> <li>CPU scheduling decisions may take place when a process: <ol> <li>Switches from <strong>running</strong> to <strong>waiting</strong> state.</li> <li>Switches from <strong>running</strong> to <strong>ready</strong> state.</li> <li>Switches from <strong>waiting</strong> to <strong>ready</strong>. (우선순위가 높은 프로세스의 경우 waiting에서 running으로 갈 여지도 있음)</li> <li><strong>Terminates</strong>.</li> </ol> </li> <li>Scheduling under 1 and 4 is nonpreemptive. <ul> <li>스스로 끝났거나 waiting으로 갔기 때문에</li> </ul> </li> <li>Preemptive scheduling is possible under 2 and 3 <ul> <li>하지만 고려사항이 있음 <ul> <li>Consider access to shared data (data consistency)</li> <li>Consider preemption while in kernel mode (kernel data의 protection)</li> <li>Consider interrupts occurring during crucial OS activities</li> </ul> </li> <li>2번 runnung -&gt; ready : time quantum으로 강제로 CPU를 뺏기 때문</li> <li>waiting에서 event가 completion이 되었다면 running을 해야 하는데 ready를 거쳤다가 가게된다. <ul> <li>이때, 해당 process가 우선순위가 굉장히 높다면 설령 ready queue에 여러 다른 프로세스가 있어도 곧바로 running으로 갈 수 있는 여지도 있다.</li> <li>즉, 우선순위가 무지하게 높은 프로세스가 waiting이 끝나서 ready로 가는 경우 preemption이 일어난다.</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="preemptive-vs-non-preemptive-scheduling">Preemptive vs. Non-preemptive scheduling</h2> <ul> <li>Non-Preemptive scheduling <ul> <li>Once the CPU has been allocated to a process, the process keeps the CPU until it release the CPU either <ul> <li>by terminating or</li> <li>by switching to the waiting state</li> </ul> </li> <li>Windows 3.1 Apple Mach OS</li> </ul> </li> <li>Preemptive scheduling <ul> <li>Case of two processes sharing data</li> <li>Design of Kernel <ul> <li>During the process of system call <ul> <li>UNIX waits either <strong>for a system call to complete</strong> or <strong>for I/O block take place before doing a context switch</strong></li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="dispatcher">Dispatcher</h2> <ul> <li>Dispatcher module gives control of the CPU to the process selected by the short-term scheduler; this involves: <ul> <li>switching context (by OS) <ul> <li>context가 바뀔 때 해당 process가 block 되면서 남긴 running snapshot 정보를 PCB에 저장해 두었다가 다시 실행 될 때 해당 running snapshot을 복원하여 실행된다.</li> </ul> </li> <li>switching to user mode</li> <li>jumping to the proper location in the user program to restart that program</li> </ul> </li> <li>Dispatch latency – time it takes for the dispatcher to stop one process and start another running. <ul> <li>real-time processing을 할 때, 이를 최소화 시키는 것이 중요함.</li> </ul> </li> </ul> <p><br /></p> <h2 id="scheduling-criteria뭐가-더-좋은지를-비교할-수-있는-기준">Scheduling Criteria(뭐가 더 좋은지를 비교할 수 있는 기준)</h2> <ul> <li>Different algorithms have different properties which may favor 1 class of process over another <ul> <li>Need criteria to measure performance of various algorithms</li> <li>목적에 따라 다른 기준 적용</li> </ul> </li> <li>CPU utilization – keep the CPU as busy as possible <span style="color:green">(시험)</span> <ul> <li>Percentage of time CPU is busy <ul> <li>0~100 % CPU <strong>overload</strong>(100), too many waiting jobs <ul> <li>0: CPU가 사용자 process는 사용하지 않고 오직 OS만</li> <li>100: OS는 실행이 안되고 사용자 process만 계속해서 실행됨.</li> </ul> </li> </ul> </li> </ul> </li> <li>Throughput – # of processes that complete their execution per time unit <ul> <li>단위 시간당 얼마나 많은 process가 실행되었는지</li> <li><strong>Size of job affect throughput</strong></li> </ul> </li> <li>Turnaround time – amount of time to execute a particular process (<strong>running + waiting,</strong> not ready)<span style="color:green">(시험)</span> <ul> <li>N개의 job을 실행하는 데 걸린 총 시간</li> <li>process가 실행되고나서 종료될 때까지의 시간</li> <li>Total waiting time at all queues &amp; execution time (batch?) <ul> <li>execution time: running state에서 머문 시간</li> <li>total waiting time at all queues: waiting state에서 머문 시간</li> </ul> </li> </ul> </li> <li>Waiting time <ul> <li>amount of time a process has been waiting <strong>in the ready</strong>, <ul> <li><mark>waiting time은 ready에서 머문 시간!!!!!!!!!!!!!</mark></li> <li>ready는 실행을 하고 싶은데 못하고 있는 상황이기 때문에</li> </ul> </li> <li>CPU scheduling alg. Does not affect the amount of time during which a process executes or does I/O <ul> <li>CPU scheduling 알고리즘이 ready queue에서 대기한 시간에는 영향을 주지만 running 상태나 waiting 상태에서 머문 시간에는 아무런 영향도 주지 않는다.</li> </ul> </li> <li>It affects only the amount of time that a process spends waiting in the Ready Q</li> </ul> </li> <li>Response time – amount of time it takes from when a request was submitted until the first response is produced, not output (for time-sharing environment) <ul> <li>프로세스 요청(실행 요구)된 순간부터 사용자가 응답을 받은 딱 그 순간까지 걸린 시간</li> </ul> </li> </ul> <p><br /></p> <h2 id="optimization-criteria">Optimization Criteria</h2> <ul> <li>Max CPU utilization</li> <li>Max throughput</li> <li>Min turnaround time</li> <li>Min waiting time</li> <li>Min response time</li> <li><strong>Fairness</strong> <ul> <li>No particular job should be overly penalized(피해를 받는) through CPU scheduling</li> <li>리눅스의 aging 기법과 같은 애가 이를 해결함.(일정 시간이 지날수록 우선순위가 점점 높아짐)</li> </ul> </li> </ul> <p><br /></p> <h2 id="scheduling-wo-multiprogramming">Scheduling w/o Multiprogramming</h2> <ul> <li>Process A, B : each job requires 4 sec CPU time</li> <li>Assuming each exhibit following behavior <ul> <li>CPU burst 1sec, I/O burst 1 sec -&gt; 완전히 실행되기 위해선 4sec CPU burst, 3 sec I/O burst 필요</li> <li>Strategy: 1 job run to completion</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151918471.png" alt="image-20220927151918471" /></p> <ul> <li>CPU utilization = busy time / total = 8/14 = 57 %</li> <li>Throughput = 2 jobs/ 14 secs = 1/7</li> <li>Turnaround time</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151937774.png" alt="image-20220927151937774" /></p> <p><br /></p> <h2 id="scheduling-with-multiprogramming">Scheduling with Multiprogramming</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927151959948.png" alt="image-20220927151959948" /></p> <ul> <li>Throughput = 1/4 (not 1/7, 위 사진에서 오타남)</li> </ul> <p><br /></p> <h2 id="scheduling-types">Scheduling Types</h2> <ul> <li>Non Preemptive (internal stimulus) <ul> <li>Job allocated CPU and can remain an CPU until <ul> <li>Completes, I/O request, System call</li> </ul> </li> </ul> </li> <li>Preemptive (external stimulus) <ul> <li>A job on CPU can be removed (at any time) and replaced with <strong>another user process</strong></li> </ul> </li> </ul> <p><br /></p> <h2 id="first-come-first-servedfcfs-scheduling">First-Come, First-Served(FCFS) Scheduling</h2> <ul> <li>Non-preemptive</li> <li>Jobs are given time on CPU in order in which request in (ready queue)</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152101148.png" alt="image-20220927152101148" /></p> <ul> <li>Suppose that the processes arrive in the order: P1 , P2 , P3 The Gantt Chart for the schedule is:</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152113269.png" alt="image-20220927152113269" /></p> <ul> <li>Waiting time for P1 = 0; P2 = 24; P3 = 27 <ul> <li>Average waiting time: (0 + 24 + 27)/3 = 17</li> </ul> </li> </ul> <p><br /></p> <h2 id="fcfs-scheduling-cont">FCFS Scheduling (Cont.)</h2> <p><strong>Suppose</strong> that the processes arrive in the order P2 , P3 , P1 .</p> <ul> <li>The Gantt chart for the schedule is:</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152157395.png" alt="image-20220927152157395" /></p> <ul> <li>Waiting time for P1 = 6; P2 = 0; P3 = 3 <ul> <li>Average waiting time: (6 + 0 + 3)/3 = 3</li> </ul> </li> <li>Much better than previous case.</li> <li><strong>Convoy effect</strong> - short process behind long process <ul> <li>short process가 long process 뒤에 서있는 효과</li> <li>쇼핑카트에 물건이 많은 사람이 맨 앞에 서있으면 오래 걸림.</li> </ul> </li> <li>CPU bound job may benefit <ul> <li>CPU utilization이 높아지기 때문에</li> </ul> </li> <li>I/O bound may be penalized <ul> <li>waiting 시간이 길어지기 때문에</li> </ul> </li> </ul> <p><br /></p> <h2 id="fcfs-scheduling-cont-1">FCFS Scheduling (Cont.)</h2> <ul> <li>Problem <ul> <li>Wide variance in turnaround time <span style="color:green">(시험)</span></li> <li>Suceptible(민감) to convoy effect</li> <li>Bad for small jobs</li> <li>Troublesome for timesharing system</li> </ul> </li> <li>Advantage <ul> <li>Easy to implement</li> <li>Fast (to pick next job to run)</li> </ul> </li> </ul> <p><br /></p> <h2 id="shortest-job-first-sjf-scheduling">Shortest-Job-First (SJF) Scheduling</h2> <ul> <li>Associate with each process the length of its next CPU burst. <ul> <li>Use these lengths to schedule the process with the shortest time.</li> <li>Ready list is sorted in increasing order</li> </ul> </li> <li>Two schemes: <ul> <li><strong>Non-preemptive</strong> <ul> <li>once CPU given to the process it cannot be preempted until completes its CPU burst.</li> </ul> </li> <li>Preemptive <ul> <li>if a new process arrives with CPU burst length <strong>less than remaining time of current executing process</strong>, preempt(뺏는다.).</li> <li>This scheme is known as the Shortest-Remaining-Time-First (SRTF).</li> </ul> </li> </ul> </li> <li>SJF is optimal – gives minimum average waiting time for a given set of processes. <ul> <li>The difficulty is knowing the length of the next CPU request</li> <li><strong>How to know length of the next CPU burst?</strong> -&gt; Could ask the user(정확도가 좀 떨어짐)</li> </ul> </li> </ul> <p><br /></p> <h2 id="example-of-non-preemptive-sjf">Example of Non-Preemptive SJF</h2> <p>이해를 위해 실제로 그럴 확률은 적지만 I/O burst가 없는 상황을 예로 보겠다.</p> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152353544.png" alt="image-20220927152353544" /></p> <ul> <li> <p>SJF (non-preemptive)</p> </li> <li> <p>P2가 먼저 왔더라도 P1이 실행된 이후에 Burst time을 따져봤을 때 P3가 더 짧기 때문에 먼저 실행한다.</p> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152405017.png" alt="image-20220927152405017" /></p> <ul> <li>Average waiting time = (0 + 6 + 3 + 7)/4 = 4</li> </ul> <p><br /></p> <h2 id="example-of-preempitve-sjf">Example of Preempitve SJF</h2> <p><mark>아래 차트 그리는 문제 나올 듯</mark></p> <p>앞과 같은 예제 - preemptive 버전</p> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152427425.png" alt="image-20220927152427425" /></p> <ul> <li>SJF (preemptive)</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152440692.png" alt="image-20220927152440692" /></p> <ul> <li>running 상태에 진입을 했어도 preemption 조건이 만족되면 preempt를 실행한다. <ul> <li>P1은 0초에 도착하여 P1 밖에 없으므로 실행을 하다가 2초가 되었을 때 P2가 도착하는데 이 때 P1의 남은 Burst Time은 5초이고 P2는 4초이므로 preemption을 진행하여 P2가 CPU를 빼앗아 실행을 진행한다.</li> </ul> </li> <li>Average waiting time = (9 + 1 + 0 + 2) / 4 = 3</li> </ul> <p><br /></p> <h2 id="example-of-shortest-remaining-time-first">Example of Shortest-remaining-time-first</h2> <ul> <li>Now we add the concepts of varying arrival times and preemption to the analysis</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152507314.png" alt="image-20220927152507314" /></p> <ul> <li>Preemptive SJF Gantt Chart</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152518038.png" alt="image-20220927152518038" /></p> <ul> <li>Average waiting time = [(10-1)+(1-1)+(17-2)+5-3)]/4 = 26/4 = 6.5 msec</li> </ul> <p><br /></p> <h2 id="problem">problem</h2> <ul> <li>Starvation - 프로세스가 끊임없이 필요한 컴퓨터 자원을 가져오지 못하는 상황 <ul> <li>fairness 문제</li> <li>The granting of service to particular job is postponed forever</li> <li>Infinite wait</li> <li>Ex) job A 20 <ul> <li>B 3</li> <li>C 3 …</li> <li>A가 너무 길어서 다른 프로세스가 올 때마다 다른 프로세스를 실행하느라 A를 계속 실행을 못하게 됨</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="determining-length-of-next-cpu-burst">Determining Length of Next CPU Burst</h2> <ul> <li>Although SJF is optimal, it <strong>can not be implemented</strong>. <ul> <li>There is <strong>no way to know</strong> the length of the next CPU burst</li> <li>Can only predict the length.</li> </ul> </li> <li>The next CPU burst is <strong>predicted</strong> as an exponential average of the measured lengths of previous CPU burst</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152732740.png" alt="image-20220927152732740" /></p> <ul> <li>Commonly, α set to ½</li> </ul> <p><br /></p> <h2 id="examples-of-exponential-averaging">Examples of Exponential Averaging</h2> <ul> <li>α =0 <ul> <li>tau<sub>n+1</sub> = tau<sub>n</sub></li> <li>Recent history does not count.</li> <li>Current conditions are assumed to be transient</li> </ul> </li> <li>α =1 <ul> <li>tau<sub>n+1</sub> = t<sub>n</sub></li> <li>전에 실행되었던 실측치 만으로 tau_n+1 을 결정</li> <li>Only the actual last CPU burst counts.</li> <li>History is assumed to be <strong>old</strong> and <strong>irrelevant</strong> (Fig. 5.3 α =0.5)</li> </ul> </li> <li>If we expand the formula, we get:</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927152922082.png" alt="image-20220927152922082" /></p> <ul> <li>Since both α and (1 - α) are less than or equal to 1, each successive term has less weight than its predecessor <ul> <li>그 전보다 낮은 weight를 가지게 됨</li> </ul> </li> </ul> <p><br /></p> <h2 id="prediction-of-the-length-of-the-next-cpu-burst">Prediction of the Length of the Next CPU Burst</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153000704.png" alt="image-20220927153000704" /></p> <p>tau가 실측치 t에 거의 근사한 모습이다.</p> <p><br /></p> <h2 id="priority-scheduling">Priority Scheduling</h2> <ul> <li>A <strong>priority</strong> number (임의로 주어진 integer) is associated with <strong>each process</strong> <ul> <li>SJF와는 조금 다름(SJF는 next CPU burst time만으로 결정)</li> <li>PS는 각 process에게 주어진 priority number로 결정</li> </ul> </li> <li>The CPU is allocated to the process with the highest priority (smallest integer = highest priority). <ul> <li>Preemptive <ul> <li>Control the length of time a job is on CPU</li> <li>실행 중간에 자기보다 우선순위가 높은 애가 생기면 뺏김.</li> </ul> </li> <li>Non-preemptive</li> </ul> </li> <li>SJF is a priority scheduling where priority is the predicted next CPU burst time.</li> <li>Problem define = Starvation –&gt; low priority processes may never execute.</li> <li><strong>Solution</strong> define = <strong>Aging</strong> –&gt; as time progresses, increase the priority of the process <ul> <li>ready queue에 머문 시간이 길어질 수록 priority가 높아짐</li> </ul> </li> </ul> <p><br /></p> <h2 id="example-of-priority-scheduling">Example of Priority Scheduling</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153130274.png" alt="image-20220927153130274" /></p> <ul> <li>Priority scheduling Gantt Chart</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153142972.png" alt="image-20220927153142972" /></p> <ul> <li>Average waiting time = 41/5 = 8.2 msec</li> </ul> <p><br /></p> <h2 id="round-robin-rr">Round Robin (RR)</h2> <ul> <li>Designed for time sharing systems</li> <li>Each process gets a small unit of CPU time (<strong>time quantum</strong>), usually 10-100 milliseconds. After this time has elapsed, the process is preempted and added to the <strong>end</strong> of the ready queue. <ul> <li>time quantum: running state에서 머무를 수 있는 최대 시간</li> </ul> </li> <li>If there are n processes in the ready queue and the time quantum is q, then each process gets 1/n of the CPU time in chunks of at most q time units at once. <mark>No process waits more than (n-1)q time units. </mark> <ul> <li><strong>fairness 보장</strong>하는 방식!!!</li> </ul> </li> <li>Performance of RR <strong>depends</strong> heavily on the <strong>size of Time Quantum</strong> <ul> <li>q large =&gt; FIFO <ul> <li>Good for CPU bound, bad for interactive job</li> <li>Less context switch</li> </ul> </li> <li>q small =&gt; <ul> <li>Processor sharing <ul> <li>Appears(착각) to user as though each of n processes has its own processor running at 1/n the speed of real processor</li> </ul> </li> <li>q must be large with respect to context switch, otherwise overhead is too high. <ul> <li>context switching을 너무 자주 하면서 생기는 overhead</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="example-rr-with-time-quantum--20">Example: RR with Time Quantum = 20</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153348488.png" alt="image-20220927153348488" /></p> <ul> <li>The Gantt chart is:</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153357582.png" alt="image-20220927153357582" /></p> <ul> <li>P2는 burst time이 17이라 20이라는 time quantum을 다 사용하지 않고 마무리됨</li> <li>Typically, <strong>higher average turnaround</strong> than SJF, <strong>but better response</strong>.</li> <li>q should be large compared to context switch time</li> <li>q usually 10ms to 100ms, context switch &lt; 10 usec</li> </ul> <p><br /></p> <h2 id="how-a-smaller-time-quantum-increases-context-switches">How a Smaller Time Quantum Increases Context Switches</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153433105.png" alt="image-20220927153433105" /></p> <p>high time quantum makes overhead</p> <p><br /></p> <h2 id="turnaround-time-varies-with-the-time-quantum">Turnaround Time Varies With The Time Quantum</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153457114.png" alt="image-20220927153457114" /></p> <p>올바른 time quantum 값을 정하기 어려움(비례하거나 반비례하지 않음)</p> <p><br /></p> <h2 id="mulitilevel-queue-scheduling">Mulitilevel Queue Scheduling</h2> <ul> <li><strong>Ready queue is partitioned</strong> into separate <strong>queues</strong>: foreground (interactive) background (batch)</li> <li>Process permanently in a given queue</li> <li>Each queue has its own scheduling algorithm, <ul> <li><strong>foreground – RR (Round Robin)</strong></li> <li><strong>background – FCFS (First come First served)</strong></li> </ul> </li> <li>Scheduling must be done between the queues. <ul> <li>Fixed priority preemptive scheduling; <ul> <li>i.e., serve all from foreground then from background. (foreground에 하나라도 있으면 그거먼저(preemption) scheduling)</li> <li>Possibility of starvation.</li> </ul> </li> <li>Time slice – each queue gets a certain amount of CPU time which it can schedule amongst its processes; i.e., 80% to foreground in RR, 20% to background in FCFS <ul> <li>starvation reduces</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="multilevel-queue-scheduling">Multilevel Queue Scheduling</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153552854.png" alt="image-20220927153552854" /></p> <p><br /></p> <h2 id="multilevel-feedback-queue-scheduling">Multilevel Feedback Queue Scheduling</h2> <p>feedback을 허용하는 방식</p> <ul> <li><strong>In a Multi-level queue</strong> scheduling, processes are permanently assigned to a queue on entry to the system (queue 간의 이동을 금지) <ul> <li>Processes do not move between queues</li> </ul> </li> <li>A process can move between the various queues; <ul> <li>If a process uses too much CPU time, it will be moved to a lower priority queue</li> <li>A process that waits too long in a lower priority queue may be moved to a higher priority queue <ul> <li>aging can be implemented this way. (prevents starvation)</li> </ul> </li> </ul> </li> <li>Multilevel-feedback-queue scheduler defined by the following parameters: <ul> <li>number of queues</li> <li>scheduling algorithms for each queue</li> <li>method used to determine when to upgrade a process</li> <li>method used to determine when to demote a process</li> <li>method used to determine which queue a process will enter when that process needs service <ul> <li>I/O bound or interactive processes to the higher priority q</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="multilevel-feedback-queues">Multilevel Feedback Queues</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927153706500.png" alt="image-20220927153706500" /></p> <p>interactive 성격을 띠는 process는 CPU burst time이 짧기 때문에 quantum 값을 작게 준다.</p> <ul> <li>아래로 갈 수록 우선순위가 낮은 큐</li> </ul> <p>우선순위가 낮아질 수록 quantum 값을 크게 줌.</p> <p>FCFS는 time quantum이 존재하지 않는다.</p> <ul> <li>사용할 수 있다면 CPU time을 만들어 바로 사용할 수 있는 방식이기 때문에</li> </ul> <p><br /></p> <h2 id="example-of-multilevel-feedback-queue">Example of Multilevel Feedback Queue</h2> <ul> <li>Three queues: <ul> <li>Q0 – RR, time quantum 8 milliseconds</li> <li>Q1 – RR, time quantum 16 milliseconds</li> <li>Q2 – FCFS</li> </ul> </li> <li>Scheduling <ul> <li>A new job enters queue Q0 which is served FCFS. <ul> <li>When it gains CPU, job receives 8 milliseconds.</li> <li>If it does not finish in 8 milliseconds, job is moved to queue Q1 .</li> </ul> </li> <li>At Q1 job is again served FCFS and receives 16 additional milliseconds. <ul> <li>If it still does not complete, it is preempted and moved to queue Q2</li> </ul> </li> </ul> </li> <li>우선순위가 높은 곳에서도 안 끝나면 넌 낮은데로 가버렷! 그래도 안 끝나면 넌 FCFS로 가버렷!(무조건 끝나게)</li> </ul> <p><br /></p> <h2 id="review-scheduler-activations">Review: Scheduler Activations</h2> <ul> <li>Communication between kernel and <strong>thread library</strong> <ul> <li>Both M:M and Two-level models require communication to maintain the appropriate number of kernel threads allocated to the application</li> <li>This communication allows an application to maintain the correct number kernel threads for performance</li> </ul> </li> <li>Typically use an intermediate data structure between user and kernel threads - <strong>lightweight process (LWP)</strong> : 자료구조의 일종(유저스레드와 커널스레드에 mapping 정보를 담는) <ul> <li>한 애플리케이션에서 사용될 커널 스레드의 갯수를 타협하는 애</li> <li>Appears to be a virtual processor on which process can schedule user thread to run</li> <li>Each LWP attached to kernel thread</li> <li>OS schedules kernel threads to run on a physical processor</li> <li>If a kernel thread blocks, LWP blocks, and user-level thread attached to LWP also blocks</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154038193.png" alt="image-20220927154038193" /></p> <ul> <li>OS의 CPU scheduler가 하는 결정: 여러 개 커널 thread 중에서 어떤 커널 thread가 먼저 실행 될지 <ul> <li>CPU에 의해서 실행되기 때문에 kernel thread라고 불리는 것.</li> </ul> </li> <li>user level(<mark>thread library</mark>)하는 결정: 어떤 user thread가 LWP에 할당될 것인가</li> </ul> <p><br /></p> <h2 id="review-scheduler-activations-1">Review: Scheduler Activations</h2> <p>How many LWPs(i.e., kernel thread) to create? (for user thread)</p> <ul> <li>CPU-bound application running on a processor: <ul> <li>only one thread can run at a time, so one LWP is sufficient</li> <li>Other type of application may require multiple LWPs (concurrent threads)</li> </ul> </li> <li>An LWP is required for each concurrent blocking system call</li> <li>Scheduler activations <ul> <li>a communication mechanism from the kernel to the thread library</li> <li>Kernel provides an application with a set of LWPs</li> <li>Kernel must inform an application about certain events (upcall) <ul> <li>Ex: <strong>notify which application thread is about to block</strong> -&gt; 그럼 다른 유저스레드 할당할 수 있겠네??</li> <li>Upcalls are handled by the thread library with an upcall handler, which must run on a LWP – Kernel allocates a new LWP to the application, <ul> <li>available kernel thread의 갯수를 조정해주는 -&gt; upcall</li> </ul> </li> <li>upcall handler 실행, blocking thread의 state save</li> <li>blocking thread를 실행하던 기존 LWP는 반납</li> <li>upcall handler는 이 LWP에 다른 thread를 scheduling 함.</li> <li>Blocking 해제시, event upcall 처리용 LWP, block되었던 thread 실행용 LWP 할당</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="thread-scheduling-contention-scope">Thread Scheduling: Contention scope</h2> <ul> <li>When threads supported by OS, <strong>threads</strong> (not processes) are scheduled,</li> <li>user-level과 kernel-level threads의 차이는 scheduling 되는 방법에 있음</li> <li>User-level threads are managed by thread library, kernel is unaware of them <ul> <li>To run on CPU, user-level threads should be mapped to kernel-level threads</li> <li>Typically use an intermediate data structure between user and kernel threads called <strong>lightweight process (LWP)</strong> <ul> <li>Appears to be a virtual processor on which process can schedule user thread to run</li> <li>Thread library schedules user-level threads to run on available LWP <ul> <li>CPU에 의해 실행되는 것을 의미하는 것이 아님.</li> </ul> </li> <li>Each LWP attached to kernel thread</li> <li>How many LWPs to create? - managed by thread library</li> </ul> </li> <li>Known as <strong>process-contention scope (PCS)</strong> <mark>since scheduling competition is within the process  </mark><span style="color:green">(시험)</span> <ul> <li>어플리케이션 내에서</li> </ul> </li> <li>PCS is done via priority set by programmer</li> <li>Both M:M and Two-level models require communication to maintain the appropriate number of kernel threads allocated to the application</li> </ul> </li> </ul> <p><br /></p> <h2 id="contention-scope시험">Contention scope<span style="color:green">(시험)</span></h2> <ul> <li>Kernel thread are scheduled onto available CPU is <strong>system-contention scope</strong> (SCS) – competition <strong>among all threads in system</strong></li> <li>System using O:O(one-to-one) model (window, Linux) schedules threads <strong>using only SCS</strong> <ul> <li>선발할 이유가 없음, 어차피 OS는 소속을 보지 않기 때문에</li> </ul> </li> </ul> <p><br /></p> <h2 id="pthread-scheduling">Pthread Scheduling</h2> <ul> <li>We studied POSIX Pthread programming in previous chapter <ul> <li>pthread_create( )</li> </ul> </li> <li>API allows specifying either PCS or SCS during thread creation <ul> <li>PTHREAD_SCOPE_PROCESS schedules threads using PCS scheduling</li> <li>PTHREAD_SCOPE_SYSTEM schedules threads using SCS scheduling</li> </ul> </li> <li>Can be limited by OS – Linux and Mac OS X only allow PTHREAD_SCOPE_SYSTEM</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154217241.png" alt="image-20220927154217241" /></p> <p><br /></p> <h2 id="pthread-scheduling-api시험">Pthread Scheduling API<span style="color:green">(시험)</span></h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="c1"> </span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="c1"> </span><span class="cp">
#define NUM_THREADS 5 
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span> 
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">scope</span><span class="p">;</span>
    <span class="n">pthread_t</span> <span class="n">tid</span><span class="p">[</span><span class="n">NUM</span> <span class="n">THREADS</span><span class="p">];</span> 
    <span class="n">pthread_attr_t</span> <span class="n">attr</span><span class="p">;</span> 
    <span class="cm">/* get the default attributes */</span> 
    <span class="n">pthread_attr_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">);</span> 
    <span class="cm">/* first inquire on the current scope */</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pthread_attr_getscope</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">scope</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to get scheduling scope</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="k">else</span> <span class="p">{</span> 
        <span class="k">if</span> <span class="p">(</span><span class="n">scope</span> <span class="o">==</span> <span class="n">PTHREAD_SCOPE_PROCESS</span><span class="p">)</span> 
            <span class="n">printf</span><span class="p">(</span><span class="s">"PTHREAD_SCOPE_PROCESS"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">scope</span> <span class="o">==</span> <span class="n">PTHREAD_SCOPE_SYSTEM</span><span class="p">)</span> 
            <span class="n">printf</span><span class="p">(</span><span class="s">"PTHREAD_SCOPE_SYSTEM"</span><span class="p">);</span> 
        <span class="k">else</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Illegal scope value.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="p">}</span>
    <span class="cm">/* set the scheduling algorithm to PCS or SCS */</span> 
    <span class="n">pthread_attr_setscope</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="n">PTHREAD_SCOPE_SYSTEM</span><span class="p">);</span> 
    <span class="cm">/* create the threads */</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
        <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span><span class="n">runner</span><span class="p">,</span><span class="nb">NULL</span><span class="p">);</span> 
    <span class="cm">/* now join on each thread */</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM_THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
        <span class="n">pthread_join</span><span class="p">(</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span> 
<span class="p">}</span> 
<span class="cm">/* Each thread will begin control in this function */</span> 
<span class="kt">void</span> <span class="o">*</span><span class="nf">runner</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">param</span><span class="p">)</span>
<span class="p">{</span> 
    <span class="cm">/* do some work ... */</span> 
    <span class="n">pthread_exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> 
<span class="p">}</span> 

</code></pre></div></div> <p><br /></p> <h2 id="multiple-processor-scheduling">Multiple-Processor Scheduling</h2> <ul> <li>CPU scheduling more complex when multiple CPUs are available.</li> <li>Multiprocessor system <ul> <li>Systems that provide multiple processors, each one contains single-core CPU</li> <li>Currently, applies to <ul> <li>Multi-core CPU</li> <li>Multi-threaded cores</li> <li>NUMA(non uniform memory access) systems <ul> <li>CPU마다 자기만 access하는 memory가 있다. (그래서 memory마다 접근하는 시간이 다 다르다.)</li> </ul> </li> <li>Heterogeneous multiprocessing (하는 일 특화)</li> </ul> </li> </ul> </li> <li><strong>Homogeneous processors</strong> within a multiprocessor. <ul> <li>Any available processor can be used to run any process in the queue</li> </ul> </li> <li><strong>Heterogeneous processors</strong> <ul> <li>Only programs compiled for a given processor’s instruction set could be run on that processor</li> </ul> </li> <li>Allows several processes to run <strong>in parallel by providing multiple physical processors</strong></li> </ul> <p><br /></p> <h2 id="approaches-to-multiple-processor-scheduling">Approaches to Multiple-Processor Scheduling</h2> <ul> <li><strong>Asymmetric</strong> multiprocessing <ul> <li>only one processor handles scheduling decision, I/O processing and system activities such as accessing the system data structures <ul> <li>cpu 중에 대장인 master cpu가 있다.</li> <li>한 cpu가 스케쥴링, I/O 프로세싱을 지시하고 나머지 cpu는 시키는 일을 받아서 한다.</li> </ul> </li> <li>The other processors only execute use code</li> <li>alleviating the need for data sharing. (메모리 쉐어링을 할 필요가 없음.)</li> <li>Much simpler than symmetric multiprocessing</li> </ul> </li> <li><strong>Symmetric</strong> multiprocessing (SMP) - each processor is <strong>self-scheduling</strong>, <ul> <li>모두 동등한 cpu이다. 스케쥴링도 cpu 별로 각자 알아서 한다</li> <li>all processes in common ready queue (has race condition problem),</li> <li>or each has its own private queue of ready processes <ul> <li>Currently, most common</li> </ul> </li> <li>Load sharing <ul> <li>Common ready queue, and are scheduled onto any available processor</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="multiple-processor-scheduling---load-balancing">Multiple-Processor Scheduling - Load Balancing</h2> <ul> <li>If SMP, need to keep all CPUs loaded for efficiency</li> <li>Load balancing attempts to keep workload evenly distributed</li> <li>Push migration – periodic task checks load on each processor, and if found pushes task from overloaded CPU to other CPUs <ul> <li>실행 상태(live)에서 이주 시킨다.</li> </ul> </li> <li>Pull migration – idle(한가한) processors pulls waiting task from busy processor</li> </ul> <p><br /></p> <h2 id="processor-affinity친화적인">Processor affinity(친화적인)</h2> <ul> <li> <p>CPU 별로 특성이 있는 경우</p> </li> <li>실행중인 프로세서에서 계속 실행시키면 <ul> <li>Cache memory 잔상을 이용하여 fast successive memory access 효과 기대</li> </ul> </li> <li>common ready queue</li> <li>private ready queue : 보다 나은 processor affinity 효과</li> <li>process has affinity for processor on which it is currently running <ul> <li>soft affinity : process affinity를 반드시 보장해야 하는 것은 아닌 <ul> <li>되도록이면 이렇게 하자</li> </ul> </li> <li>hard affinity : 반드시 보장해야 하는 <ul> <li>무조건 이렇게 해야 해</li> </ul> </li> <li>Variations including processor sets</li> </ul> </li> <li>프로세스가 돌다가 waiting 상태가 되었을 때 다시 돌아오려고 할 때 돌던 곳으로 돌아와서 실행하는 것이 좋은가 아니면 load balance를 고려했을 때 해당 프로세스가 실행될 지점의 load가 큰 경우 어떻게 해야 하는가?</li> </ul> <p><br /></p> <h2 id="numa-and-cpu-scheduling">NUMA and CPU Scheduling</h2> <p>Memory architecture도 processor affinity에 영향을 줌</p> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154620887.png" alt="image-20220927154620887" /></p> <p>Note that memory-placement algorithms can also consider affinity</p> <p><br /></p> <h2 id="multicore-processors">Multicore Processors</h2> <ul> <li>Recent trend to place multiple processor cores on same physical chip</li> <li>Each core appears to OS to be a separate logical CPU</li> <li>Faster and consumes less power</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154656267.png" alt="image-20220927154656267" /></p> <p><br /></p> <h2 id="multicore-processors-1">Multicore Processors</h2> <ul> <li>Memory stall <ul> <li>메모리 access 와 CPU 성능 차이 때문에 CPU가 놀고 있는 것</li> </ul> </li> <li>Resulted from speed gap between CPU and memory, cache miss</li> <li>Multiple threads per core also growing <ul> <li>Takes advantage of memory stall to make progress on another thread while memory retrieve happens</li> </ul> </li> <li><strong>Multithreaded processing core</strong> in which several <strong>hardware threads</strong> are assigned to each core <strong>(chip multi-threading or hyper-threading)</strong> <ul> <li>If one hardware thread stalls while waiting for memory, the core can switch to another thread</li> <li>Oracle Sparc M7 processor 8 threads per core, 8 cores per processor, thus providing OS with 64 logical CPUs</li> </ul> </li> </ul> <hr /> <p>atomic operation: instruction cycle을 중지시킬 interrupt는 존재하지 않음.</p> <hr /> <p><br /></p> <h2 id="multithreaded-multicore-system">Multithreaded Multicore System</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927154752640.png" alt="image-20220927154752640" /></p> <p>hyper thread: memory stall 시간 안에 여러 개의 thread를 concurrent하게 실행 함.</p> <p><br /></p> <h2 id="heterogeneous-multiprocessing">Heterogeneous multiprocessing</h2> <ul> <li><strong>Homogeneous multiprocessing</strong> <ul> <li>All processors are identical in terms of capabilities, allowing any thread can run any processing core</li> <li>Memory access time can be vary according to load balancing, processor affinity policy,</li> </ul> </li> <li>Mobile systems include multi-core architecture that run the same instruction set <ul> <li>But each core may be different in terms of clock speed, power consumption management</li> <li>For ARM processors, Higher performance big core consumes more energy</li> <li>Little core consumes less energy</li> <li>CPU scheduler assign tasks considering the characteristics of task</li> </ul> </li> </ul> <p><br /></p> <h2 id="real-time-systems">Real-Time systems</h2> <ul> <li> <p>일 처리가 의미있는 시간 안에 완료되는 System</p> </li> <li><strong>Hard real-time systems</strong> - required to complete <strong>a critical task</strong> within a guaranteed amount of time. <ul> <li>Resource reservation</li> <li>Scheduler should know exactly how long each os function takes to perform and be guaranteed to take a maximum amount of time</li> <li>Such a guarantee is impossible in a general purpose system</li> <li>프로세스가 탑재되기 전에 실행 시간이 미리 정해져 있음</li> </ul> </li> <li><strong>Soft real-time systems</strong> – requires that critical processes receive priority over less fortunate ones. <ul> <li>전화가 연결될 때 ring-back tone과 같은(특정 시간 안에 끝나는 것이 보장되지 않음) <ul> <li>ring-back tone이 routing이 빠르게 되면 금방 들리겠지만 routing이 느리게 되면 몇십초 있다가 들릴 수 있다.</li> </ul> </li> <li>Priority scheduling w/O aging <ul> <li>Starvation possible</li> </ul> </li> <li>Dispatch latency must be small <ul> <li>The smaller the dispatch latency, the faster a real-time process can start execution once it is runnable</li> <li>Many os waits for either a system call to complete or for an I/O block to take place before doing a context switch</li> <li>Dispatch latency can be long</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="real-time-scheduling">Real-Time Scheduling</h2> <ul> <li>In general, real-time operating systems must provide: <ol> <li>Preemptive, priority-based scheduling</li> <li>Preemptive kernels</li> <li>Latency must be minimized</li> </ol> </li> </ul> <p>kernel code를 실행 중에 우선순위가 높은 프로세스가 들어오면 preemption</p> <p><br /></p> <h2 id="event-latency">Event Latency</h2> <ul> <li>Event latency is the amount of time from when an event occurs to when it is serviced. <ul> <li>Software event – timer expiration</li> <li>Hardware event</li> </ul> </li> <li>Different latency requirements for the events</li> <li>It should be minimize event latency</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155042925.png" alt="image-20220927155042925" /></p> <p><br /></p> <h2 id="real-time-cpu-schduling">Real-Time CPU Schduling</h2> <ul> <li>Soft real-time systems - no guarantee as to when critical realtime process will be scheduled</li> <li>Hard real-time systems - task must be serviced by its deadline</li> <li>Two types of latencies affect performance <ol> <li><strong>Interrupt latency</strong> – time from arrival of interrupt at CPU to start of routine that services interrupt <ul> <li>interrupt가 발생하고 (CPU가 인지하고) ISR(Interrupt Service Routine)이 실행되는 시간까지의 간격</li> </ul> </li> <li><strong>Dispatch latency</strong> – time for schedule to take current process off CPU and switch to another <ul> <li>현재 돌고있는 프로세스를 끌어내리고 새로 run 할 프로세스로 바꾸는 시간</li> </ul> </li> </ol> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155301424.png" alt="image-20220927155301424" /></p> <ul> <li> <p>In Linux ISR이 두 개로 나눠짐, Top half, Bottom half</p> </li> <li>interrupt를 CPU가 감지하기 까지 걸린 시간(delay) <ul> <li>interrupt 우선순위가 낮을 수록 이 delay가 커진다.</li> </ul> </li> <li>context switch: 프로세스의 잔상을 저장 <ul> <li>우선순위가 높은 놈이 있으면 interrupt를 처리하고 다시 되돌아 온다는 보장이 없는데 그러면 되돌아오지 않기 때문에 context switching이 필요하다.</li> </ul> </li> <li>interrupt latency: 이벤트가 발생한 시점부터 ISR이 딱 실행될 때까지의 시간</li> </ul> <p><br /></p> <h2 id="interrupt-latency">Interrupt latency</h2> <ul> <li>Kernel Data structure가 수정되는 동안 Interrupt disable 된 시간 최소화</li> </ul> <p><br /></p> <h2 id="dispatch-latency시험">Dispatch latency<span style="color:green">(시험)</span></h2> <ul> <li>Amount of time required for dispatcher to stop one process and start another.</li> <li>To keep dispatch latency low, we need to allow <ul> <li><strong>Conflict phase</strong> of dispatch latency (수 msecs): <span style="color:green">(시험)</span> <ul> <li>Preemption of any process running in the kernel</li> <li>Release by low-priority processes <strong>resources</strong> needed by a high-priority <ul> <li>우선순위가 낮은 프로세스가 자원을 갖고 있는 경우 priority inversion</li> <li>prioity inversion: 순식간에 우선순위를 확 올려줘서 빨리 끝내게 하는</li> <li>ex) system call을 실행 중에 우선순위가 높은 놈이 큐에 들어오면 preemption이 진행되어야 하는데 안전하게 system call이 끝난 뒤에 하자니 real-time system이 보장되지 않기 때문에 이를 kernel에서 뺏어야 하는데 우선 순위가 높은 놈이 지금 쓰고 있던 놈의 자원을 필요로 할 수 있기 때문에 이를 priority inversion을 사용해서 너 높은 우선순위 줄테니까 빨리 끝내!!! 하고 끝나면 다시 원래의 값으로 돌린다.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155343341.png" alt="image-20220927155343341" /></p> <ul> <li>interrupt processing: interrupt latency + ISR time</li> <li>dispatch latency</li> </ul> <p><br /></p> <h2 id="dispatch-latency">Dispatch latency</h2> <ul> <li>Insert preemption points in long duration system calls, which check to see whether a high priority process needs to be run <ul> <li>Context switch can be taken place only at preemption points</li> <li>Preemption points can be placed at only safe locations in kernel <ul> <li>Kernel data structures are not being modified</li> </ul> </li> <li>Only a few preemption points possible</li> </ul> </li> <li>Make the entire kernel pre-emptible <ul> <li>All kernel DS must be protected through the use of synchronization mechanism</li> <li>Priority inversion <ul> <li>Higher priority process needs to read or modify kernel data that are currently being accessed by lower priority process</li> <li>Higher priority process would be waiting for a lower priority one to finish</li> <li>Can be solved by priority inheritance protocol, in which all low priority processes inherit the high priority until they are done with the resource in question <ul> <li>When they are finished, their priority reverts to its original value</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="priority-based-scheduling">Priority-based Scheduling</h2> <ul> <li>For real-time scheduling, scheduler must support preemptive, priority-based scheduling <ul> <li>But only guarantees soft real-time</li> </ul> </li> <li>For hard real-time must also provide ability to meet deadlines <ul> <li>deadline이 중요!</li> <li>Admission control</li> </ul> </li> <li>Processes have new characteristics: periodic ones require CPU at constant intervals <ul> <li>Has processing time t, deadline d, period p</li> <li>0 ≤ t ≤ d ≤ p</li> <li>Rate of periodic task is 1/p</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155522120.png" alt="image-20220927155522120" /></p> <ul> <li>p: event 처리 시간</li> <li>d: deadline</li> <li>d &lt; p 이면 real time 프로세싱이라고 할 수 없음 <ul> <li>데드라인이 지나서 처리하는 것은 real time 의 의미를 살리지 못한 것</li> </ul> </li> <li>d &gt; p 이면 처리 못한 애가 있는데 다음 거를 처리하게 되는 경우 발생</li> </ul> <p><br /></p> <h2 id="rate-monotonic-scheduling-1시험">Rate Monotonic Scheduling (1)<span style="color:green">(시험)</span></h2> <p>rate monotonic: 주기의 역순으로 우선순위를 설정</p> <p>즉, 빈도(frequency)가 높은 애가 높은 우선순위를 갖는다.</p> <ul> <li>Schedules <strong>periodic tasks</strong> using a <strong>static priority</strong> with preemption</li> <li>A priority is assigned based on the inverse of its period -&gt; 1/p</li> <li>Shorter periods = higher priority;</li> <li>Longer periods = lower priority</li> <li>Period: P1 = 50, p2 = 100</li> <li>Processing time: t1 = 20, t2 = 35</li> <li>CPU utilization = ti/pi , p1 -&gt; 20/50 = 0.4, p2 -&gt; 35/100 = 0.35 <ul> <li>실제 처리에 필요한 시간의 비율</li> </ul> </li> <li>Total CPU utilization = <strong>0.75</strong> -&gt; both meet their deadlines <ul> <li>둘 다 deadline 안에 처리가 가능하다.</li> </ul> </li> </ul> <p><br /></p> <h2 id="rate-monotonic-scheduling-2">Rate Monotonic Scheduling (2)</h2> <p>만약 우선순위가 p이면 (not 1/p)</p> <p>deadline이 주기랑 같다고 가정</p> <ul> <li> <p>If p2 is assigned higher priority than p1 -&gt; p1 will miss its deadline</p> <ul> <li> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155646648.png" alt="image-20220927155646648" /></p> </li> <li> <p>p2는 deadline안에 처리가 됨.</p> </li> </ul> </li> <li> <p>P<sub>1</sub> is assigned a higher priority than P<sub>2</sub> . (rate monotonic) -&gt; both can meet deadlines</p> <ul> <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155708991.png" alt="image-20220927155708991" /></li> <li>p2가 30초 동안 실행되다가 P1 주기에 도달하여 이제 누가 우선순위가 높은지 따져봐야 되는데 P1의 deadline이 더 짧기 때문에 P2를 preemption하게 된다. <ul> <li>P1=50, P2=100</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="missed-deadlines-with-rate-monotonic-scheduling-3">Missed Deadlines with Rate Monotonic Scheduling (3)</h2> <p>rate monotonic scheduling은 완벽한 하드 리얼타임 시스템이 될 수 없음.</p> <ul> <li>Optimal in which static priority is used</li> <li>Period: P1 = 50, p2 = 80 -&gt; p1 will be assigned higher priority</li> <li>Processing time: t1 = 25, t2 = 35</li> <li>Total CPU utilization = (25/50) + (35/80) = 0.94 -&gt; p2 can not meet deadline <ul> <li>6%가 남아있기 때문에 가능할 것처럼 보이지만 진행 과정을 보면 P2가 끝나지 못했는데 P2 주기가 다가온 것을 볼 수 있다.</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155747221.png" alt="image-20220927155747221" /></p> <p><br /></p> <h2 id="earliest-deadline-first-scheduling-edf시험">Earliest Deadline First Scheduling (EDF)<span style="color:green">(시험)</span></h2> <ul> <li>지금시점으로부터 deadline이 제일 임박한 애를 먼저 스케쥴링 <ul> <li>주기가 짧은 놈이 preemption 되는 것이 아니라, 데드라인이 가장 작은 놈에게 <strong>preemption을</strong> 줌</li> </ul> </li> <li> <p>하드 리얼타임 시스템이 가능함!</p> </li> <li>Dynamic Priorities are assigned according to deadlines: <ul> <li>Rate Monotonic과 다르게 우선순위가 계속해서 바뀐다. <ul> <li>rate monotonic은 한 번 결정되면 바뀌지 않음(주기가 바뀌는 것이 아니기 때문에)</li> </ul> </li> <li><strong>the earlier the deadline, the higher the priority</strong>; <ul> <li>지금 시점에서!!!!!!!!</li> </ul> </li> <li>the later the deadline, the lower the priority</li> </ul> </li> <li>Priorities are adjusted to reflect the deadline of newly runnable process</li> <li>Period: P1 = 50, p2 = 80 -&gt; p1 will be assigned higher priority</li> <li>Processing time: t1 = 25, t2 = 35</li> <li>Rate3 – can not meet, EDF – can meet</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155830622.png" alt="image-20220927155830622" /></p> <ul> <li>0초에 P1, P2가 동시에 시작</li> <li>P1이 처음에 우선순위가 높기 때문에 먼저 실행</li> <li>25초동안 P1 실행</li> <li>P2처리하다가 P1 주기에서 이제 누가 우선순위가 높은지 판정하게 되는데 P1은 이미 끝났기 때문에 deadline이 100이고 P2는 아직 실행 중이기 때문에 deadline이 80이므로 P2가 더 높은 우선순위를 차지하게 되어 preemption이 일어나지 않고 계속 실행된다.</li> <li>그러다가 P2 주기에서 <ul> <li>P2 deadline: 160</li> <li>P1 deadline: 100</li> <li>이므로 P1이 우선순위라 그대로 실행을 진행하고</li> </ul> </li> <li>다시 P1 주기에서는 <ul> <li>P2 deadline: 160</li> <li>P1 deadline: 150</li> <li>이므로 P1이 우선순위가 더 높기 때문에 현재 실행중이던 P2 process를 preemption 하여 P1 process를 실행한 것이다.</li> </ul> </li> </ul> <p><strong>rate monotonic 보다 real time process를 훨씬 더 보장!!!!</strong></p> <p><br /></p> <h2 id="proportional-share-scheduling">Proportional Share Scheduling</h2> <ul> <li>T shares are allocated among all processes in the system <ul> <li>전체 CPU time의 비율</li> </ul> </li> <li>An application receives <strong>N shares</strong> where N &lt; T</li> <li>This ensures <strong>each application</strong> will receive N / T of the total processor time</li> <li>Must work with <strong>admission control policy</strong> to guarantee that an application receives its allocated shares of time <ul> <li>일정 시간의 비율을 할당 받는 것이 보장되지 않으면 거부하는 policy</li> </ul> </li> </ul> <p><br /></p> <h2 id="posix-real-time-scheduling">POSIX Real-Time Scheduling</h2> <ul> <li>The POSIX.1b standard</li> <li>API provides functions for managing real-time threads</li> <li>Defines two scheduling classes for real-time threads:</li> </ul> <ol> <li>SCHED_FIFO - threads are scheduled using a FCFS strategy with a FIFO queue. There is no time-slicing for threads of equal priority</li> <li>SCHED_RR - similar to SCHED_FIFO except time-slicing occurs for threads of equal priority</li> <li>SCHED_OTHER – system specific</li> </ol> <ul> <li>Defines two functions for getting and setting scheduling policy:</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927155944084.png" alt="image-20220927155944084" /></p> <p><br /></p> <h2 id="posic-real-time-scheduling-api">POSIC Real-Time Scheduling API</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="c1"> </span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="c1"> </span><span class="cp">
#define NUM THREADS 5 
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> 
<span class="p">{</span> 
    <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">policy</span><span class="p">;</span>
    <span class="n">pthread</span> <span class="n">t</span> <span class="n">tid</span><span class="p">[</span><span class="n">NUM</span> <span class="n">THREADS</span><span class="p">];</span> 
    <span class="n">pthread</span> <span class="n">attr</span> <span class="n">t</span> <span class="n">attr</span><span class="p">;</span> 
    <span class="cm">/* get the default attributes */</span> 
    <span class="n">pthread</span> <span class="n">attr</span> <span class="n">init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">);</span> 
    
    <span class="cm">/* get the current scheduling policy */</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pthread</span> <span class="n">attr</span> <span class="n">getschedpolicy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">policy</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to get policy.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
    <span class="k">else</span> <span class="p">{</span> 
        
        <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">OTHER</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED OTHER</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">RR</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED RR</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">policy</span> <span class="o">==</span> <span class="n">SCHED</span> <span class="n">FIFO</span><span class="p">)</span> <span class="n">printf</span><span class="p">(</span><span class="s">"SCHED FIFO</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        
        <span class="cm">/* set the scheduling policy - FIFO, RR, or OTHER */</span> 
        <span class="k">if</span> <span class="p">(</span><span class="n">pthread</span> <span class="n">attr</span> <span class="n">setschedpolicy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span> <span class="n">SCHED</span> <span class="n">FIFO</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> 
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Unable to set policy.</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span> 
        <span class="cm">/* create the threads */</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM</span> <span class="n">THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
            <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="o">&amp;</span><span class="n">attr</span><span class="p">,</span><span class="n">runner</span><span class="p">,</span><span class="nb">NULL</span><span class="p">);</span> 
        <span class="cm">/* now join on each thread */</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">NUM</span> <span class="n">THREADS</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> 
            <span class="n">pthread</span> <span class="n">join</span><span class="p">(</span><span class="n">tid</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span> 
    <span class="p">}</span>
    <span class="cm">/* Each thread will begin control in this function */</span> 
    <span class="kt">void</span> <span class="o">*</span><span class="n">runner</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">param</span><span class="p">)</span>
    <span class="p">{</span> 
        <span class="cm">/* do some work ... */</span> 
        <span class="n">pthread</span> <span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span> 
    <span class="p">}</span>
</code></pre></div></div> <p><br /></p> <hr /> <p>이 아래의 OS example은 시험에 안나옴 (그 다음은 나옴)</p> <p>real time processing까지 시험범위</p> <h2 id="operating-system-examples">Operating System Examples</h2> <ul> <li>Linux scheduling</li> <li>Solaris scheduling</li> <li>Windows XP scheduling</li> </ul> <p><br /></p> <h2 id="solaris">Solaris</h2> <ul> <li>Priority-based scheduling</li> <li>Six classes available</li> <li>Time sharing (default)</li> <li>Interactive</li> <li>Real time</li> <li>System</li> <li>Fair Share <ul> <li>Fixed priority</li> </ul> </li> <li>Given thread can be in one class at a time</li> <li>Each class has its own scheduling algorithm</li> <li>Time sharing is multi-level feedback queue <ul> <li>Loadable table configurable by sysadmin</li> </ul> </li> </ul> <p>​</p> <p><br /></p> <h2 id="solaris-dispatch-table">Solaris Dispatch Table</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160212057.png" alt="image-20220927160212057" /></p> <p><br /></p> <h2 id="solaris-scheduling">Solaris Scheduling</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160227596.png" alt="image-20220927160227596" /></p> <p><br /></p> <h2 id="solaris-scheduling-cont">Solaris Scheduling (Cont.)</h2> <ul> <li>Scheduler converts class-specific priorities into a per-thread global priority <ul> <li>Thread with highest priority runs next</li> <li>Runs until (1) blocks, (2) uses time slice, (3) preempted by higherpriority thread</li> <li>Multiple threads at same priority selected via RR</li> </ul> </li> </ul> <p><br /></p> <h2 id="windows-scheduling">Windows Scheduling</h2> <ul> <li>Windows uses priority-based preemptive scheduling</li> <li>Highest-priority thread runs next</li> <li>Dispatcher is scheduler</li> <li>Thread runs until (1) blocks, (2) uses time slice, (3) preempted by higher-priority thread</li> <li>Real-time threads can preempt non-real-time</li> <li>32-level priority scheme</li> <li>Variable class is 1-15, real-time class is 16-31</li> <li>Priority 0 is memory-management thread</li> <li>Queue for each priority</li> <li>If no run-able thread, runs idle thread</li> </ul> <p><br /></p> <h2 id="windows-priority-classes">Windows Priority Classes</h2> <ul> <li>Win32 API identifies several priority classes to which a process can belong <ul> <li>REALTIME_PRIORITY_CLASS, HIGH_PRIORITY_CLASS, ABOVE_NORMAL_PRIORITY_CLASS,NORMAL_PRIORITY_CLASS, BELOW_NORMAL_PRIORITY_CLASS, IDLE_PRIORITY_CLASS</li> </ul> </li> <li>All are variable except REALTIME</li> <li>A thread within a given priority class has a relative priority <ul> <li>TIME_CRITICAL, HIGHEST, ABOVE_NORMAL, NORMAL, BELOW_NORMAL, LOWEST, IDLE</li> </ul> </li> <li>Priority class and relative priority combine to give numeric priority</li> <li>Base priority is NORMAL within the class</li> <li>If quantum expires, priority lowered, but never below base</li> </ul> <p><br /></p> <h2 id="windows-priority-classes-cont">Windows Priority Classes (Cont.)</h2> <ul> <li>If wait occurs, priority boosted depending on what was waited for</li> <li>Foreground window given 3x priority boost</li> <li>Windows 7 added user-mode scheduling (UMS) <ul> <li>Applications create and manage threads independent of kernel</li> <li>For large number of threads, much more efficient</li> <li>UMS schedulers come from programming language libraries like C++ Concurrent Runtime (ConcRT) framework</li> </ul> </li> </ul> <p><br /></p> <h2 id="windows-xp-priorities">Windows XP Priorities</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927160616698.png" alt="image-20220927160616698" /></p> <p><br /></p> <h2 id="linux-scheduling-through-version-25">Linux Scheduling Through Version 2.5</h2> <ul> <li>Prior to kernel version 2.5, ran variation of standard UNIX scheduling algorithm <ul> <li>Did not support SMP system</li> <li>Runnable task의 개수가 증가하면 성능 저하</li> </ul> </li> <li>Version 2.5 moved to constant order O(1) scheduling time <ul> <li>SMP system 지원, <ul> <li>Processor affinity. Load balancing 지원</li> </ul> </li> <li>runnable task 개수에 상관없이 constant scheduling</li> <li>Worked well, but poor response times for interactive processes</li> </ul> </li> </ul> <p><br /></p> <h2 id="linux-scheduling-in-version-2623-">Linux Scheduling in Version 2.6.23 +</h2> <ul> <li> <p>O(1) provides excellent performance for SMP, but poor response time for interactive tasks - Completely Fair Scheduler (CFS)</p> </li> <li> <p>Scheduling is based on Scheduling classes</p> <ul> <li> <p>Each class is assigned a specific priority</p> </li> <li> <p>2 scheduling classes included, others can be added</p> </li> <li> <p>Different scheduling algorithms can be used for different scheduling classes</p> <ol> <li> <p>Default - CFS</p> </li> <li> <p>real-time</p> </li> </ol> </li> <li> <p>Scheduler picks highest priority task in highest scheduling class</p> </li> </ul> </li> <li> <p>Priority에 따라 고정 길이의 time quantum을 제공하던 방식 개선</p> <ul> <li>Rather than quantum based on fixed time allotments, CFS assigns a proportion of CPU time to each task</li> <li>This proportion is calculated based on nice value from -20 to +19</li> <li>CFS does not use discrete values of time slices and instead identifies target latency <ul> <li>interval of time during which task should run at least once</li> </ul> </li> <li>Proportions of CPU time are allocated from the value of targeted latency</li> <li>Target latency can increase if number of active tasks increases</li> </ul> </li> <li>CFS scheduler does not directly assign priorities</li> <li>CFS records how long each task has run by maintaining per task virtual run time in variable vruntime <ul> <li>Vruntime is associated with decay factor based on priority of task <ul> <li>lower priority is higher decay rate</li> <li>high priority is lower decay rate</li> </ul> </li> <li>Normal default priority (nice value 0) yields <ul> <li>virtual run time = actual run time</li> </ul> </li> <li>Low priority : virtual run time &gt; actual run time</li> <li>High priority : virtual run time &lt; actual run time</li> </ul> </li> <li>To decide next task to run, scheduler picks task with lowest virtual run time</li> <li>Assume that two tasks have the same nice values, one task is I/O bound, the other is CPU bound <ul> <li>The value of vruntime will eventually be lower for I/O bound task than for CPU bound task</li> <li>Higher priority will be given for I/O bound task</li> <li>if CPU bound task is executing when I/O bound task becomes eligible to run <ul> <li>Preemption by I/O bound task: Preemptive, priority based</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="linux-scheduling-cont">Linux Scheduling (Cont.)</h2> <ul> <li>Real-time scheduling according to POSIX.1b <ul> <li>Real-time tasks have static priorities (0 ~ 99)</li> </ul> </li> <li>Any task scheduled using SCHED_FIFO or SCHED_RR real-time policy runs at higher priority than normal non-real-time tasks</li> <li>All other normal tasks dynamic based on nice value plus or minus 5 <ul> <li>Nice value of -20 maps to global priority 100</li> <li>Nice value of +19 maps to priority 139</li> <li>Map into global priority with numerically lower values indicating higher priority</li> <li>Interactivity of task determines plus or minus <ul> <li>More interactive -&gt; more minus</li> </ul> </li> <li>Priority recalculated when task expired</li> <li>This exchanging arrays implements adjusted priorities</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161205643.png" alt="image-20220927161205643" /></p> <p><br /></p> <h2 id="priorities-and-time-slice-length">Priorities and Time-slice length</h2> <p>CPU를 얼마나 사용했냐에 따라서 등급을 조정</p> <ul> <li>Two priority ranges: time-sharing and real-time <ul> <li>real-time은 우선순위가 동적으로 조정되지 않음</li> </ul> </li> <li>Real-time range from 0 to 99 and nice value from 100 to 140</li> <li>Higher priority gets larger q <ul> <li>우선순위가 높을 수록 time quantum을 높게 줌.</li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161247767.png" alt="image-20220927161247767" /></p> <ul> <li>real-time이 100개, other task(normal task)가 40개</li> <li>real-time은 철저한 우선순위 기반</li> <li>normal task는 계속해서 우선순위가 바뀜</li> <li>주어진 time quantum을 다 쓰는 경우에 우선 순위가 내려감</li> </ul> <p><br /></p> <h2 id="list-of-tasks-indexed-according-to-priorities">List of Tasks Indexed According to Priorities</h2> <ul> <li>Task runnable as long as time left in time slice (active) <ul> <li>다 실행되지 못하고 preemption 된 경우는 active queue에 머물러 있고</li> </ul> </li> <li>If no time left (expired), not runnable until all other tasks use their slices <ul> <li>time slice가 남아있는 경우 expired queue로 넘어간다.</li> </ul> </li> <li>All runnable tasks tracked in per-CPU <strong>runqueue</strong> data structure <ul> <li>Two priority arrays (active, expired)</li> <li>Tasks indexed by priority</li> <li>When no more active, arrays are exchanged <ul> <li>active queue에 있는 것들이 전부 expired로 넘어가면 그때 두 queue(active, expired)는 바뀌게 된다.</li> </ul> </li> </ul> </li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161321720.png" alt="image-20220927161321720" /></p> <p><br /></p> <h2 id="cfs-performance">CFS Performance</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161336095.png" alt="image-20220927161336095" /></p> <p><br /></p> <h2 id="algorithm-evaluation">Algorithm Evaluation</h2> <ul> <li>How to select CPU-scheduling algorithm for an OS?</li> <li>Determine criteria, then evaluate algorithms</li> <li>Deterministic modeling <ul> <li>Type of analytic evaluation</li> <li>Takes a particular predetermined workload and defines the performance of each algorithm for that workload</li> <li>Simple but only answer to specific cases</li> </ul> </li> <li>Consider 5 processes arriving at time 0</li> </ul> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161408493.png" alt="image-20220927161408493" /></p> <p><br /></p> <h2 id="deterministic-evaluation">Deterministic Evaluation</h2> <ul> <li>For each algorithm, calculate minimum average waiting time</li> <li>Simple and fast, but requires exact numbers for input, applies only to those inputs <ul> <li>FCS is 28ms <ul> <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161438283.png" alt="image-20220927161438283" /></li> </ul> </li> <li>Non-preemptive SFJ is 13ms: <ul> <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161449469.png" alt="image-20220927161449469" /></li> </ul> </li> <li>RR is 23ms: <ul> <li><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161506156.png" alt="image-20220927161506156" /></li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="queueing-models">Queueing Models</h2> <ul> <li>Generally no static set of processes to use for deterministic modeling</li> <li>Compute criterion using two distributions</li> <li>Describes the arrival of processes, and CPU and I/O bursts probabilistically <ul> <li>Distribution of CPU and I/O bursts</li> <li>Arrival-time distribution - Distribution of times when processes arrive in the system <ul> <li>Commonly exponential, and described by mean</li> <li>Computes average throughput, utilization, waiting time, etc</li> </ul> </li> </ul> </li> <li>Computer system described as network of servers, <ul> <li>each server has queue of waiting processes <ul> <li>CPU with ready queue, I/O with device queue</li> </ul> </li> <li>Knowing arrival rates and service rates</li> <li>Computes utilization, average queue length, average wait time, etc</li> </ul> </li> </ul> <p><br /></p> <h2 id="littles-formula">Little’s Formula</h2> <ul> <li> <p>n = average queue length</p> </li> <li> <p>W = average waiting time in queue</p> </li> <li> <p>λ = average arrival rate into queue</p> </li> <li> <p>Little’s law – in steady state, processes leaving queue must equal processes arriving,</p> <p>thus n = λ x W</p> </li> <li> <p>Valid for any scheduling algorithm and arrival distribution</p> </li> <li> <p>For example, if on average 7 processes arrive per second, and normally 14 processes in queue, then average wait time per process = 2 seconds</p> </li> </ul> <p><br /></p> <h2 id="simulations">Simulations</h2> <p>가상의 실시간을 소프트웨어로 구현하고, 시뮬레이션 돌리기</p> <ul> <li>Queueing models limited</li> <li>Simulations more accurate <ul> <li>Programmed model of computer system</li> <li>Clock is a variable</li> <li>Gather statistics indicating algorithm performance</li> <li>Data to drive simulation gathered via <ul> <li>Random number generator according to probabilities</li> <li>Distributions defined mathematically or empirically</li> <li>Trace tapes record sequences of real events in real systems</li> </ul> </li> </ul> </li> </ul> <p><br /></p> <h2 id="evaluation-of-cpu-schedulers-by-simulation">Evaluation of CPU Schedulers by Simulation</h2> <p><img src="https://raw.githubusercontent.com/speardragon/save-image-repo/main/img/image-20220927161753590.png" alt="image-20220927161753590" /></p> <p><br /></p> <h2 id="implementation">Implementation</h2> <ul> <li>Even simulations have limited accuracy</li> <li>Just implement new scheduler and test in real systems <ul> <li>High cost, high risk</li> <li>Environments vary</li> </ul> </li> <li>Most flexible schedulers can be modified per-site or per-system</li> <li>Or APIs to modify priorities</li> <li>But again environments vary</li> </ul> </section> <footer class="page__meta"> <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-09-27T00:00:00+09:00">September 27, 2022</time></p> </footer> <nav class="pagination"> <a href="/HCI-5.-HCI-in-The-Software-Process/" class="pagination--pager" title="[HCI] 5. HCI in The Software Process ">Previous</a> <a href="/OS-Synchronization-Tools/" class="pagination--pager" title="[OS] Synchronization Tools ">Next</a> </nav> </div> </article> </div> </section> <footer> <p> <a href="https://github.com/github_username" title="Github"> <svg><use xlink:href="#icon-github"></use></svg> </a> <a href="https://www.facebook.com/facebook_username" title="Facebook"> <svg><use xlink:href="#icon-facebook"></use></svg> </a> <a href="https://twitter.com/twitter_username" title="Twitter"> <svg><use xlink:href="#icon-twitter"></use></svg> </a> <a href="https://medium.com/@medium_username" title="Medium"> <svg><use xlink:href="#icon-medium"></use></svg> </a> <a href="https://www.instagram.com/instagram_username" title="Instagram"> <svg><use xlink:href="#icon-instagram"></use></svg> </a> <a href="https://www.linkedin.com/in/linkedin_username" title="LinkedIn"> <svg><use xlink:href="#icon-linkedin"></use></svg> </a> </p> <ul> <li> <a href="http://localhost:4000/">Home</a> </li> <li> <a href="http://localhost:4000/about">About</a> </li> <li> <a href="http://localhost:4000/contact">Contact</a> </li> <li> <a href="http://localhost:4000/feed.xml">Feed</a> </li> </ul> <p> <span>Jekflix</span> was made with <svg class="love"><use xlink:href="#icon-heart"></use></svg> by <a href="https://rossener.com" target="_blank" class="creator">Thiago Rossener</a> </p> </footer> <script type="application/ld+json"> { "@context": "http://schema.org", "@type": "Organization", "name": "Jekflix", "description": "Jekflix is a template for Jekyll inspired by Netflix and made by Thiago Rossener.", "url": "http://localhost:4000/", "logo": { "@type": "ImageObject", "url": "http://localhost:4000/assets/img/icons/mediumtile.png", "width": "600", "height": "315" }, "sameAs": [ "https://github.com/github_username","https://www.facebook.com/facebook_username","https://twitter.com/twitter_username","https://medium.com/@medium_username","https://www.instagram.com/instagram_username","https://www.linkedin.com/in/linkedin_username" ] } </script> <!-- Include the script that allows Netlify CMS login --> <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script> <!-- Include the website scripts --> <script src="/assets/js/scripts.min.js"></script> <!-- Include Google Analytics script --> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script> <script> var host = window.location.hostname; if (host != 'localhost') { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-XXXXXXXX-X'); } </script> <!-- Include extra scripts --> </body> </html>
